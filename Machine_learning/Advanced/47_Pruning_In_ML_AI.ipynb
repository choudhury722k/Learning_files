{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3-fpbULmNvI1"
   },
   "source": [
    "# Pruning in ML/AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iq9DwqRDNtIt"
   },
   "source": [
    "Pruning as a concept was originally introduced to the field of deep learning by Yann LeCun in an eerie titled paper “Optimal Brain Damage”. The word pruning means trimming or cutting away the excess; in the context of machine learning and artificial intelligence, it involves removing the redundant or the least important parts of a model or search space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pd0u6GKtOYdO"
   },
   "source": [
    "# Using Pruning to Regularize a Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOc-Rzt9Ocn5"
   },
   "source": [
    "We’ll be training a DecisionTreeClassifier model on the [Titanic dataset](https://www.kaggle.com/c/titanic/) available on Kaggle. In this example, we’ll use pruning as a regularization technique for the overfitting-prone DecisionTreeClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f_-6lDWbOzzd"
   },
   "source": [
    "Load, clean, and split the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install pip --upgrade --user -q\n",
    "!python -m pip install numpy pandas seaborn matplotlib scipy sklearn statsmodels tensorflow keras --user -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-53ODROaLp6U"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NKvzVSQu8GHU"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"https://raw.githubusercontent.com/agconti/kaggle-titanic/master/data/train.csv\")\n",
    "data = data.loc[:,(\"Survived\",\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Fare\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GIu7kTt68Gdc"
   },
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)\n",
    "#'inplace=True' applies the code to the 'data' object.\n",
    "le = LabelEncoder()\n",
    "data.Sex = le.fit_transform(data.Sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rWygcTY88Gzg"
   },
   "outputs": [],
   "source": [
    "x = data.iloc[:,1:]   # Second column until the last column\n",
    "y = data.iloc[:,0]    # First column (Survived) is our target\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g_zDfE-yBUjR"
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tWi95w14BWwZ"
   },
   "outputs": [],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LC2oMagxQAkt"
   },
   "source": [
    "  Create a baseline model, train and evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YVeUToegBABZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X3LpVnTbQCve"
   },
   "source": [
    "Let’s visualize the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9SKivqQc8L_Q"
   },
   "outputs": [],
   "source": [
    "dt_classifier = DecisionTreeClassifier(random_state = 42)\n",
    "dt_classifier.fit(x_train, y_train)  #train parameters: features and target\n",
    "pred = dt_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IjtDooM68Pyk"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, pred)\n",
    "#parameters: targets to be predicted and predictions from new data used before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V32F5MHg8PwM"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25,20))\n",
    "_ = tree.plot_tree(dt_classifier, \n",
    "                   feature_names=x.columns,  \n",
    "                   class_names=[\"Died\", \"Survived\"],\n",
    "                   filled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oc7dy6jQQH5t"
   },
   "source": [
    "Prune the tree by searching for the optimum depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9kdJ2_pJ8Ptd"
   },
   "outputs": [],
   "source": [
    "max_depth = []\n",
    "acc = []\n",
    "for i in range(1,30):\n",
    " dt_classifier = DecisionTreeClassifier(max_depth=i, random_state = 42)\n",
    " dt_classifier.fit(x_train, y_train)\n",
    " pred = dt_classifier.predict(x_test)\n",
    " acc.append(accuracy_score(y_test, pred))\n",
    " max_depth.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q1nPxgO98L3c"
   },
   "outputs": [],
   "source": [
    "print(max(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MaiMBF1ACaYh"
   },
   "outputs": [],
   "source": [
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gEL2-KQsCIcU"
   },
   "outputs": [],
   "source": [
    "depth = acc.index(max(acc)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MSZKsTDiCUq3"
   },
   "outputs": [],
   "source": [
    "depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2poe0RhQLXb"
   },
   "source": [
    "Let’s visualize the pruned tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "utn-z0Dc8LpW"
   },
   "outputs": [],
   "source": [
    "dt_classifier = DecisionTreeClassifier(max_depth=depth, random_state = 42)\n",
    "dt_classifier.fit(x_train, y_train)\n",
    "pred = dt_classifier.predict(x_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g4oafvWjCVS0"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25,20))\n",
    "_ = tree.plot_tree(dt_classifier, \n",
    "                   feature_names=x.columns,  \n",
    "                   class_names=[\"Died\", \"Survived\"],\n",
    "                   filled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UCmVafsHQOou"
   },
   "source": [
    "# Compressing a Neural Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jDtlWXHQTjI"
   },
   "source": [
    "In this section,  we illustrate the use of pruning for compressing a convolutional neural network model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HAwP3jMFQWbn"
   },
   "source": [
    "  Install tensorflow-model-optimization and create the baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BWj-aDZ_QPmZ"
   },
   "outputs": [],
   "source": [
    "! pip install -q tensorflow-model-optimization\n",
    "import tempfile\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "# Load MNIST dataset\n",
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the input image so that each pixel value is between 0 to 1.\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Define the model architecture.\n",
    "model = keras.Sequential([\n",
    "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
    "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "# Train the classification model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(\n",
    "  train_images,\n",
    "  train_labels,\n",
    "  epochs=4,\n",
    "  validation_split=0.1,\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UHkGTSZsQbNR"
   },
   "source": [
    "  Evaluate and save the baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gsonIyynQZmh"
   },
   "outputs": [],
   "source": [
    "_, baseline_model_accuracy = model.evaluate(\n",
    "    test_images, test_labels, verbose=0)\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "_, keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model, keras_file, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o6OpG2tBQf1_"
   },
   "source": [
    "Prune the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-x5VdASwQeIA"
   },
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# Compute end step to finish pruning after 2 epochs.\n",
    "batch_size = 128\n",
    "epochs = 2\n",
    "validation_split = 0.1\n",
    "num_images = train_images.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "#Define model for pruning.\n",
    "pruning_params = {\n",
    "'pruning_schedule':\n",
    "tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "final_sparsity=0.80,\n",
    "begin_step=0,\n",
    "end_step=end_step)\n",
    "}\n",
    "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# prune_low_magnitude requires a recompile.\n",
    "model_for_pruning.compile(optimizer='adam',\n",
    "loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "metrics=['accuracy'])\n",
    "\n",
    "logdir = tempfile.mkdtemp()\n",
    "callbacks = [\n",
    "tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "]\n",
    "\n",
    "model_for_pruning.fit(train_images, train_labels,\n",
    "batch_size=batch_size, epochs=epochs,\n",
    "validation_split=validation_split,\n",
    "callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rFiVvrg7TVmk"
   },
   "outputs": [],
   "source": [
    " _, pruned_keras_file = tempfile.mkstemp('.h5')\n",
    " tf.keras.models.save_model(model_for_pruning, pruned_keras_file, include_optimizer=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ShCiZVtIQnAq"
   },
   "source": [
    "Evaluate and compare with baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wYO840OOQlhJ"
   },
   "outputs": [],
   "source": [
    "_, model_for_pruning_accuracy = model_for_pruning.evaluate(\n",
    "  test_images, test_labels, verbose=0)\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "print('Pruned test accuracy:', model_for_pruning_accuracy) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUKN73gJQtIw"
   },
   "source": [
    "There is a very small drop in performance, now let’s compare the size of the two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BJAMDAFbQqjc"
   },
   "outputs": [],
   "source": [
    "def get_gzipped_model_size(file):\n",
    "  # Returns size of gzipped model, in bytes.\n",
    "  import os\n",
    "  import zipfile\n",
    "  _, zipped_file = tempfile.mkstemp('.zip')\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(file)\n",
    "  return os.path.getsize(zipped_file)\n",
    "\n",
    "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(pruned_keras_file))) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOibqVQZiEmSTmwGnvxLnaa",
   "collapsed_sections": [],
   "name": "1_Pruning_In_ML/AI.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
