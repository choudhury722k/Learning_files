{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gK_UalSbp_18"
   },
   "source": [
    "# **What is XG Boost?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KJai_vSCqD56"
   },
   "source": [
    "XGBoost, an abbreviation for eXtreme Gradient Boosting is one of the most commonly used machine learning algorithms. Be it for classification or regression problems, XGBoost has been successfully relied upon by many since its release in 2014. It is a library for implementing optimised and distributed gradient boosting and provides a great framework for C++, Java, Python, R and Julia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4fT16LRz9X0"
   },
   "source": [
    "Unlike other boosting algorithms where weights of misclassified branches are increased, in Gradient Boosted algorithms the loss function is optimised. XGBoost is an advanced implementation of gradient boosting along with some regularization factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0zjKgYOy0BKN"
   },
   "source": [
    "For complete understanding of this algorithm please refer this post [Understanding XGBoost in Detail](https://analyticsindiamag.com/xgboost-internal-working-to-make-decision-trees-and-deduce-predictions/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rBRf1R160VCW"
   },
   "source": [
    "# **The Reason Behind Its Popularity**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MMQAfySE0ZGs"
   },
   "source": [
    "XGBoost provides a number of features that can greatly impact the efficiency and performance of a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Olm1OJI0a2H"
   },
   "source": [
    "\n",
    "Parallelisation, distributed computing, cache optimisation, automatic handling of missing data are some of its features that stand out compared to other algorithms and libraries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LXziUAA20cAr"
   },
   "source": [
    "Another set of factors include the speed of execution and the performance of the model in both regression and classification type problems. The algorithm is most effective in producing a model with lesser variance and a more stable prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SlGOGGYbqL7E"
   },
   "source": [
    "# **Implement XGBoost In Python**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F4nfiQY70p4k"
   },
   "source": [
    "We will be using a dataset given for the hackathon “Predicting House Prices In Bengaluru” at MachineHack.com. (Click [here](https://machinehack.com/hackathons/predicting_house_prices_in_bengaluru/data) to download the complete dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HxKMfIns43y6"
   },
   "source": [
    "## **Installing XGBoost**\n",
    "\n",
    "Use the python pip installer to install the XGBoost library from your terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install pip --upgrade --user -q\n",
    "!python -m pip install numpy pandas seaborn matplotlib scipy sklearn statsmodels xgboost --user -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hAp52V0e5AVi"
   },
   "source": [
    "## **Let’s get coding:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l-j3zjAmqT5e"
   },
   "source": [
    "## **Importing the libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c3nMAhWpvbT5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t3lgLn_2vp8U"
   },
   "source": [
    "## **Importing the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EZrsxWtkvy_W"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('XGB_Train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LgFQDonVwCr2"
   },
   "source": [
    "We will check what is there in the data and its shape. Refer to the below code for the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KzRQC5APwDaU"
   },
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "92qBtiyZFuxK"
   },
   "outputs": [],
   "source": [
    "dataset.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EXHUkf8xGIpl"
   },
   "outputs": [],
   "source": [
    "#Dealing with NA data values\n",
    "dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w4soCI6sGnJP"
   },
   "outputs": [],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5p7jgAttwFYT"
   },
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A16D_5H5NUDc"
   },
   "outputs": [],
   "source": [
    "def convert_to_ft(x):\n",
    "  \"\"\"\n",
    "  \"\"\"\n",
    "  if \"Sq. Meter\" in x:\n",
    "    x = x.replace(\"Sq. Meter\", \"\")\n",
    "    x = float(x)\n",
    "    x_ft  = x * 10.764\n",
    "  elif \"Sq. Yards\" in x:\n",
    "    x = x.replace(\"Sq. Yards\", \"\")\n",
    "    x = float(x)\n",
    "    x_ft = x * 3.0\n",
    "  elif \"Acres\" in x:\n",
    "    x = x.replace(\"Acres\", \"\")  \n",
    "    x = float(x)\n",
    "    x_ft = x * 43560\n",
    "  elif \"-\" in x:\n",
    "    o, t = x.split(\"-\")\n",
    "    o = float(o)\n",
    "    t = float(t)\n",
    "    x_ft = (o+t)/2\n",
    "  else:\n",
    "    x_ft = float(x)\n",
    "\n",
    "  return x_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ndipiAnzJKoi"
   },
   "outputs": [],
   "source": [
    "#convert Object datatype of total_sqft to integer\n",
    "def func(x):\n",
    "  \"\"\"\n",
    "  \"\"\"\n",
    "  x = convert_to_ft(x)\n",
    "  # try:\n",
    "  #   x = convert_to_ft(x)\n",
    "  # except:\n",
    "  #   print(\"Except\",x)\n",
    "  return x\n",
    "\n",
    "dataset['total_sqft'] = dataset[\"total_sqft\"].apply(lambda x : func(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v09eoRO85tYl"
   },
   "source": [
    "The data consists of features of Houses in locations across Bangalore. The problem is to predict the ‘price’ of the houses from  ‘total_sqfeet’, ‘size’, ‘bath’, ‘balcony’, ‘area_type’ and ‘location’.\n",
    "\n",
    "The data has been preprocessed to some extent. Click [here](https://analyticsindiamag.com/data-pre-processing-in-python/) for instructions on Data preprocessing in python. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G5NqSQHZwJx5"
   },
   "source": [
    "## **Extracting the values and categorising the features to dependent and Independent Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lyOHXiZi6G2A"
   },
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,[0,2,3,5,6,7]].values\n",
    "y = dataset.iloc[:, 8].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nmCvOVWe6lWT"
   },
   "source": [
    "\n",
    "> * **X**: Set of Independent features(‘total_sqfeet’, ‘size’, ‘bath’, ‘balcony’, ‘area_type’ and ‘location’).\n",
    "> * **Y**: Dependendent Feature (price)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "naICwmIs60nl"
   },
   "source": [
    "## **Handling categorical Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U00Y7P0YDKi_"
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AQT7Hhlq64SJ"
   },
   "source": [
    "The first three features ‘size’, ‘area_type’ and ‘location’ in the dataset consist of categorical values and hence is required to encode them to numbers.\n",
    "\n",
    "We will use the label encoder to encode the features into numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P4P4IKgZ67gA"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_X_0= LabelEncoder()\n",
    "le_X_1= LabelEncoder()\n",
    "le_X_2= LabelEncoder()\n",
    "\n",
    "X[:, 2] = le_X_0.fit_transform(X[:, 2])\n",
    "X[:, 0] = le_X_1.fit_transform(X[:, 0])\n",
    "X[:, 1] = le_X_2.fit_transform(X[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s1KXH2YZGSUE"
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9INS_YGVHGXe"
   },
   "source": [
    "## **Splitting the data set into test and training set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AGj_9im7HHr_"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dhll_5JhHPJ7"
   },
   "source": [
    "## **Creating and initialising  XGBoost Regressor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xO0RXDV3HSBV"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "regressor  = XGBRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "beIVO0UBHR2s"
   },
   "source": [
    "## **Fitting the regressor with data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fTw94S5pHW0_"
   },
   "source": [
    "After initialising the regressor we need to fit the regressor with training data so that it can learn the correlations between the features to give an accurate prediction for new inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LY0w8-YZHZB6"
   },
   "outputs": [],
   "source": [
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "83SZbeR-HeTU"
   },
   "source": [
    "## **Predicting the prices**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trCV1kXWHg2Y"
   },
   "source": [
    "Predicting for training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yt2s_9aoHjx9"
   },
   "outputs": [],
   "source": [
    "Y_pred_train = regressor.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Urqif-SfHi9m"
   },
   "source": [
    "The above code will give the X_tain (training set with independent features) as input to the regressor and predicts values for prices. The predicted values are stored in the numpy array Y_pred_train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9-2yEGeHnyZ"
   },
   "source": [
    "Predicting for test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GvbxErZ7HpD4"
   },
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QTypcDn6Hq-C"
   },
   "source": [
    "The above code will give the X_test (test set with independent features) as input to the regressor and predicts values for prices. The predicted values are stored in the numpy array Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuJl7V47HvML"
   },
   "source": [
    "## **Evaluating accuracy with RMSLE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JzHXg0rYHx0S"
   },
   "source": [
    "Calculating RMSLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6kenkdlBHu65"
   },
   "outputs": [],
   "source": [
    "def rmsle(y_pred,y_test) :\n",
    "  error = np.square(np.log10(y_pred +1) - np.log10(y_test +1)).mean() ** 0.5\n",
    "  Acc = 1 - error\n",
    "  return Acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zrdQXJTLH3At"
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy attained on Training Set = \",rmsle(Y_pred_train, y_train))\n",
    "print(\"Accuracy attained on Test Set = \",rmsle(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80QsgDqknaj-"
   },
   "source": [
    "# **Related Articles --**\n",
    "\n",
    "\n",
    "> * [Understand XG Boost](https://analyticsindiamag.com/xgboost-internal-working-to-make-decision-trees-and-deduce-predictions/)\n",
    "> * [XGBoost v/s LightGBM](https://analyticsindiamag.com/comparing-the-gradient-boosting-decision-tree-packages-xgboost-vs-lightgbm/)\n",
    "> * [Random Forest V/s XG Boost](https://analyticsindiamag.com/random-forest-vs-xgboost-comparing-tree-based-algorithms-with-codes/)\n",
    "> * [Basics of Ensemble Learning](https://analyticsindiamag.com/basics-of-ensemble-learning-in-classification-techniques-explained/) \n",
    "> * [Bagging V/S Boosting](https://analyticsindiamag.com/guide-to-ensemble-methods-bagging-vs-boosting/)\n",
    "> * [Guide to Ensemble Learning](https://analyticsindiamag.com/a-hands-on-guide-to-hybrid-ensemble-learning-models-with-python-code/)\n",
    "> * [Ensemble Methods](https://analyticsindiamag.com/primer-ensemble-learning-bagging-boosting/)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN7+3uEOoRkgy7UfY0ZM85D",
   "collapsed_sections": [],
   "name": "2_XGBoost_Custom_Data.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
