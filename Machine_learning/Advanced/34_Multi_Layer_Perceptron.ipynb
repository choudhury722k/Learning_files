{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvlM1FtpcYWl"
   },
   "source": [
    "# **Multi Layer Perceptron**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFrYDvoIfQHs"
   },
   "source": [
    "Artificial Neural Networks or shortly ANN’s are widely used today in many applications and, classification is one of them and also there are many libraries and frameworks that are dedicated to building Neural Networks with ease. Most of these frameworks and tools, however, require many lines of code to implement when compared to a simple library from Scikit-Learn that we are going to learn now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rG8iVm6rfTNg"
   },
   "source": [
    "we will discuss one of the easiest to implement Neural Network for classification from Scikit-Learn’s called the MLPClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7SC-HMptfWGo"
   },
   "source": [
    "## **MLPClassifier vs Other Classification Algorithms**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y4WJtnp0faCE"
   },
   "source": [
    "MLPClassifier stands for Multi-layer Perceptron classifier which in the name itself connects to a Neural Network. Unlike other classification algorithms such as Support Vectors or Naive Bayes Classifier, MLPClassifier relies on an underlying Neural Network to perform the task of classification.\n",
    "\n",
    "One similarity though, with Scikit-Learn’s other classification algorithms is that implementing MLPClassifier takes no more effort than implementing Support Vectors or Naive Bayes or any other classifiers from Scikit-Learn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D5O4HrayfcOE"
   },
   "source": [
    "## **Implementing MLPClassifier With Python**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JlR1F81cqKXu"
   },
   "source": [
    "Once again we will rely on our favourite hackathon platform MachineHack for the dataset we are going to use in this coding walkthrough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qWhGC8mJqPzw"
   },
   "source": [
    "To get the dataset, head to MachineHack, sign up and select the [Predict The Data Scientists Salary In India Hackathon](https://machinehack.com/hackathons/predict_the_data_scientists_salary_in_india_hackathon/data). Go ahead and start the hackathon, you can download the datasets in the assignments page of the hackathon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4nNxbtAWqzWU"
   },
   "source": [
    "Let code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MyUDeIQmq1O5"
   },
   "source": [
    "### **Importing the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install pip --upgrade --user -q\n",
    "!python -m pip install numpy pandas seaborn matplotlib scipy sklearn statsmodels --user -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WofJdiytbQBF"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"MLP_Final_Train_Dataset.csv\")\n",
    "data = data[['company_name_encoded','experience', 'location', 'salary']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FN-sJgirq670"
   },
   "source": [
    "The above code block will read the dataset into a data-frame. Also, we will stick will only a few selected features from the dataset ‘company_name_encoded’, ‘experience’, ‘location’ and ‘salary’."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LdzdJ9a9q-cq"
   },
   "source": [
    "### **Cleaning The Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mlQCsP9UrBND"
   },
   "source": [
    "Now let us clean up the data.\n",
    "\n",
    "Splitting the ‘experience’ column into two numerical columns of minimum experience and maximum experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HsfFW9i9q8nx"
   },
   "outputs": [],
   "source": [
    "#Cleaning the experience\n",
    "exp = list(data.experience)\n",
    "min_ex = []\n",
    "max_ex = []\n",
    "\n",
    "for i in range(len(exp)):\n",
    "   exp[i] = exp[i].replace(\"yrs\",\"\").strip()\n",
    "   min_ex.append(int(exp[i].split(\"-\")[0].strip()))\n",
    "   max_ex.append(int(exp[i].split(\"-\")[1].strip()))\n",
    "\n",
    "#Attaching the new experiences to the original dataset\n",
    "data[\"minimum_exp\"] = min_ex\n",
    "data[\"maximum_exp\"] = max_ex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b6pjTD-IrJJ4"
   },
   "source": [
    "Encoding the textual data in ‘location’ and ‘salary’ columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lDANZ6HBrKiz"
   },
   "outputs": [],
   "source": [
    "#Label encoding location and salary\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "data['location'] = le.fit_transform(data['location'])\n",
    "data['salary'] = le.fit_transform(data['salary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4BNfSmSJrQPo"
   },
   "source": [
    "We will now delete the original experience column and reorder the data-frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Crm_eUdFrQql"
   },
   "outputs": [],
   "source": [
    "#Deleting the original experience column and reordering\n",
    "data.drop(['experience'], inplace = True, axis = 1)\n",
    "data = data[['company_name_encoded', 'location','minimum_exp', 'maximum_exp', 'salary']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pDcKmKW9rUG6"
   },
   "source": [
    "After executing all the above code blocks our new dataset will look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0W8ZMfh8rUj_"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TGFV61Ykrdeo"
   },
   "source": [
    "### **Feature Scaling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1No-vjKJrsHZ"
   },
   "source": [
    "Scaling all the numerical features in the dataset.\n",
    "\n",
    "**Note:**\n",
    "\n",
    "‘Salary’ column is not feature scaled as it consists of the labelled classes and not numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wg1me7yJrvFE"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "data[['company_name_encoded', 'location', 'minimum_exp', 'maximum_exp']] = sc.fit_transform(data[['company_name_encoded', 'location', 'minimum_exp', 'maximum_exp']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WvEwoiOUrxHI"
   },
   "source": [
    "After scaling the dataset will look like what is shown below :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0-cQYE_7rxt2"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SU2F221Ur0_N"
   },
   "source": [
    "### **Creating training and validation sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6U3_U0E0r4F7"
   },
   "outputs": [],
   "source": [
    "#Splitting the dataset into  training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "training_set, validation_set = train_test_split(data, test_size = 0.2, random_state = 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IklCK39Or6MV"
   },
   "outputs": [],
   "source": [
    "#classifying the predictors and target variables as X and Y\n",
    "X_train = training_set.iloc[:,0:-1].values\n",
    "Y_train = training_set.iloc[:,-1].values\n",
    "X_val = validation_set.iloc[:,0:-1].values\n",
    "y_val = validation_set.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4CNl32hOr8hT"
   },
   "source": [
    "The above code block will generate predictors and targets which we can fit our model to train and validate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9bLCd9_rr-Gb"
   },
   "source": [
    "### **Measuring the Accuracy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FiWeZvMWsBvw"
   },
   "source": [
    "We will use the confusion matrix to determine the accuracy which is measured as the total number of correct predictions divided by the total number of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y9RheoGCsDA8"
   },
   "outputs": [],
   "source": [
    "def accuracy(confusion_matrix):\n",
    "   diagonal_sum = confusion_matrix.trace()\n",
    "   sum_of_all_elements = confusion_matrix.sum()\n",
    "   return diagonal_sum / sum_of_all_elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5F6CYXTYsAqn"
   },
   "source": [
    "### **Building the MLPClassifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KjnbxG0KsI15"
   },
   "source": [
    "Finally, we will build the Multi-layer Perceptron classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oQ5ciznwsK-5"
   },
   "outputs": [],
   "source": [
    "#Importing MLPClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#Initializing the MLPClassifier\n",
    "classifier = MLPClassifier(hidden_layer_sizes=(150,100,50), max_iter=300,activation = 'relu',solver='adam',random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "csKtlEe2sPyF"
   },
   "source": [
    "\n",
    "> * **hidden_layer_sizes** : This parameter allows us to set the number of layers and the number of nodes we wish to have in the Neural Network Classifier. Each element in the tuple represents the number of nodes at the ith position where i is the index of the tuple. Thus the length of tuple denotes the total number of hidden layers in the network.\n",
    "> * **max_iter**: It denotes the number of epochs.\n",
    "> * **activation**: The activation function for the hidden layers.\n",
    "> * **solver**: This parameter specifies the algorithm for weight optimization across the nodes.\n",
    "> * **random_state**: The parameter allows to set a seed for reproducing the same results\n",
    "\n",
    "After initializing we can now give the data to train the Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QxCl7xlfseSe"
   },
   "outputs": [],
   "source": [
    "#Fitting the training data to the network\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZK3Rv_BJsf2l"
   },
   "source": [
    "Using the trained network to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QXbHkG6vsiER"
   },
   "outputs": [],
   "source": [
    "#Predicting y for X_val\n",
    "y_pred = classifier.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K3368QgSslSD"
   },
   "source": [
    "### **Calculating the accuracy of predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mwjNf72ksoj2"
   },
   "outputs": [],
   "source": [
    "#Importing Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#Comparing the predictions against the actual observations in y_val\n",
    "cm = confusion_matrix(y_pred, y_val)\n",
    "\n",
    "#Printing the accuracy\n",
    "print(\"Accuracy of MLPClassifier : \", accuracy(cm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4g2b8_wDsrwZ"
   },
   "source": [
    "On executing the above code blocks you will get a pretty low score around the range of 40% to 45%. For a first timer, it’s a decent start, however, the model can be tweaked and tuned to improve the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fD68lYDPkZTw"
   },
   "source": [
    "# **Related Articles --**\n",
    "\n",
    "> * [Beginners Guide to MLP](https://analyticsindiamag.com/a-beginners-guide-to-scikit-learns-mlpclassifier/)\n",
    "> * [Beginners Guide to PyTorch](https://analyticsindiamag.com/a-beginners-guide-pytorch/)\n",
    "> * [Loss functions in PyTorch](https://analyticsindiamag.com/all-pytorch-loss-function/)\n",
    "> * [Loss functions in Tensorflow Keras](https://analyticsindiamag.com/ultimate-guide-to-loss-functions-in-tensorflow-keras-api-with-python-implementation/)\n",
    "> * [Loss function with examples](https://analyticsindiamag.com/loss-functions-in-deep-learning-an-overview/)\n",
    "> * [Optimizers in Tensorflow Keras](https://analyticsindiamag.com/guide-to-tensorflow-keras-optimizers/)\n",
    "> * [Deep Learning Frameworks](https://analyticsindiamag.com/deep-learning-frameworks/)\n",
    "> * [Types of Activation Functions](https://analyticsindiamag.com/most-common-activation-functions-in-neural-networks-and-rationale-behind-it/)\n",
    "> * [Maths for Deep Learning](https://analyticsindiamag.com/beginners-guide-neural-network-math-python/)\n",
    "> * [Deep Learning Using Tensorflow Keras](https://analyticsindiamag.com/deep-learning-using-tensorflow-keras/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uPI7f1EKrj2I"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPly9g83GXgqSuFoLUj4LoY",
   "collapsed_sections": [],
   "name": "2_Multi_Layer_Perceptron.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
