{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTkSTB8nY5-4"
   },
   "source": [
    "# PyTorch Metric Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ukYAqPy9Y7XQ"
   },
   "source": [
    "Metric Learning is defined as learning distance functions over multiple objects. PyTorch Metric Learning (PML) is an open-source library that eases the tedious and time-consuming task of implementing various deep metric learning algorithms. It was introduced by Kevin Musgrave and Serge Belongie of Cornell Tech and Ser-Nam Lim of Facebook AI in August 2020 (research paper).\n",
    "\n",
    "The flexible and modular design of the PML library enables the implementing various combinations of algorithms in the existing code. Several algorithms can also be combined for a complete train/test workflow. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xzxHnDCJY_cF"
   },
   "source": [
    "Required PyTorch version for PyTorch Metric Learning\n",
    "\n",
    "> * pytorch-metric-learning >= v0.9.90 requires torch >= 1.6\n",
    "> * pytorch-metric-learning < v0.9.90 does not have specific version requirement, but was tested with torch >= 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2m5UQhKxZC3b"
   },
   "source": [
    "# Practical implementation of PyTorch Metric Learning\n",
    "\n",
    "Hereâ€™s a demonstration of using TrainWithClassifier trainer of PML on CIFAR100 dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZeBBMtsZGGW"
   },
   "source": [
    "Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install pip --upgrade --user -q\n",
    "!python -m pip install numpy pandas seaborn matplotlib scipy sklearn statsmodels tensorflow keras --user -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ANR1IXynY1gL"
   },
   "outputs": [],
   "source": [
    "#Install PML\n",
    "!python -m pip install -q pytorch-metric-learning[with-hooks] --user -q\n",
    "#Install record keeper for logging information\n",
    "!python -m pip install record_keeper --user -q\n",
    "!python -m pip install umap-learn --user -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgcmnrc7ZJwW"
   },
   "source": [
    "  Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zL3Yqq49rdEU"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pytorch_metric_learning import losses, miners, samplers, trainers, testers\n",
    "from pytorch_metric_learning.utils import common_functions\n",
    "import pytorch_metric_learning.utils.logging_presets as logging_presets\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "from cycler import cycler\n",
    "import record_keeper\n",
    "import pytorch_metric_learning\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "logging.info(\"VERSION %s\"%pytorch_metric_learning.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iIS-W_evZj2N"
   },
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gjEUsC_btDRg"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    # layer_sizes[0] is the dimension of the input\n",
    "    # layer_sizes[-1] is the dimension of the output\n",
    "    def __init__(self, layer_sizes, final_relu=False):\n",
    "        super().__init__()\n",
    "        layer_list = []\n",
    "        layer_sizes = [int(x) for x in layer_sizes]\n",
    "        num_layers = len(layer_sizes) - 1\n",
    "        final_relu_layer = num_layers if final_relu else num_layers - 1\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            input_size = layer_sizes[i]\n",
    "            curr_size = layer_sizes[i + 1]\n",
    "            if i < final_relu_layer:\n",
    "                layer_list.append(nn.ReLU(inplace=False))\n",
    "            layer_list.append(nn.Linear(input_size, curr_size))\n",
    "        self.net = nn.Sequential(*layer_list)\n",
    "        self.last_linear = self.net[-1]\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIxL9lgEZmt3"
   },
   "source": [
    "Specify device on which torch.Tensor will be allocated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "040ZjYXjzr3m"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set trunk model and replace the softmax layer with an identity function\n",
    "trunk = torchvision.models.resnet18(pretrained=True)\n",
    "trunk_output_size = trunk.fc.in_features\n",
    "trunk.fc = common_functions.Identity()\n",
    "trunk = torch.nn.DataParallel(trunk.to(device))\n",
    "\n",
    "# Set embedder model. This takes in the output of the trunk and outputs 64 dimensional embeddings\n",
    "embedder = torch.nn.DataParallel(MLP([trunk_output_size, 64]).to(device))\n",
    "\n",
    "# Set the classifier. The classifier will take the embeddings and output a 50 dimensional vector.\n",
    "# (Our training set will consist of the first 50 classes of the CIFAR100 dataset.)\n",
    "# We'll specify the classification loss further down in the code.\n",
    "classifier = torch.nn.DataParallel(MLP([64, 50])).to(device)\n",
    "\n",
    "# Set optimizers\n",
    "trunk_optimizer = torch.optim.Adam(trunk.parameters(), lr=0.00001, weight_decay=0.0001)\n",
    "embedder_optimizer = torch.optim.Adam(embedder.parameters(), lr=0.0001, weight_decay=0.0001)\n",
    "classifier_optimizer = torch.optim.Adam(classifier.parameters(), lr=0.0001, weight_decay=0.0001)\n",
    "\n",
    "# Set the image transforms\n",
    "train_transform = transforms.Compose([transforms.Resize(64),\n",
    "                                    transforms.RandomResizedCrop(scale=(0.16, 1), ratio=(0.75, 1.33), size=64),\n",
    "                                    transforms.RandomHorizontalFlip(0.5),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "val_transform = transforms.Compose([transforms.Resize(64),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ghfe2hxuzxY7"
   },
   "outputs": [],
   "source": [
    "# Download the original datasets\n",
    "original_train = datasets.CIFAR100(root=\"CIFAR100_Dataset\", train=True, transform=None, download=True)\n",
    "original_val = datasets.CIFAR100(root=\"CIFAR100_Dataset\", train=False, transform=None, download=True)\n",
    "\n",
    "# This will be used to create train and val sets that are class-disjoint\n",
    "class ClassDisjointCIFAR100(torch.utils.data.Dataset):\n",
    "    def __init__(self, original_train, original_val, train, transform):\n",
    "        rule = (lambda x: x < 50) if train else (lambda x: x >=50)\n",
    "        train_filtered_idx = [i for i,x in enumerate(original_train.targets) if rule(x)]\n",
    "        val_filtered_idx = [i for i,x in enumerate(original_val.targets) if rule(x)]\n",
    "        self.data = np.concatenate([original_train.data[train_filtered_idx], original_val.data[val_filtered_idx]], axis=0)\n",
    "        self.targets = np.concatenate([np.array(original_train.targets)[train_filtered_idx], np.array(original_val.targets)[val_filtered_idx]], axis=0)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n",
    "    def __getitem__(self, index):            \n",
    "        img, target = self.data[index], self.targets[index]\n",
    "        img = Image.fromarray(img)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, target\n",
    "\n",
    "# Class disjoint training and validation set\n",
    "train_dataset = ClassDisjointCIFAR100(original_train, original_val, True, train_transform)\n",
    "val_dataset = ClassDisjointCIFAR100(original_train, original_val, False, val_transform)\n",
    "assert set(train_dataset.targets).isdisjoint(set(val_dataset.targets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nIUbyCOsz2wJ"
   },
   "outputs": [],
   "source": [
    "# Set the loss function\n",
    "loss = losses.TripletMarginLoss(margin=0.1)\n",
    "\n",
    "# Set the classification loss:\n",
    "classification_loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Set the mining function\n",
    "miner = miners.MultiSimilarityMiner(epsilon=0.1)\n",
    "\n",
    "# Set the dataloader sampler\n",
    "sampler = samplers.MPerClassSampler(train_dataset.targets, m=4, length_before_new_iter=len(train_dataset))\n",
    "\n",
    "# Set other training parameters\n",
    "batch_size = 32\n",
    "num_epochs = 4\n",
    "\n",
    "# Package the above stuff into dictionaries.\n",
    "models = {\"trunk\": trunk, \"embedder\": embedder, \"classifier\": classifier}\n",
    "optimizers = {\"trunk_optimizer\": trunk_optimizer, \"embedder_optimizer\": embedder_optimizer, \"classifier_optimizer\": classifier_optimizer}\n",
    "loss_funcs = {\"metric_loss\": loss, \"classifier_loss\": classification_loss}\n",
    "mining_funcs = {\"tuple_miner\": miner}\n",
    "\n",
    "# We can specify loss weights if we want to. This is optional\n",
    "loss_weights = {\"metric_loss\": 1, \"classifier_loss\": 0.5}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n8l_HZdY0AMP"
   },
   "outputs": [],
   "source": [
    "record_keeper, _, _ = logging_presets.get_record_keeper(\"example_logs\", \"example_tensorboard\")\n",
    "hooks = logging_presets.get_hook_container(record_keeper)\n",
    "dataset_dict = {\"val\": val_dataset}\n",
    "model_folder = \"example_saved_models\"\n",
    "\n",
    "def visualizer_hook(umapper, umap_embeddings, labels, split_name, keyname, *args):\n",
    "    logging.info(\"UMAP plot for the {} split and label set {}\".format(split_name, keyname))\n",
    "    label_set = np.unique(labels)\n",
    "    num_classes = len(label_set)\n",
    "    fig = plt.figure(figsize=(20,15))\n",
    "    plt.gca().set_prop_cycle(cycler(\"color\", [plt.cm.nipy_spectral(i) for i in np.linspace(0, 0.9, num_classes)]))\n",
    "    for i in range(num_classes):\n",
    "        idx = labels == label_set[i]\n",
    "        plt.plot(umap_embeddings[idx, 0], umap_embeddings[idx, 1], \".\", markersize=1)   \n",
    "    plt.show()\n",
    "\n",
    "# Create the tester\n",
    "tester = testers.GlobalEmbeddingSpaceTester(end_of_testing_hook = hooks.end_of_testing_hook, \n",
    "                                            visualizer = umap.UMAP(), \n",
    "                                            visualizer_hook = visualizer_hook,\n",
    "                                            dataloader_num_workers = 32)\n",
    "\n",
    "end_of_epoch_hook = hooks.end_of_epoch_hook(tester, \n",
    "                                            dataset_dict, \n",
    "                                            model_folder, \n",
    "                                            test_interval = 1,\n",
    "                                            patience = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_YSekeL5aQCG"
   },
   "source": [
    "Model trainer \n",
    "\n",
    "Since we have trunk model -> embedder model -> classifier architecture, we have used TrainWithClassifier trainer. It applies a metric loss and a classification loss to the utput of embedder network and classifier network output respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xrF-oZaE0HfS"
   },
   "outputs": [],
   "source": [
    "trainer = trainers.TrainWithClassifier(models,\n",
    "                                optimizers,\n",
    "                                batch_size,\n",
    "                                loss_funcs,\n",
    "                                mining_funcs,\n",
    "                                train_dataset,\n",
    "                                sampler=sampler,\n",
    "                                dataloader_num_workers = 32,\n",
    "                                loss_weights = loss_weights,\n",
    "                                end_of_iteration_hook = hooks.end_of_iteration_hook,\n",
    "                                end_of_epoch_hook = end_of_epoch_hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "urohdOS-0LJE"
   },
   "outputs": [],
   "source": [
    "#%load_ext tensorboard\n",
    "#%tensorboard --logdir example_tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W4oSRJ49aSav"
   },
   "source": [
    "Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JH7VrNsK0PBw"
   },
   "outputs": [],
   "source": [
    "trainer.train(num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AK9sb4xD0XDu"
   },
   "outputs": [],
   "source": [
    "# !pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WLozpwSbCna8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPAvobENHkDHrQqe8Veq+HE",
   "collapsed_sections": [],
   "name": "1_PyTorch_Metric_Learning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
