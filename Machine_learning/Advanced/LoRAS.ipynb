{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Gx9ExuCRT-8"
   },
   "source": [
    "# LoRAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wZIw9UYQRWo6"
   },
   "source": [
    "A common approach for overcoming this issue is generating synthetic instances of the minority class using an oversampling algorithm. SMOTE is a widely used oversampling technique. It selects an arbitrary minority class data point and its k nearest neighbours of the minority class. SMOTE then generates synthetic minority class data points along line segments joining these k nearest neighbours.  SMOTE, however, has several limitations, for example, it does not consider the distribution of minority classes and latent noise in a data set. \n",
    "\n",
    "SMOTE often over-generalizes the minority class, this leads to misclassifications of the majority class and affects the model’s overall balance.  In their paper, “LoRAS: An oversampling approach for imbalanced datasets” Saptarshi Bej, Narek Davtyan, et al. proposed Localized Randomized Affine Shadowsampling (LoRAS), which produces better machine learning models for imbalanced datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9yLmURNRYWX"
   },
   "source": [
    "To read about it more, please refer [this](https://analyticsindiamag.com/hands-on-guide-to-loras-a-better-oversampling-algorithm/) article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0iO9gYpFSba1"
   },
   "source": [
    "# **Comparing LoRAS with ADASYN, SMOTE, and its variants**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QrYZiIHySdtL"
   },
   "source": [
    "  Install LoRAS and imbalanced-learn from PyPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install pip --upgrade --user -q\n",
    "!python -m pip install numpy pandas seaborn matplotlib scipy sklearn statsmodels tensorflow keras --user -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NFQVObKvRJBN"
   },
   "outputs": [],
   "source": [
    "!python -m pip install -U imbalanced-learn --user -q\n",
    "!python -m pip install loras --user -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "REG5NQxzSlQv"
   },
   "source": [
    "Import necessary libraries and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PLJE7Wi9SjuK"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import loras\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, SVMSMOTE, ADASYN\n",
    " \n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score,    precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k_dj4l5CSrHm"
   },
   "source": [
    "We will be using the [Credit Card Fraud Detection dataset](https://www.kaggle.com/mlg-ulb/creditcardfraud) available on Kaggle. You can download it manually or fetch it using Kaggle’s API as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Uaj2eE0Ucmc"
   },
   "outputs": [],
   "source": [
    "filename='https://gitlab.com/AnalyticsIndiaMagazine/practicedatasets/-/raw/main/LoRAS/creditcard.csv'\n",
    "data=pd.read_csv(filename)\n",
    "data=data.values\n",
    "data.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZfPn4cRhUjEg"
   },
   "source": [
    "Separate the labels from features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O5vt9XQIUg8H"
   },
   "outputs": [],
   "source": [
    "labels, features = data[:,30], data[:,:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eeo3ngnUnLD"
   },
   "source": [
    "Divide the dataset into train and test set before oversampling. Never test on the oversampled or undersampled dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "13yYIDdwUk-b"
   },
   "outputs": [],
   "source": [
    "# fraud transactions\n",
    "label_1=np.where(labels == 1)[0]\n",
    "label_1=list(label_1)\n",
    "print((len(label_1)))\n",
    "features_1=features[label_1]\n",
    "features_1_train=features_1[list(range(0,246))]\n",
    "features_1_test=features_1[list(range(246,492))]\n",
    "\n",
    "# normal transactions\n",
    "label_0=np.where(labels == 0)[0]\n",
    "label_0=list(label_0)\n",
    "features_0=features[label_0]\n",
    "features_0_train=features_0[list(range(0,142157))]\n",
    "features_0_test=features_0[list(range(142157,284315))]\n",
    "\n",
    "training_data=np.concatenate((features_1_train,features_0_train))\n",
    "test_data=np.concatenate((features_1_test,features_0_test))\n",
    "training_labels=np.concatenate((np.zeros(246)+1, np.zeros(142157)))\n",
    "test_labels=np.concatenate((np.zeros(246)+1, np.zeros(142158))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibTCehcZUrM0"
   },
   "source": [
    "Oversample minority class using LoRAS and other methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LkX2KlUVUpuP"
   },
   "outputs": [],
   "source": [
    "min_class_points = features_1_train\n",
    "maj_class_points = features_0_train\n",
    "\n",
    "#LoRAS\n",
    "loras_min_class_points = loras.fit_resample(maj_class_points, min_class_points)\n",
    "print(loras_min_class_points.shape)\n",
    "LoRAS_feat = np.concatenate((loras_min_class_points, maj_class_points))\n",
    "LoRAS_labels = np.concatenate((np.zeros(len(loras_min_class_points))+1, np.zeros(len(maj_class_points))))\n",
    "\n",
    "#SMOTE\n",
    "sm = SMOTE(random_state=42, k_neighbors=30, sampling_strategy=1)\n",
    "SMOTE_feat, SMOTE_labels = sm.fit_resample(training_data,training_labels)\n",
    "print(SMOTE_feat.shape)\n",
    "print(SMOTE_labels.shape)\n",
    "\n",
    "#SMOTE Boderline\n",
    "smb = BorderlineSMOTE(random_state=42, k_neighbors=30)\n",
    "SMOTEb_feat, SMOTEb_labels = smb.fit_resample(training_data,training_labels)\n",
    "print(SMOTEb_feat.shape)\n",
    "print(SMOTEb_labels.shape)\n",
    "\n",
    "#SMOTE SVM\n",
    "sms = SVMSMOTE(random_state=42, k_neighbors=30)\n",
    "SMOTEs_feat, SMOTEs_labels = sms.fit_resample(training_data,training_labels)\n",
    "print(SMOTEs_feat.shape)\n",
    "print(SMOTEs_labels.shape)\n",
    "\n",
    "#ADASYN\n",
    "ada = ADASYN(random_state=42,n_neighbors=30)\n",
    "ADA_feat, ADA_labels = ada.fit_resample(training_data,training_labels)\n",
    "print(ADA_feat.shape)\n",
    "print(ADA_labels.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OxoB3Ef1UwIC"
   },
   "source": [
    "Create functions for creating and evaluating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-pKM2gjxUuqO"
   },
   "outputs": [],
   "source": [
    "def get_metrics(y_test, y_pred):\n",
    "    metrics = {}\n",
    "    metrics[\"f1_score\"] = f1_score(y_test, y_pred)\n",
    "    metrics[\"accuracy\"] = balanced_accuracy_score(y_test, y_pred)\n",
    "    metrics[\"precision\"] = precision_score(y_test, y_pred)\n",
    "    metrics[\"recall\"] = recall_score(y_test, y_pred)\n",
    "    return metrics\n",
    "\n",
    "def linear_regression(X_train, y_train, X_test, y_test):\n",
    "    logreg = LogisticRegression(random_state=42, C=.005, multi_class='multinomial', max_iter=685)\n",
    "    logreg.fit(X_train, y_train)\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    return get_metrics(y_test, y_pred)\n",
    "\n",
    "def random_forest(X_train, y_train, X_test, y_test):\n",
    "    det = RandomForestClassifier(n_estimators=100, max_depth=2,random_state=42)\n",
    "    det.fit(X_train, y_train)\n",
    "    y_pred = det.predict(X_test)\n",
    "    return get_metrics(y_test, y_pred) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wmY6GqTgU0sf"
   },
   "source": [
    "Train and evaluate models for different oversampling methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LG0q0FRRUzYH"
   },
   "outputs": [],
   "source": [
    "results_normal_lr = linear_regression(training_data, training_labels, test_data, test_labels)\n",
    "results_normal_rf = random_forest(training_data, training_labels, test_data, test_labels)\n",
    "\n",
    "results_loras_lr = linear_regression(LoRAS_feat, LoRAS_labels, test_data, test_labels)\n",
    "results_loras_rf = random_forest(LoRAS_feat, LoRAS_labels, test_data, test_labels)\n",
    "\n",
    "results_sm_lr = linear_regression(SMOTE_feat, SMOTE_labels, test_data, test_labels)\n",
    "results_sm_rf = random_forest(SMOTE_feat, SMOTE_labels, test_data, test_labels)\n",
    "\n",
    "results_sms_lr = linear_regression(SMOTEs_feat, SMOTEs_labels, test_data, test_labels)\n",
    "results_sms_rf = random_forest(SMOTEs_feat, SMOTEs_labels, test_data, test_labels)\n",
    "\n",
    "results_smb_lr = linear_regression(SMOTEb_feat, SMOTEb_labels, test_data, test_labels)\n",
    "results_smb_rf = random_forest(SMOTEb_feat, SMOTEb_labels, test_data, test_labels)\n",
    "\n",
    "results_ada_lr = linear_regression(ADA_feat, ADA_labels, test_data, test_labels)\n",
    "results_ada_rf = random_forest(ADA_feat, ADA_labels, test_data, test_labels)\n",
    "\n",
    "sampling_method = ['Normal', 'LoRAS','SMOTE','SMOTE SVM', 'SMOTE BORDELINE', 'ADASYN'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B-gbxckIU6O3"
   },
   "source": [
    "Plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0QnHs-HxU4Xw"
   },
   "outputs": [],
   "source": [
    "# linear regression results\n",
    "LR_results = [results_normal_lr, results_loras_lr, results_sm_lr, results_sms_lr, \n",
    "              results_smb_lr, results_ada_lr]\n",
    "LR_dict = dict(zip(sampling_method, LR_results))\n",
    "#create a DataFrame from the results dictionary\n",
    "LR_df = pd.DataFrame.from_dict(LR_dict, orient='index')\n",
    "# create a column for sampling methods\n",
    "LR_df['sampling_method'] = LR_df.index\n",
    "LR_df.plot(x='sampling_method', y=['f1_score', 'accuracy', 'precision', 'recall'],\n",
    "          kind=\"bar\", figsize=(12, 8), rot = 45,\n",
    "          title = \"Performance of Linear Regression models built with different Sampling Methods\")\n",
    "\n",
    "# random forest results\n",
    "RF_results = [results_normal_rf, results_loras_rf, results_sm_rf,\n",
    "            results_sms_rf, results_smb_rf, results_ada_rf]\n",
    "RF_dict = dict(zip(sampling_method, RF_results))\n",
    "#create a DataFrame from the results dictionary\n",
    "RF_df = pd.DataFrame.from_dict(RF_dict, orient='index')\n",
    "# create a column for sampling methods\n",
    "RF_df['sampling_method'] = RF_df.index\n",
    "RF_df.plot(x='sampling_method', y=['f1_score', 'accuracy', 'precision', 'recall'],\n",
    "          kind=\"bar\", figsize=(12, 8), rot = 45,\n",
    "          title = \"Performance of Random Forest models built with different Sampling Methods\") "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPbqrJO7+UDef8O+FEVv6ah",
   "collapsed_sections": [],
   "name": "1_LoRAS.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "bf1c1c88dcd4a5670b9a47bf2bba5adec14ec31820c4d35855d0349e55a0f49f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
