{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bxN56oCU67VV"
   },
   "source": [
    "# **Naive Bayes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zUOPSMDb7C8f"
   },
   "source": [
    "The Naive Bayes classification algorithm has been in use for a very long time, particularly in applications that require classification of texts. It is a probabilistic algorithm based on the popular Conditional Probability and Bayes Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2IyzYR0V7GWr"
   },
   "source": [
    "##**The Bayes Theorem**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D12ziLXJ7Lca"
   },
   "source": [
    "The Bayes theorem has various applications in Machine Learning, categorizing a mail as spam or important is one simple and very popular application of the Bayes classification.\n",
    "\n",
    "One of the simplest definitions of the Bayes Theorem is that it describes the probability of an event, based on prior knowledge of conditions that might be related to the event.\n",
    "\n",
    "The theorem is mathematically expressed as :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NahUNuN47Nl5"
   },
   "source": [
    "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAANAAAABBCAYAAACgniqSAAAQ4ElEQVR4nO2dfVBU1RvHnxm1qSExHHESX2Z9TykEE2U03J00JgnEl0XBSkRQUSSwdLKmvYs5vThJBlhmhjmpuasVmtak7MKMb5WWpmLmC4VIqWO+a2nsOd/fH869P5Z77764UMvvdz4zZwbuPffZc++e773nPud5zhIEAsFdQ/92AwSC1owQkEAQAEJAAkEACAEJBAEgBCQQBIAQkEAQAEJAAkEACAEJBAEgBPQ/BuccVqsV169fb1a7NpsNO3bsCMgG59zt/8rKShiNRjDGArKrxdWrVyFJks/1m7atsLAQpaWlXo8TAgpSOOcwm81KmTNnjvL33LlzcejQIdWXzhgDEWl2nGXLlinHZ2ZmYsGCBTCbzcjLy8PatWtx8eJFj+1ZvXo1tmzZctfns3LlShCRm1g450hISEBxcbHqXGQqKyuVdqelpaGgoED5X5IkNDQ06F4Hp9PpU9skSUJ8fLybHcYY7r33XlRVVXk8VggoSKmqqoLD4YDVagURwW63w+FwwOFwIDMzUxFK4w4pSRKMRiNcLpfKnt1uVzqx1WqFw+HA5s2bIUkSTCYToqOjPXa4srKyuxbQ5cuXMXDgQPTq1Uv1tLl06RJCQ0OxdetW3esgt1EWhcPhgNPpxJQpU5Tzadz5c3NzMXHiRJ/a5nQ6QUR49NFHVUKsqKhAv379cP78ed3jhYCCGM45hgwZgqFDh6o6XmFhISIiItDQ0ADgzh3TaDTC4XDo2rPZbCAiHDx40G37yZMnQUTIycnRfRIEIiBJkmAwGBASEqI5XCsuLkZ6erruZzPGEBUVhcGDB6vqpKamIiIiQrlp1NXVYfjw4cp18QTnHMnJyTAYDOjfv7/KNuccGRkZeP/993VtCAEFMYwxhISEYNasWaovNysrC0SEb775BgCwZcsWREREeHyfMJvNICLVE+q7774DEWHKlCm6x96tgHbv3o2wsDDcvn0bRIRLly6p6jDG0KVLF9y4cUPTxrfffgsiwsKFC922c84xY8YMt+sgSRKSkpJ8atuLL76IvLw8JCYmomvXrprXzul0wmg06opbCCiI2b9/P4gI7777rtv269evIzo6GpGRkbh27RoYY5g+fTrmzp2ra4tzju7du2PQoEGqsf7MmTNBRNi7d6/u8R9++KHfAuKcw2g0YvXq1Vi6dCmICD/++KNmvd69e+PAgQOadhYvXgwiUjkxXC4XoqKiEB0drVyH2NhYbNq0yWvbGGNIS0vDiRMnkJeXhw4dOmgK6OTJk+jRo4fmsBgQAgpqlixZotxd5U7POYfFYnHrjIwxhIeHY+nSpbq2/vjjDxARnnvuOeUdori4GAaDAbm5ufj5559177LA3Qlo165diuOgqKgIRISdO3dq1h05ciTsdrvmMOrxxx+HwWBwcxgwxmC1WtGpUydcvXoVwB1BhYSE4Pvvv/fatuLiYkyYMAHAnadWmzZtNEXy119/gYhw5swZTTtCQEEKYwwJCQkgIsTExMBgMCA0NBQpKSmYPn262wu/y+UCEeGjjz7StedwOEBEeOGFF5CVlQWz2YyMjAwYDAYsWbLEo3gA/wXEOcfkyZMVL9Znn30GIsKnn36qWT8tLQ2LFi1SPQXkczOZTHjkkUfQrVs33HfffYiKikJ+fr5bpz979iyICL/++qvHttXX1yM1NVX5LEmSQESoqanRPI8uXbqgsrJS05YQUJDy+++/g4gUr1pDQwMYY2CM6bpt9TxZADBv3jzNO+nhw4cVYXnCXwHNmTMHr7/+OpxOJ5xOJyoqKkBEui/k8+bNQ2pqqurc9u3bByLCrFmzwBiDy+XSvQ7ykNfTHBjnHA8++CAqKiqUtskC0rp+nHMMHjwYy5cv17QnBBSkrFmzBkTk02QeYwydO3fGtm3bNPdzztGvXz8kJSWpOt25c+dARCAij0+hDz74wGcBXb16Fe3atUOHDh3Qq1cvDB06FImJiSAiLF68WPOYgoICzZf1FStWgIhQVlbm9XPlm4EnAZWVlYGI0KlTJ/Tv3x8jRozA2LFjQUR48803VfU554iOjtadlBUCClJycnJARDh06JDXui6XC6NGjdIdwskiWbFihWqf3EFnzJjRLALinCMnJwfvvfee23b5KZmVlaX5OZMmTVIJSJ5MJiKcOnXK62ffvn0bbdq00R3Ccc4RHx+Py5cvu22Xh7daIuGco3PnzkJArQnZe9V05t5T/fz8fF0ngtxBGr83cc5RU1ODMWPGaLq2m+KLgDjnWLVqlebTTBaQnkt4xIgRMJvNfh3TFMYY+vfvr+lEuHXrFqxWK4xGo2qfPJmqJZLr1697HAkIAQUZkiQhJSVFGVaZTCZYrVaPx3DOUVpaitzcXLftNpsNWVlZyiz+2LFjkZeXB4vFgmnTpqF9+/bIzs72adLRm4CcTqfi9HjooYfc2ix3XPl8zGazWyfnnKNXr15YuXKl23WQ2y0f4y0WjzGG9PR02O12t+1bt26FwWBQrmlhYaFb2+R9ycnJMJvNbmKtrq72OBL4RwRUWVmpOqlAuXnzJlatWtWsNoE7F7Qlght95YsvvsDWrVuxYcMGbNiwATabzae779dff41u3bq5tb26uhrbt2+HzWbTLDdv3vTJNuBdQFVVVUp7bTYbjh49quyz2+1u+5q6q2tqanDPPfe4ecEqKyuV+vKxvmCxWDBhwgQ3+5WVlYrDoGm4kt1ud/uMpv20vLwcw4YN0+0Tfgmo8cVvfEFsNhsOHDigOQxwOBy4//77ceXKFa/2GWMYNmwYvvzyS6916+vr0bNnT5/aferUKSWOrHGR297Yo1NYWAiTyeR1SBNsMMbQt29fbN68uUXs++NE8JeMjAxMnTrVZzF74syZMwgLC0NdXV3AtuRQKk9R3X4JKD8/H7m5uejYsSOsViskSVLKkCFDkJKSgsOHDyv1r127hsjISJSXl/tkf/Xq1SAirFmzxmvdM2fOeJx5b4zNZkNmZiYSEhJgMBhgtVphsVggSRIyMjIQERGhDDk45xg5ciQkSWqWL/SfRJIkPPXUUy3yBG0pAdntdvTp00dzDuZukSQJmZmZAdvJyMjAuHHjPF5Pv4dwH3/8saZbUZ7wahwhLEkSLBaLT1/okSNHMGrUKBAR3nrrLa/1/REQANy4cQNEhPHjx6uE0a9fP7cX9q+++gqhoaG6s8/BCmMM2dnZKCoqanbbLSEgzrnHydW7hTGGAQMGYNeuXXdto6amBpGRkThx4oTHen4LKCMjA0SkMnz8+HEQERITE8E5V4Zjvro+Bw4cqHiL5s+f7/WYuro6vwR08OBBTeFzzhEeHg4iwrFjx5RtSUlJsFgsPtsPFuQQl+bG4XBgz549zWpTTtloCRhjfiXUNaWwsNCnEYhfApIn5MLDw1VPleLiYjdX4KFDh0BEXhO1gDuThtnZ2Th27BiICM8++6zXY/wV0IEDB0BEqtyOjRs3goiQm5vrdsHy8/ORnp7+rzoUBMGPXwK6cuWK4g5tzN69e9G9e3cMHjxY6XAlJSXo3r27VxVzzjFx4kQ4HA5lGPjEE0947binT5/2WUCccxQUFCj5M3JoTEFBAUJDQ/H222+r2llaWoqYmBiP7ZCftL6U1uaUEPiGXwKSh1jLli3Djh07MHPmTMTExCiz3HJn45xj9uzZGD16tFebJSUlGDNmDID/Tpw1DbnXwh8BNX4/S09PR2xsLMLCwhAXF4f6+nrNeRCn04m2bdvi9u3bunbLysowcuRIj8VoNMJoNGLBggU+tVXQuvBLQLm5uSAiVFRUKC7gCxcuqO7ScqbfnDlzPNo7fvw4EhIS3FzLUVFR6Nq1q1cB1dbW+iwgOSBR6/1n4MCBMJlMqnOQw1+qq6t17XLONYvsFm9aPFFUVIRXX31VlFZQ9u3bp3xvPguIc44+ffqgR48e+PPPP73WTU1N9SggOc5JvkPLxWQyoV27dl6HcP4ISI73On36tGqfHInbNFxdFtD+/fs9noM/xRNFRUVYuHChKK2g3JWAzp8/DyJCRkaG187NGMOiRYs8DuFKS0uVnIzGd+5x48aBiPDbb795/AxfBSTntTfOm5eRh3ZEhHPnzrntk+Ojzp49q2t706ZNqhuAXpk6darXtgpaHz4LaOfOnSAin9JlgTuTl3pOBM45IiIi3JQsI684481l6quAGGMwGAxISkpSLakkZ3YuX75c04kQEhLi8eXfHyeC8Ob9b+JVQHa7HS+//DJSU1OVQDxf5hl++OEHEJFb6DhjDBaLBaGhoSAijBs3Ttl35MgRmM1m5Qn0zDPP4Pnnn9e1701A8gKD8rJQjSMn5G1xcXFYv369psjz8/MRGxsrOr7AI14FVF1dDZvNpgTiORwO3fTWxty8eRMRERHYvn272/by8nLdwL2mcXYbN27Ute/LE8hT7F5tba3u00WeSA1kIu7/GcZYQBOkVVVVzR583FK0aDT2+PHjNbP8mgN/nAj+snnzZnTu3LlZAhJbM40jouWyceNG5YaqdQNijGH8+PGq3B4AKls2mw3btm2DzWbDqVOnlJGALw6cYKFFBVRfX4/hw4dj9+7dzW67JQUUFxeH2bNnt4jt1kRVVZXiGZXn0V555RVYLBaYTCZERka6BQ8Dd9IJMjMzNac2zGYzkpOTQUSYNm0aLBaLEtQrO6hke6WlpZrTC8FGi+cD2e12n9MZ/KG2thYPPPBAs9oE7uQDtVREc2tEXhNAK93aZDKhY8eOyrWqq6tDWFiYx/Tr+fPng4hUwispKXELBZPTr7XS0IOJfyShzm63N/uY9qeffvJpwQ1/SU1NVYJKBf8NEs7OznbbLguo6aqgkyZN0rXFOUdKSgoiIyNVN6h169YpWaEy5eXlePjhh4M6rUSkdAs88s4774CIVIl6LpcLBoPBbXXU2NhYj44fxhhiYmJU62AzxjB69GgQkVvmaW1tLYjILbs12BACEujCOceTTz7ptoi9vF1OfpTXCnC5XAgPD/e4KujFixdBRCgpKVHWd9u/fz8mTpyI0aNHY8+ePaphYpcuXfD555+33EkGiBCQQBc5UsNgMCAnJwdWqxVpaWkYMmQI4uLi3NYXuHDhgtdVQWVnwYABA9C1a1e0b98eRIT169fj77//1jwmPj4er732WtC+kwoBCXSRkxATExOxadMmZS7t9OnTqvcSOd9Kb1FDzjkee+wxGAwGuFwutxhBOVZxw4YNquNmzZqFyZMnB+17kBCQQBd5ddS1a9d6rSsnUOr9RIk8fHv66adVYmhoaAARITU1VXVcTk4OkpOTxRNI0LqQc7o6derk07pxt27dQtu2bTUj3gFg27ZtugsU5ufna2YFA4DJZMLs2bOFgAStC/knU4YPH+7zqqB9+/ZV/fqdjPxTLU0XKDx69KjynqU1+dqjRw+88cYbd38iLYwQkEBF44DbSZMmIT093evaFvKqoE0XLpSDeCMjI5WJUrnEx8eDiDBixAjNsCA5heaTTz5p1vNrToSABCoa//SH0+n0KXgYuCOWrKwst21yrJtWcTqd+OWXX3SHZ3IKjVbaS7AgBCRoNurr69G7d2+f3pl8wWw2Izs7O2g9cIAQkKAZ4ZxDkiS89NJLAdtat24dBg0a5DUz+d9GCEjQrLhcLkRERKiCRf2Bc46ePXt6/Hn5YEEISNDsHDt2LKBkxMrKSreg0mBGCEggCAAhIIEgAISABIIAEAISCAJACEggCAAhIIEgAISABIIAEAISCAJACEggCAAhIIEgAISABIIAEAISCALgP2z0mXyzDAhsAAAAAElFTkSuQmCC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlx_X2ZY7f5f"
   },
   "source": [
    "Where **A**and **B** are events and **P(B)** is never zero :\n",
    "\n",
    "**P(A|B)** is the likelihood of event **A** occurring given that **B** is true.\n",
    "\n",
    "**P(B|A)** is the likelihood of event **B** occurring given that **A** is true.\n",
    "\n",
    "**P(A)** and **P(B)** are the probabilities of observing **A** and **B** independently of each other.\n",
    "\n",
    "Click [here](https://analyticsindiamag.com/what-is-a-naive-bayes-classifier-and-what-significance-does-it-have-for-ml/) for more explanation and examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rmONdnZw77bt"
   },
   "source": [
    "## **Lets Code!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R1EyRiQR7-Kl"
   },
   "source": [
    "### **Getting the train_dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fB6bJ8hm8HnA"
   },
   "source": [
    "In the following code section, we will use a classification train_dataset from [Machinehackâ€™s Predict The train_data Scientists Salary In India](https://machinehack.com/hackathons/predict_the_train_data_scientists_salary_in_india_hackathon/) Hackathon.\n",
    "\n",
    "To get the train_dataset, head to Machinehack, Sign up, start the hackathon and download the train_dataset from the hackathons page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install pip --upgrade --user -q \n",
    "!python -m pip install numpy pandas seaborn matplotlib scipy statsmodels sklearn --user -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PobTiUvpapaZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#Load train train_data\n",
    "train_data = pd.read_csv(\"Naive_Bayes_Final_Train_Dataset.csv\")\n",
    "train_data = train_data[['company_name_encoded','experience', 'location', 'salary']]\n",
    "\n",
    "\n",
    "#Load Test train_data\n",
    "test_data = pd.read_csv(\"Naive_Bayes_Final_Test_Dataset.csv\")\n",
    "test_data = test_data[['company_name_encoded','experience', 'location']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eVWDO7KjDfGH"
   },
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_P6vwfPxEkWl"
   },
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8n0c4roEm-I"
   },
   "source": [
    "### **Exploring The Training train_dataset**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dkygd9TDFbmS"
   },
   "outputs": [],
   "source": [
    "print(\"#\"*30)\n",
    "print(\"\\nFeatures/Columns : \\n\", train_data.columns)\n",
    "print(\"#\"*30)\n",
    "print(\"\\n\\nNumber of Features/Columns : \", len(train_data.columns))\n",
    "print(\"#\"*30)\n",
    "print(\"\\nNumber of Rows : \",len(train_data))\n",
    "print(\"#\"*30)\n",
    "print(\"\\n\\nData Types :\\n\", train_data.dtypes)\n",
    "print(\"#\"*30)\n",
    "print(\"\\nContains NaN/Empty cells : \", train_data.isnull().values.any())\n",
    "print(\"#\"*30)\n",
    "print(\"\\nTotal empty cells by column :\\n\", train_data.isnull().sum(), \"\\n\\n\")\n",
    "print(\"#\"*30)\n",
    "print(\"\\n\\nNumber of Unique Locations : \", len(train_data['location'].unique()))\n",
    "print(\"#\"*30)\n",
    "print(\"\\n\\nNumber of Unique Salaries : \", len(train_data['salary'].unique()))\n",
    "print(\"#\"*30)\n",
    "print(\"\\n\\nUnique Salaries:\\n\", train_data['salary'].unique())\n",
    "print(\"#\"*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUPeaULlFun7"
   },
   "source": [
    "The above code block is to help us understand the kind of data we are dealing with such as the number of records or samples, number of features, presence of missing values, unique classes etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b8yzgyhTFyBP"
   },
   "source": [
    "### **Cleaning The training Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nE7u1Dk0IT2S"
   },
   "source": [
    "Now let us clean up the training data.\n",
    "\n",
    "We can see that the experiences are given in strings, so lets convert them to integers in a logical way by splitting it in to minimum experience (minimum_exp)  and maxim experience (maximum_exp).Also we will label encode the categorical features location and salary. We will then delete the original experience column, attach the new ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iibu75ReFxIu"
   },
   "outputs": [],
   "source": [
    "#Cleaning the experience\n",
    "exp = list(train_data.experience)\n",
    "min_ex = []\n",
    "max_ex = []\n",
    "\n",
    "for i in range(len(exp)):\n",
    "  exp[i] = exp[i].replace(\"yrs\",\"\").strip()\n",
    "  min_ex.append(int(exp[i].split(\"-\")[0].strip()))\n",
    "  max_ex.append(int(exp[i].split(\"-\")[1].strip()))\n",
    "#Label encoding location and salary\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "train_data['location'] = le.fit_transform(train_data['location'])\n",
    "train_data['salary'] = le.fit_transform(train_data['salary'])\n",
    "\n",
    "#Attaching the new experiences to the original dataset\n",
    "train_data[\"minimum_exp\"] = min_ex\n",
    "train_data[\"maximum_exp\"] = max_ex\n",
    "\n",
    "#Deleting the original experience column and reordering\n",
    "train_data.drop(['experience'], inplace = True, axis = 1)\n",
    "train_data = train_data[['company_name_encoded', 'location','minimum_exp', 'maximum_exp', 'salary']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJjKDwnSQGe2"
   },
   "source": [
    "After executing all the above code blocks our new dataset will look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cladN061QHZ3"
   },
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5a0lgsIHIzli"
   },
   "source": [
    "### **Cleaning the Testing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HDY-V7eOFtYP"
   },
   "outputs": [],
   "source": [
    "#Cleaning the experience\n",
    "exp = list(test_data.experience)\n",
    "min_ex = []\n",
    "max_ex = []\n",
    "\n",
    "for i in range(len(exp)):\n",
    "  exp[i] = exp[i].replace(\"yrs\",\"\").strip()\n",
    "  min_ex.append(int(exp[i].split(\"-\")[0].strip()))\n",
    "  max_ex.append(int(exp[i].split(\"-\")[1].strip()))\n",
    "#Label encoding location\n",
    "test_data['location'] = le.fit_transform(test_data['location'])\n",
    "#train_data['salary'] = le.fit_transform(train_data['salary'])\n",
    "\n",
    "#Attaching the new experiences to the original dataset\n",
    "test_data[\"minimum_exp\"] = min_ex\n",
    "test_data[\"maximum_exp\"] = max_ex\n",
    "\n",
    "#Deleting the original experience column and reordering\n",
    "test_data.drop(['experience'], inplace = True, axis = 1)\n",
    "test_data = test_data[['company_name_encoded', 'location','minimum_exp', 'maximum_exp']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCeJiv8xQMmw"
   },
   "source": [
    "### **Feature Scaling of Training Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PMVXQIfJQRSo"
   },
   "source": [
    "We will now scale all the numerical features in the dataset except the target variable which is salary(category)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kZ0QYU_EQL6x"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "train_data[['company_name_encoded', 'location', 'minimum_exp', 'maximum_exp']] = sc.fit_transform(train_data[['company_name_encoded', 'location', 'minimum_exp', 'maximum_exp']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ec_0zK75QbTa"
   },
   "source": [
    "### **Feature Scaling of Testing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SfkJo0LBFtDr"
   },
   "outputs": [],
   "source": [
    "test_data[['company_name_encoded', 'location', 'minimum_exp', 'maximum_exp']] = sc.fit_transform(test_data[['company_name_encoded', 'location', 'minimum_exp', 'maximum_exp']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jn-Bxc5JQZrk"
   },
   "source": [
    "### **Creating training and validation sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MVwjOfMmQk4t"
   },
   "outputs": [],
   "source": [
    "#Splitting the dataset into  training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "training_set, validation_set = train_test_split(train_data, test_size = 0.2, random_state = 21)\n",
    "#classifying the predictors and target variables as X and Y\n",
    "X_train = training_set.iloc[:,0:-1].values\n",
    "Y_train = training_set.iloc[:,-1].values\n",
    "X_val = validation_set.iloc[:,0:-1].values\n",
    "y_val = validation_set.iloc[:,-1].values\n",
    "X_test = test_data.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4OovgWoPQ4p4"
   },
   "source": [
    "### **Measuring the Accuracy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VhjSxflTQ9VH"
   },
   "source": [
    "We will use confusion matrix to determine the correct number of predictions. The accuracy is measured as the total number of correct predictions divided by the total number of predictions. We will define a function to calculate and return the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YxDjvDezQ6Mm"
   },
   "outputs": [],
   "source": [
    "def accuracy(confusion_matrix):\n",
    "  diagonal_sum = confusion_matrix.trace()\n",
    "  sum_of_all_elements = confusion_matrix.sum()\n",
    "  return diagonal_sum / sum_of_all_elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVqvk98SRA9b"
   },
   "source": [
    "### **Initialising the Naive Bayes Classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rbt0lVwWRE_T"
   },
   "source": [
    "We now have all the data ready to be fitted to the Bayesian classifier. In the below code block we will initialize the Naive Bayes Classifier and fit the training data to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-id8qnWIRHO_"
   },
   "outputs": [],
   "source": [
    "#Importing the library\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#Initializing the classifier\n",
    "classifier = GaussianNB()\n",
    "#Fitting the training data\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FMmSopxBRINL"
   },
   "source": [
    "###**Predicting for the validation set**\n",
    "\n",
    "\n",
    "The below code will store the predictions returned by the predict method into y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BO66GfuzROl5"
   },
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I43IbeuNRTGF"
   },
   "source": [
    "Generating the confusion matrix and printing the accuracy\n",
    "\n",
    "The below-given code block will generate a confusion matrix from the predictions and the actual values of the validation set for salary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0_whsQ4SRRms"
   },
   "outputs": [],
   "source": [
    "#Generating the confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "print(\"__ACCURACY = \", accuracy(cm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iN8370o1RYM-"
   },
   "source": [
    "The Naive Bayesian classifier when fitted with the given data gave an accuracy of 38%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nMov6sRvRvIe"
   },
   "source": [
    "### **Prediction on Test Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DcZv9VNkRgaq"
   },
   "outputs": [],
   "source": [
    "y_test= classifier.predict(X_test)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3wpbdfa6aVF"
   },
   "source": [
    "Related Articles:\n",
    "\n",
    "\n",
    "> * [Naive Bayes from Scratch](https://analyticsindiamag.com/understanding-naive-bayes-classifier-from-scratch/)\n",
    "> * [Naive Bayes Algorithm](https://analyticsindiamag.com/a-hands-on-introduction-to-naive-bayes-classification-in-python/)\n",
    "> * [Significance of Naive Bayes](https://analyticsindiamag.com/what-is-a-naive-bayes-classifier-and-what-significance-does-it-have-for-ml/)\n",
    "> * [Comparison with other Classification Algorithms](https://analyticsindiamag.com/hands-on-guide-to-predict-fake-news-using-logistic-regression-svm-and-naive-bayes-methods/)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO9qvYoHhAOYVupix+jRnDW",
   "collapsed_sections": [],
   "name": "2_Naive_Bayes_Custom_Data.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
