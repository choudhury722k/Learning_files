{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NaiveBayesClassification_IRIS_DATA.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"}},"cells":[{"cell_type":"markdown","metadata":{"id":"5oOhyXwpAVOD"},"source":["# In this practice session, we will learn to code Naive Bayes Classifier. \n","# We will perform the following steps to build a simple classifier using the popular Iris dataset.\n","\n"," \n"," \n","  - **Data Preprocessing**\n","\n","    - Importing the libraries.\n","    - Importing dataset (Dataset Link https://archive.ics.uci.edu/ml/datasets/iris).\n","    - Dealing with the categorical variable.\n","    - Classifying dependent and independent variables.\n","    - Splitting the data into a training set and test set.\n","    - Feature scaling.\n"," \n","\n","  -  **Naive-Bayes Classification**\n","\n","    - Create a Naive-Bayes classifier.\n","    - Feed the training data to the classifier.\n","    - Predicting the species for the test set.\n","    - Using the confusion matrix to find accuracy."]},{"cell_type":"markdown","metadata":{"id":"BWKv2y7UAVOM"},"source":["# Load the Dependencies"]},{"cell_type":"code","metadata":{"id":"n7eL6tNZAVON"},"source":["import ipywidgets as widgets\n","from IPython.display import display\n","\n","style = {'description_width': 'initial'}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6BZ-jLOunczC"},"source":["#1 Importing essential libraries\n","import pandas as pd\n","import numpy as np\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","from sklearn.datasets import load_iris\n","import seaborn as sns\n","iris = load_iris() \n","data = iris.data \n","target = iris.target \n","names = iris.target_names"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3ZAvevNQAVOR"},"source":["# Load the Dataset"]},{"cell_type":"code","metadata":{"id":"WKtERLr9n09B"},"source":["#file_name = 'iris.data'\n","\n","dataset = pd.DataFrame(data, columns=['sepal length', 'sepal width', 'petal length', \"petal width\"])\n","dataset['Species']=target\n","dataset.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0HK0w-4CAVOT"},"source":["print(f\"Dataset has {dataset.shape[0]} rows and {dataset.shape[1]} columns.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g9qXmgIzAVOU"},"source":["#Plotting the relation between salary and experience\n","wig_col = widgets.Dropdown(\n","                options=[col for col in dataset.columns.tolist() if col.startswith(('sepal', 'petal'))],\n","                description='Choose a Column to Plot vs. Attributes',\n","                disabled=False,\n","                layout=widgets.Layout(width='40%', height='40px'),\n","                style=style)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"URjJyWJ0AVOV"},"source":["# Plot Variables"]},{"cell_type":"code","metadata":{"id":"Tjp1190RAVOV"},"source":["display(wig_col)\n","\n","sns.catplot(x=\"Species\", y=wig_col.value, kind=\"boxen\", data=dataset, height=8.27, aspect=11.7/8.27);"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gmaZoIrWAVOW"},"source":["g = sns.catplot(x=\"Species\", y=wig_col.value, kind=\"violin\", inner=None, data=dataset, height=8.27, aspect=11.7/8.27)\n","sns.swarmplot(x=\"Species\", y=wig_col.value, color=\"k\", size=3, data=dataset, ax=g.ax);\n","\n","display(wig_col)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G5WuUWRFn4j8"},"source":["#3 classify dependent and independent variables\n","X = dataset.iloc[:,:-1].values  #independent variable YearsofExperience\n","y = dataset.iloc[:,-1].values  #dependent variable salary"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-bZ82kVbn7Ga"},"source":["print(\"\\nIdependent Variable (Sepal and Petal Attributes):\\n\\n\", X[:5])\n","print(\"\\nDependent Variable (Species):\\n\\n\", y[:5])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vm1bzGV9AVOY"},"source":["# Encode Classes"]},{"cell_type":"code","metadata":{"id":"oE1nYhxLAVOZ"},"source":["from sklearn.preprocessing import LabelEncoder\n","labelencoder = LabelEncoder()\n","dataset['Species'] = labelencoder.fit_transform(dataset['Species'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"owYFm7MPAVOZ"},"source":["dataset['Species'].unique()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D3BEWxWTAVOa"},"source":["# Create Train and Test Sets"]},{"cell_type":"code","metadata":{"id":"BFMIwI5Zn9MX"},"source":["#4 Creating training set and testing set\n","from sklearn.model_selection import train_test_split\n","test_size = widgets.FloatSlider(min=0.01, max=0.6, value=0.2, description=\"Test Size :\", tooltips=['Usually 20-30%'])\n","display(test_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uLGadE5vAVOb"},"source":["#Divide the dataset into Train and Test sets\n","X_train, X_test, y_train, y_test = train_test_split(X ,y, test_size=test_size.value, random_state = 0) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YcY06YGDn_dz"},"source":["print(\"Training Set :\\n----------------\\n\")\n","print(\"X = \\n\", X_train[:5])\n","print(\"y = \\n\", y_train[:5])\n","\n","print(\"\\n\\nTest Set :\\n----------------\\n\")\n","print(\"X = \\n\",X_test[:5])\n","print(\"y = \\n\", y_test[:5])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ErQQm4CvAVOc"},"source":["print(f\"Shape of Training set is {X_train.shape}\")\n","print(f\"Shape of Testing set is {X_test.shape}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j1HrDnLoAVOc"},"source":["# Normalise Features\n","\n","As the Features are not in the range of 0-1, Let's normalize the features using Standard Scaler(Z-score) normalization and Label Encode the Class String Names."]},{"cell_type":"code","metadata":{"id":"YqBGDORoAVOc"},"source":["#Feature scaling\n","from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()\n","\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test) \n","\n","print(\"\\n-------------------------\\nDataset after Scaling:\\n-------------------------\\n\", )\n","\n","print(\"\\nX_train :\\n\", X_train[:5])\n","print(\"-------------------------\")\n","print(\"\\nX_test :\\n\", X_test[:5])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H6Y_W5-VAVOc"},"source":["# Naive-Bayes Classifier"]},{"cell_type":"code","metadata":{"id":"kZEdiaZeAVOd"},"source":["# import Naive-Bayes library\n","from sklearn.naive_bayes import GaussianNB"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gcNKBxfvAVOd"},"source":["# Predict and Evaluate the Model "]},{"cell_type":"code","metadata":{"id":"8XbYFyk8oCrH"},"source":["classifier = GaussianNB()\n","\n","#Feed the training data to the classifier\n","classifier.fit(X_train,y_train)\n","\n","#Predicting the species for test set\n","y_pred = classifier.predict(X_test)\n","\n","print(\"\\n---------------------------\\n\")\n","print(\"Predicted Values for Test Set :\\n\",y_pred)\n","print(\"\\n---------------------------\\n\")\n","print(\"Actual Values for Test Set :\\n\",y_test)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZAwiJVWuoHEX"},"source":["#8 Claculating the Accuracy of the predictions\n","from sklearn import metrics\n","print(\"Prediction Accuracy = \", metrics.accuracy_score(y_test, y_pred))\n","\n","#9 Comparing Actual and Predicted Salaries for he test set\n","print(\"\\nActual vs Predicted Salaries \\n------------------------------\\n\")\n","error_df = pd.DataFrame({\"Actual\" : y_test,\n","                         \"Predicted\" : y_pred})\n","\n","error_df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vKIxFSCaAVOe"},"source":["# Actual vs. Predicted "]},{"cell_type":"code","metadata":{"id":"NK0BD7qUAVOe"},"source":["#Using confusion matrix to find the accuracy\n","from sklearn.metrics import confusion_matrix, classification_report\n","cm = confusion_matrix(y_test,y_pred)\n","\n","accuracy = cm.diagonal().sum()/cm.sum()\n","\n","print(\"\\n---------------------------\\n\")\n","print(\"Accuracy of Predictions = \",accuracy)\n","\n","print(\"\\n---------------------------\\n\")\n","print(classification_report(y_test, y_pred))"],"execution_count":null,"outputs":[]}]}