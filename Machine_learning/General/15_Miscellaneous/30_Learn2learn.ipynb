{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"1_Learn2learn.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPhylAFHquOmcYEtWlKC5VT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# learn2learn: A Library For Meta-Learning Research "],"metadata":{"id":"dPY0QTILGYLW"}},{"cell_type":"markdown","source":["learn2learn is a software library designed for meta-learning research. It was introduced by Sebastien M. R. Arnold from University of Southern California, Praateek Mahajan from Iterable Inc., Debajyoti Datta from University of Virginia, Ian Bunner from University of Waterloo and Konstantinos Saitas Zarkias from KTH Royal Institute of Technology and Research Institute of Sweden (RISE) in the year 2020 (research paper)."],"metadata":{"id":"s9qEvxoSGiQZ"}},{"cell_type":"markdown","source":["To know more about it, please refer [this](https://analyticsindiamag.com/guide-to-learn2learn-a-library-for-meta-learning-research/) article."],"metadata":{"id":"wfzxkmAJGjGn"}},{"cell_type":"markdown","source":["# Practical Implementation"],"metadata":{"id":"ZSPS4WEUJ-Hr"}},{"cell_type":"markdown","source":["Hereâ€™s a demonstration of few-shot learning using MAML wrapper for fast-adaptation. MAML (Model-Agnostic Meta-Learning) is a model-agnostic algorithm for meta-learning i.e. it is compatible with any kind of model trained using gradient descent and is applicable to a wide range of tasks such as reinforcement learning, classification and regression. (MAML research paper). The code uses the benchmark interface for loading the mtini-ImageNet dataset.\n"],"metadata":{"id":"p6HuMye0KAyf"}},{"cell_type":"markdown","source":["Clone the learn2learn GitHub repository"],"metadata":{"id":"i6f1ZwqEJ9_6"}},{"cell_type":"markdown","source":["And install the learn2learn library using pip command"],"metadata":{"id":"eAbqVA90KG5L"}},{"cell_type":"code","execution_count":null,"source":["!python -m pip install pip --upgrade --user -q\n","!python -m pip install numpy pandas seaborn matplotlib scipy sklearn statsmodels tensorflow keras --user -q"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["!git clone https://github.com/learnables/learn2learn\n","!pip install learn2learn"],"outputs":[],"metadata":{"id":"ApQUTVI7QukI"}},{"cell_type":"code","execution_count":null,"source":["import IPython\n","IPython.Application.instance().kernel.do_shutdown(True)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["Import the required libraries"],"metadata":{"id":"Sy5G_KGYKMob"}},{"cell_type":"code","execution_count":null,"source":["import random\n","import numpy as np\n","\n","import torch\n","from torch import nn, optim\n","\n","import learn2learn as l2l\n","from learn2learn.data.transforms import (NWays,\n","                                         KShots,\n","                                         LoadData,\n","                                         RemapLabels,\n","                                         ConsecutiveLabels)\n","\n","#Define a function for computing model accuracy\n","\n","def accuracy(predictions, targets):\n","    predictions = predictions.argmax(dim=1).view(targets.shape)\n","    return (predictions == targets).sum().float() / targets.size(0)\n","# Define a method for fast adaption of the neural network\n","\n","def fast_adapt(batch, learner, loss, adaptation_steps, shots, ways, device):\n","    data, labels = batch\n","    data, labels = data.to(device), labels.to(device)\n","\n","    # Separate data into adaptation/evalutation sets\n","    adaptation_indices = np.zeros(data.size(0), dtype=bool)\n","    adaptation_indices[np.arange(shots*ways) * 2] = True\n","    evaluation_indices = torch.from_numpy(~adaptation_indices)\n","    adaptation_indices = torch.from_numpy(adaptation_indices)\n","    adaptation_data, adaptation_labels = data[adaptation_indices], labels[adaptation_indices]\n","    evaluation_data, evaluation_labels = data[evaluation_indices], labels[evaluation_indices]\n","\n","    # Adapt the model\n","    for step in range(adaptation_steps):\n","        adaptation_error = loss(learner(adaptation_data), adaptation_labels)\n","        learner.adapt(adaptation_error)\n","\n","    # Evaluate the adapted model\n","    predictions = learner(evaluation_data)\n","    evaluation_error = loss(predictions, evaluation_labels)\n","    evaluation_accuracy = accuracy(predictions, evaluation_labels)\n","    return evaluation_error, evaluation_accuracy\n","\n","#Define main() method which marks the point from where the code execution begins\n","def main(\n","        ways=5,\n","        shots=5,\n","        meta_lr=0.003,\n","        fast_lr=0.5,\n","        meta_batch_size=32,\n","        adaptation_steps=1,\n","        num_iterations=100,\n","        cuda=True,\n","        seed=42,\n","):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    device = torch.device('cpu')\n","    if cuda and torch.cuda.device_count():\n","        torch.cuda.manual_seed(seed)\n","        device = torch.device('cuda')\n","\n","    # Create Tasksets using the benchmark interface\n","    tasksets = l2l.vision.benchmarks.get_tasksets('mini-imagenet',\n","                                                  train_samples=2*shots,\n","                                                  train_ways=ways,\n","                                                  test_samples=2*shots,\n","                                                  test_ways=ways,\n","                                                  root='~/data',\n","    )\n","\n","    # Create model\n","    #Model creation\n","    model = l2l.vision.models.MiniImagenetCNN(ways)\n","    model.to(device)\n","    maml = l2l.algorithms.MAML(model, lr=fast_lr, first_order=False)\n","    opt = optim.Adam(maml.parameters(), meta_lr)\n","    loss = nn.CrossEntropyLoss(reduction='mean')\n","    #Compute training and validation errors and accuracies   \n","    for iteration in range(num_iterations):\n","        opt.zero_grad()\n","        meta_train_error = 0.0\n","        meta_train_accuracy = 0.0\n","        meta_valid_error = 0.0\n","        meta_valid_accuracy = 0.0\n","        for task in range(meta_batch_size):\n","            # Compute meta-training loss\n","            learner = maml.clone()\n","            batch = tasksets.train.sample()\n","            evaluation_error, evaluation_accuracy = fast_adapt(batch,\n","                                                               learner,\n","                                                               loss,\n","                                                               adaptation_steps,\n","                                                               shots,\n","                                                               ways,\n","                                                               device)\n","            evaluation_error.backward()\n","            meta_train_error += evaluation_error.item()\n","            meta_train_accuracy += evaluation_accuracy.item()\n","\n","            # Compute meta-validation loss\n","            learner = maml.clone()\n","            batch = tasksets.validation.sample()\n","            evaluation_error, evaluation_accuracy = fast_adapt(batch,\n","                                                               learner,\n","                                                               loss,\n","                                                               adaptation_steps,\n","                                                               shots,\n","                                                               ways,\n","                                                               device)\n","            meta_valid_error += evaluation_error.item()\n","            meta_valid_accuracy += evaluation_accuracy.item()\n","\n","        # Print some metrics\n","        print('\\n')\n","        print('Iteration', iteration)\n","        print('Meta Train Error', meta_train_error / meta_batch_size)\n","        print('Meta Train Accuracy', meta_train_accuracy / meta_batch_size)\n","        print('Meta Valid Error', meta_valid_error / meta_batch_size)\n","        print('Meta Valid Accuracy', meta_valid_accuracy / meta_batch_size)\n","\n","        # Average the accumulated gradients and optimize\n","        for p in maml.parameters():\n","            p.grad.data.mul_(1.0 / meta_batch_size)\n","        opt.step()\n","\n","    meta_test_error = 0.0\n","    meta_test_accuracy = 0.0\n","    for task in range(meta_batch_size):\n","        # Compute meta-testing loss\n","        learner = maml.clone()\n","        batch = tasksets.test.sample()\n","        evaluation_error, evaluation_accuracy = fast_adapt(batch,\n","                                                           learner,\n","                                                           loss,\n","                                                           adaptation_steps,\n","                                                           shots,\n","                                                           ways,\n","                                                           device)\n","        meta_test_error += evaluation_error.item()\n","        meta_test_accuracy += evaluation_accuracy.item()\n","    print('Meta Test Error', meta_test_error / meta_batch_size)\n","    print('Meta Test Accuracy', meta_test_accuracy / meta_batch_size)\n","\n","\n","if __name__ == '__main__':\n","    main()"],"outputs":[],"metadata":{"id":"5X1LrI9RI-k9"}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{"id":"yC0olYY6RQF3"}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{"id":"bXXHjcygGUuN"}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{"id":"Z4pxW4rdGUpC"}}]}