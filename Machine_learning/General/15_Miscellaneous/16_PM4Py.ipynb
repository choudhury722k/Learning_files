{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"1_PM4Py.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNt5STk2q+rBbmbGsMKYobM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# PM4Py"],"metadata":{"id":"ZVPaGx-3ZaVh"}},{"cell_type":"markdown","source":["Pm4py is an open-source python library built by Fraunhofer Institute for Applied Information Technology to support Process Mining. \n"],"metadata":{"id":"LK52sSYSZ-81"}},{"cell_type":"markdown","source":["To read about it more, please refer [this](https://analyticsindiamag.com/guide-to-pm4py-python-framework-for-process-mining-algorithms/) article."],"metadata":{"id":"dURGpBWiaARh"}},{"cell_type":"markdown","source":["## Installation"],"metadata":{"id":"9ID9MYASaHDH"}},{"cell_type":"code","execution_count":null,"source":["!python -m pip install pip --upgrade --user -q\n","!python -m pip install numpy pandas seaborn matplotlib scipy sklearn statsmodels tensorflow keras --user -q"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["!python -m pip install -U pm4py --user -q"],"outputs":[],"metadata":{"id":"6Q-gnB0FaKhn"}},{"cell_type":"code","execution_count":null,"source":["import IPython\n","IPython.Application.instance().kernel.do_shutdown(True)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["## Data Loading\n","\n","This library supports tabular data input like CSV with the help of pandas. But the recommended data format for event logs is XES(EXtensible Event Stream). This is an XML based hierarchical, tag-based log storage format prescribed by IEEE as a standard.\n","\n","Let’s load some bank transaction logs stored in xes format. Data is downloaded from this [website](https://www.cs.upc.edu/~taymouri/dataset.html\n",")."],"metadata":{"id":"LCii-8YDaKJ2"}},{"cell_type":"code","execution_count":null,"source":["from pm4py.objects.log.importer.xes import importer as xes_importer\n","log = xes_importer.apply('https://gitlab.com/AnalyticsIndiaMagazine/practicedatasets/-/raw/main/PM4Py/banktransfer(2000-all-noise).xes')"],"outputs":[],"metadata":{"id":"nhx4w-U7XDAJ"}},{"cell_type":"markdown","source":["If we prefer to use pandas to analyse the data we can convert the imported logs as follows.\n"],"metadata":{"id":"CYdQa02jbUWy"}},{"cell_type":"code","execution_count":null,"source":["import pandas as pd\n","from pm4py.objects.conversion.log import converter as log_converter\n","df = log_converter.apply(log, variant=log_converter.Variants.TO_DATA_FRAME)\n","# df.to_csv('banktransfer')\n","df "],"outputs":[],"metadata":{"id":"3_oQZPOZbQ5G"}},{"cell_type":"markdown","source":["We can see that the three most important attributes, case id, timestamp and name of the event are present. Let us reduce the number of rows by limiting the number of traces. This can be done by pm4py’s own suite of filtering functions."],"metadata":{"id":"8twYaL5kbXUR"}},{"cell_type":"code","execution_count":null,"source":["from pm4py.algo.filtering.log.timestamp import timestamp_filter\n","filtered_log = timestamp_filter.filter_traces_contained(log, \"2013-01-01 00:00:00\", \"2020-01-01 23:59:59\") "],"outputs":[],"metadata":{"id":"yVmzyxZGbU_j"}},{"cell_type":"markdown","source":["## Model Discovery\n","\n","PM4PY supports three formalisms that represent the process models: PetriNets(Place Transition Net), Directly Flow graphs and Process trees. We will confine ourselves to using Petrinets in this article. Following is the description of Petrinets published in the pm4py documentation."],"metadata":{"id":"dMv98mcTbcCG"}},{"cell_type":"markdown","source":["Petrinets can be obtained using several different mining algorithms.We will use one such algorithm called alphaminer."],"metadata":{"id":"0tNJoO0sbeoH"}},{"cell_type":"code","execution_count":null,"source":["from pm4py.algo.discovery.alpha import algorithm as alpha_miner\n","net, initial_marking, final_marking = alpha_miner.apply(filtered_log) "],"outputs":[],"metadata":{"id":"9i0Sy0ARbZ9R"}},{"cell_type":"markdown","source":["## Visualizing a Petrinet"],"metadata":{"id":"r9pX_mnlbiqL"}},{"cell_type":"code","execution_count":null,"source":["from pm4py.visualization.petrinet import visualizer as pn_visualizer\n","gviz = pn_visualizer.apply(net, initial_marking, final_marking)\n","pn_visualizer.view(gviz) "],"outputs":[],"metadata":{"id":"Yb0Mz5BHbgzw"}},{"cell_type":"markdown","source":["## Conformance Checking\n","\n","Following is an example code to perform conformance checking.We generate a model using a part of the log and then validate the entire log."],"metadata":{"id":"mgjmmbQXbn5W"}},{"cell_type":"code","execution_count":null,"source":["from pm4py.algo.discovery.inductive import algorithm as inductive_miner\n","from pm4py.algo.filtering.log.auto_filter.auto_filter import apply_auto_filter\n","from pm4py.algo.conformance.tokenreplay.diagnostics import duration_diagnostics\n","#Generating model using only a part of the log\n","filtered_log = apply_auto_filter(log)\n","net, initial_marking, final_marking = inductive_miner.apply(filtered_log)\n","#Checking the entire log for conformance with the model\n","from pm4py.algo.conformance.tokenreplay import algorithm as token_based_replay\n","parameters_tbr = {token_based_replay.Variants.TOKEN_REPLAY.value.Parameters.DISABLE_VARIANTS: True, token_based_replay.Variants.TOKEN_REPLAY.value.Parameters.ENABLE_PLTR_FITNESS: True}\n","replayed_traces, place_fitness, trans_fitness, unwanted_activities = token_based_replay.apply(log, net,\n","                                                                                              initial_marking,\n","                                                                                              final_marking,\n","                                                                                              parameters=parameters_tbr)"],"outputs":[],"metadata":{"id":"-q_sz_26blpp"}},{"cell_type":"code","execution_count":null,"source":["#Displaying Diagnostics Information\n","act_diagnostics = duration_diagnostics.diagnose_from_notexisting_activities(log, unwanted_activities)\n","for act in act_diagnostics:\n","    print(act, act_diagnostics[act]) "],"outputs":[],"metadata":{"id":"MehOQkJzfL4e"}}]}