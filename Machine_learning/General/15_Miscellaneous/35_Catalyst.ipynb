{"cells":[{"cell_type":"markdown","source":["# Catalyst – A PyTorch Framework For Accelerated Deep Learning "],"metadata":{"id":"RQUdDWWRh_w4"}},{"cell_type":"markdown","source":["Catalyst is a PyTorch framework developed with the intent of advancing research and development in the domain of deep learning. It enables code reusability, reproducibility and rapid experimentation so that users can conveniently create deep learning models and pipelines without writing another training loop.\n","\n","Catalyst framework is part of the PyTorch ecosystem – a collection of numerous tools and libraries for AI development. It is also a part of the Catalyst Ecosystem – an MLOps ecosystem that expedites training, analysis and deployment of deep learning experiments through Catalyst, Alchemy and Reaction frameworks respectively"],"metadata":{"id":"f6NYE5PgiHTV"}},{"cell_type":"markdown","source":["To read about it more, please refer [this](https://analyticsindiamag.com/guide-to-catalyst-a-pytorch-framework-for-accelerated-deep-learning/) article."],"metadata":{"id":"0enyJiDWiIhZ"}},{"cell_type":"markdown","source":["# Practical implementation\n","\n","Here’s a demonstration of handling image classification task using Catalyst. We have used the well-known MNIST dataset having 10 output classes (for classifying images of handwritten digits from 0 to 9). "],"metadata":{"id":"gc12f0DciOz9"}},{"cell_type":"markdown","source":["Install Catalyst library using pip command"],"metadata":{"id":"iF_RYdrCiRT1"}},{"cell_type":"code","execution_count":null,"source":["!python -m pip install pip --upgrade --user -q\n","!python -m pip install numpy pandas seaborn matplotlib scipy sklearn statsmodels tensorflow keras --user -q"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["!python -m pip install -U catalyst --user -q"],"outputs":[],"metadata":{"id":"KLVlaD5U2HYg"}},{"cell_type":"code","execution_count":null,"source":["import IPython\n","IPython.Application.instance().kernel.do_shutdown(True)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["  Import required libraries and modules"],"metadata":{"id":"4OmGRIckikwa"}},{"cell_type":"code","execution_count":null,"source":["import os\n","from torch import nn, optim\n","from torch.utils.data import DataLoader\n","from catalyst import dl, utils\n","from catalyst.data.transforms import ToTensor\n","from catalyst.contrib.datasets import MNIST"],"outputs":[],"metadata":{"id":"HVgvx2fj2VVa"}},{"cell_type":"markdown","source":["  Define the neural network model, loss function and optimizer to be used\n","\n","Here, we use a simple architecture comprising an input layer and a hidden layer each having 28 neurons while the output layer has 10 neurons since we have 10 possible output classes."],"metadata":{"id":"hLNZEE8Miq0O"}},{"cell_type":"markdown","source":["We have used the cross entropy loss function of PyTorch which combines LogSoftmax and NLLLoss in one class."],"metadata":{"id":"SLV8vJJWitgP"}},{"cell_type":"code","execution_count":null,"source":["model = nn.Sequential(nn.Flatten(), nn.Linear(28 * 28, 10))\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.02)"],"outputs":[],"metadata":{"id":"jbr1s68v3wwB"}},{"cell_type":"markdown","source":["Load data for training and validation\n","\n","Using DataLoader() method of PyTorch, we load the MNIST dataset from contrib API of  Catalyst. We create a dictionary to load both training and validation sets at once by specifying the ‘train’ parameter of MNIST() as True or False respectively."],"metadata":{"id":"Uh2W_fGii1YM"}},{"cell_type":"code","execution_count":null,"source":["loaders = {\n","    \"train\": DataLoader(MNIST(os.getcwd(), train=True, download=True, transform=ToTensor()), batch_size=32),\n","    \"valid\": DataLoader(MNIST(os.getcwd(), train=False, download=True, transform=ToTensor()), batch_size=32),\n","}"],"outputs":[],"metadata":{"id":"wT4qOBLJ4gX6"}},{"cell_type":"markdown","source":["Define an experiment runner for handling experiments with supervised model using SupervisedRunner() method of Runners API."],"metadata":{"id":"bGe_jnDVi5qj"}},{"cell_type":"code","execution_count":null,"source":["runner = dl.SupervisedRunner(input_key=\"features\", output_key=\"logits\", target_key=\"targets\", loss_key=\"loss\")"],"outputs":[],"metadata":{"id":"7vwTE7pH4j_O"}},{"cell_type":"markdown","source":["Model training using Runners.train() method"],"metadata":{"id":"Ib6Tk_qzi7n2"}},{"cell_type":"code","execution_count":null,"source":["# model training\n","runner.train(\n","    model=model,\n","    criterion=criterion,\n","    optimizer=optimizer,\n","    loaders=loaders,\n","    num_epochs=1,\n","    callbacks=[\n","        dl.AccuracyCallback(input_key=\"logits\", target_key=\"targets\", topk_args=(1, 3, 5)),\n","        # catalyst[ml] required\n","        dl.ConfusionMatrixCallback(input_key=\"logits\", target_key=\"targets\", num_classes=10),\n","    ],\n","    logdir=\"./logs\",\n","    valid_loader=\"valid\",\n","    valid_metric=\"loss\",\n","    minimize_valid_metric=True,\n","    verbose=True,\n","    load_best_on_end=True,\n",")"],"outputs":[],"metadata":{"id":"BUxyZ_wx4qJR"}},{"cell_type":"code","execution_count":null,"source":["features_batch = next(iter(loaders[\"valid\"]))[0]\n","# model stochastic weight averaging\n","model.load_state_dict(utils.get_averaged_weights_by_path_mask(logdir=\"./logs\", path_mask=\"*.pth\"))\n","# model tracing\n","utils.trace_model(model=runner.model, batch=features_batch)\n","# model quantization\n","utils.quantize_model(model=runner.model)\n","# model pruning\n","utils.prune_model(model=runner.model, pruning_fn=\"l1_unstructured\", amount=0.8)\n","# onnx export\n","utils.onnx_export(model=runner.model, batch=features_batch, file=\"./logs/mnist.onnx\", verbose=True)"],"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-d86e79b27a06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfeatures_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"valid\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# model stochastic weight averaging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_averaged_weights_by_path_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./logs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"*.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# model tracing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1407\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1408\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Sequential:\n\tMissing key(s) in state_dict: \"1.weight_orig\", \"1.weight_mask\". \n\tUnexpected key(s) in state_dict: \"1.weight\". "]}],"metadata":{"colab":{"background_save":true},"id":"HA2lfJJT4vNJ"}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{"id":"EcF3bQF4jRBn"}}],"metadata":{"colab":{"authorship_tag":"ABX9TyOewLioL0+KV+Kwcxcx79nE","collapsed_sections":[],"name":"1_Catalyst.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":2}