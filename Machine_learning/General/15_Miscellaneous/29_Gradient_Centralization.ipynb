{"cells":[{"cell_type":"markdown","source":["# Gradient Centralization"],"metadata":{"id":"kUfYtKZwIkm_"}},{"cell_type":"markdown","source":["Model optimization plays a vital role in improving the performance of a Deep Neural Network (DNN). Techniques such as Batch Normalization and Weight Standardization perform Z-score standardization on activations or weights of the network. This article describes a novel optimization method called ‘Gradient Centralization (GC)’ which works directly on gradients instead. It was introduced by Hongwei Yong, Jianqiang Huang, Xiansheng Hua and Lei Zhang – researchers at The Hong Kong Polytechnic University and the DAMO Academy in April 2020."],"metadata":{"id":"PkjTG7KBIjTH"}},{"cell_type":"markdown","source":["To read about it more, please refer [this](https://analyticsindiamag.com/hands-on-guide-to-gradient-centralization/) article."],"metadata":{"id":"CiPtRPfZIsTQ"}},{"cell_type":"markdown","source":["# Practical implementation \n","\n","Here’s a demonstration of GC using gradient-centralization-tf, a Python package designed to implement GC with TensorFlow. We have used the Horses or Humans dataset having 500 rendered images of horses and 527 rendered images of humans in different poses and locations. Each image has 300*300 pixels dimensions and 24-bit color. \n","Step-wise explanation of the code is as follows:\n","\n","Install the gradient-centralization-tf package using pip command"],"metadata":{"id":"pEWgb2moMnEB"}},{"cell_type":"code","execution_count":null,"source":["!python -m pip install pip --upgrade --user -q\n","!python -m pip install numpy pandas seaborn matplotlib scipy sklearn statsmodels tensorflow keras --user -q"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["!python -m pip install gradient-centralization-tf --user -q"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["import IPython\n","IPython.Application.instance().kernel.do_shutdown(True)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":1,"source":["#    Import required libraries \n","import tensorflow as tf\n","from time import time #for execution time computation\n","import os  #for interacting with the Operating System\n","import zipfile  #for extracting dataset’s .zip files\n","import gctf\n","\n","#for image augmentation\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.optimizers import RMSprop\n","from tabulate import tabulate\n"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5410,"status":"ok","timestamp":1624608276197,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"},"user_tz":-330},"id":"oD1C3X5sH0Fp","outputId":"120566ca-3c86-4ef0-b932-c80882182bd8"}},{"cell_type":"markdown","source":["  Download the data from GCS (Google Cloud Storage)"],"metadata":{"id":"xFGOYXyIMwxc"}},{"cell_type":"code","execution_count":null,"source":["# #Get training data\n","# !wget --no-check-certificate \\\n","#   https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip \\\n","#     -O /tmp/horse-or-human.zip\n","\n","# #Get validation data\n","# !wget --no-check-certificate \\    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip \\\n","#         -O /tmp/validation-horse-or-human.zip\n"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1878,"status":"ok","timestamp":1624608284751,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"},"user_tz":-330},"id":"3TTdE5suH1lD","outputId":"7764b530-09cb-4154-9ea0-0ae54943933a"}},{"cell_type":"markdown","source":["Read and extract the dataset’s downloaded .zip files"],"metadata":{"id":"QpHnfE7IMyzN"}},{"cell_type":"code","execution_count":null,"source":["# #Path of the training data file\n","# file = '/tmp/horse-or-human.zip'\n","\n","# #Read the zip file\n","# reference = zipfile.ZipFile(file, 'r')\n","\n","# #Extract the data\n","# reference.extractall('/tmp/horse-or-human')\n","\n","# \t#Repeat the process for extracting validation data\n","# file = '/tmp/validation-horse-or-human.zip'\n","# reference = zipfile.ZipFile(file, 'r')\n","# reference.extractall('/tmp/validation-horse-or-human')\n","\t\n","# #Close the archive file using ZipFile.close()\n","# reference.close()"],"outputs":[],"metadata":{"executionInfo":{"elapsed":1126,"status":"ok","timestamp":1624608290805,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"},"user_tz":-330},"id":"h9AMF189Iz5-"}},{"cell_type":"markdown","source":["Create separate directories for horses and humans images to be used for training and validation"],"metadata":{"id":"fw4BlVwzM2Ik"}},{"cell_type":"code","execution_count":9,"source":["# Directory for training horse pictures\n","horse_train = os.path.join('https://gitlab.com/AnalyticsIndiaMagazine/practicedatasets/-/tree/main/gradient_centralization/horse-or-human/horses')\n","\n","# Directory for training human pictures\n","human_train = os.path.join('https://gitlab.com/AnalyticsIndiaMagazine/practicedatasets/-/tree/main/gradient_centralization/horse-or-human/humans')\n","\n","# Directory for training horse pictures\n","horse_validation = os.path.join('https://gitlab.com/AnalyticsIndiaMagazine/practicedatasets/-/tree/main/gradient_centralization/validation-horse-or-human/horses')\n","\n","# Directory for training human pictures\n","human_validation = os.path.join('https://gitlab.com/AnalyticsIndiaMagazine/practicedatasets/-/tree/main/gradient_centralization/validation-horse-or-human/humans')\n"],"outputs":[],"metadata":{"executionInfo":{"elapsed":398,"status":"ok","timestamp":1624608305305,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"},"user_tz":-330},"id":"yiaWPHLIJehR"}},{"cell_type":"markdown","source":["Increase amount  training and validation data by image augmentation"],"metadata":{"id":"C3-Pz2V9M4em"}},{"cell_type":"code","execution_count":10,"source":["#Modify training image\n","trainDatagen = ImageDataGenerator(\n","      rescale=1./255, #rescalling factor\n","      rotation_range=40, #rotate image by 40 degrees\n","      width_shift_range=0.2, #fraction of total image width\n","      height_shift_range=0.2, #fraction of total image height\n","      shear_range=0.2, #shear intensity\n","      zoom_range=0.2, #zooming range will be [1-0.2,1+0.2] = [0.8,1.2]\n","      horizontal_flip=True, #flip the image horizontally\n","      fill_mode='nearest') #way to fill the points outside the input’s boundaries\n","\n","#Modify validation set images\n","validDatagen = ImageDataGenerator(rescale=1/255) \n","\n","# Flow training images in batches of 128 using trainDatagen generator\n","trainGen = trainDatagen.flow_from_directory(\n","        'https://gitlab.com/AnalyticsIndiaMagazine/practicedatasets/-/tree/main/gradient_centralization/horse-or-human/',  # source directory for training images\n","        target_size=(300, 300), \n","        batch_size=128,\n"," #binary labels required because we will use binary_crossentropy loss as this is a binary classification task (classify images as horse or human)\n","        class_mode='binary')\n","\n","# Similarly, flow validation images in batches of 32 using validDatagen\n","validationGen = validDatagen.flow_from_directory(\n","        'https://gitlab.com/AnalyticsIndiaMagazine/practicedatasets/-/tree/main/gradient_centralization/validation-horse-or-human/', \n","        target_size=(300, 300),  \n","        batch_size=32,\n","        class_mode='binary')\n"],"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'https://gitlab.com/AnalyticsIndiaMagazine/practicedatasets/-/tree/main/gradient_centralization/horse-or-human/'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-768228a0cb9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Flow training images in batches of 128 using trainDatagen generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m trainGen = trainDatagen.flow_from_directory(\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;34m'https://gitlab.com/AnalyticsIndiaMagazine/practicedatasets/-/tree/main/gradient_centralization/horse-or-human/'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# source directory for training images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[1;32m    956\u001b[0m             \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m     \"\"\"\n\u001b[0;32m--> 958\u001b[0;31m     return DirectoryIterator(\n\u001b[0m\u001b[1;32m    959\u001b[0m         \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dtype'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m     super(DirectoryIterator, self).__init__(\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_data_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras_preprocessing/image/directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'https://gitlab.com/AnalyticsIndiaMagazine/practicedatasets/-/tree/main/gradient_centralization/horse-or-human/'"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":506,"status":"ok","timestamp":1624608323525,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"},"user_tz":-330},"id":"KLvyK9VKJnkN","outputId":"731776a1-e207-4cf1-bdbf-16672f7399b0"}},{"cell_type":"markdown","source":["The above output shows that our data has a total 1027 training images and 256 images for validation. Each of the images belongs either of the two classes – horse or human.\n","\n","\n","\n","\n","\n","Build the DNN model"],"metadata":{"id":"fjwgCNW7M7aJ"}},{"cell_type":"code","execution_count":4,"source":["myModel = tf.keras.models.Sequential([\n","   # 1st convolution\n","               #convolutional layer\n","    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(300, 300, 3)),\n","    tf.keras.layers.MaxPooling2D(2, 2),  #pooling layer\n","\n","    # 2nd convolution\n","    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),  #convolutional layer\n","    tf.keras.layers.Dropout(0.5),  #dropout regularization\n","    tf.keras.layers.MaxPooling2D(2,2), #pooling layer\n","\n","    # 3rd convolution\n","    tf.keras.layers.Conv2D(64, (3,3), activation='relu'), #convolutional layer\n","    tf.keras.layers.Dropout(0.5), #pooling layer\n","\n","\n","\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    \n"," # Flatten the results to feed into a DNN\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dropout(0.5), #dropout regularization\n","    # Hidden layer with 512 neurons\n","    tf.keras.layers.Dense(512, activation='relu'),\n","\n","#Output layer with a single neuron. It will give output 0 (for horse) or 1 (for human)\n","     tf.keras.layers.Dense(1, activation='sigmoid')\n","])\n"],"outputs":[],"metadata":{"executionInfo":{"elapsed":1215,"status":"ok","timestamp":1624608336152,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"},"user_tz":-330},"id":"6OWu1MErJtoQ"}},{"cell_type":"markdown","source":["Create a class for computing training time so that we can compare it for model using GC and that without GC used for optimization"],"metadata":{"id":"-YK97dDMM-hN"}},{"cell_type":"code","execution_count":5,"source":["class TimeTaken(tf.keras.callbacks.Callback):\n","    def on_train_begin(self, logs={}):\n","        self.times = []\n","\n","    def on_epoch_begin(self, batch, logs={}):\n","        self.epoch_time_start = time()\n","\n","    def on_epoch_end(self, batch, logs={}):\n","        self.times.append(time() - self.epoch_time_start)\n"],"outputs":[],"metadata":{"executionInfo":{"elapsed":395,"status":"ok","timestamp":1624608339246,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"},"user_tz":-330},"id":"5ZyIVXwWJ9Tu"}},{"cell_type":"markdown","source":["Train the model without using GC"],"metadata":{"id":"xlasbFgyNAoH"}},{"cell_type":"code","execution_count":6,"source":["time1 = TimeTaken()\n","\n","#Compile the model\n","myModel.compile(loss='binary_crossentropy', #loss function\n","              optimizer=RMSprop(lr=1e-4), #’lr’ is the learning rate\n","              metrics=['accuracy'])\n","\n","#Fit the model on the training data\n","hist1 = myModel.fit(\n","      trainGen,\n","      steps_per_epoch=8,  #number of steps for each epoch\n","      epochs=10, #number of epochs\n","      verbose=1,\n","      validation_data = validationGen, \n","      validation_steps=8, #number of validation stepso\n","      callbacks = [time1])\n"],"outputs":[{"output_type":"stream","name":"stderr","text":["/home/aishwarya/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","3/8 [==========>...................] - ETA: 35s - loss: 6.2222 - accuracy: 0.5078"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-4c3c3f41eeb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#Fit the model on the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m hist1 = myModel.fit(\n\u001b[0m\u001b[1;32m     10\u001b[0m       \u001b[0mtrainGen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m#number of steps for each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n","\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"M5QGGnzoKCQt"}},{"cell_type":"markdown","source":["Train the model with GC used for optimization"],"metadata":{"id":"lWD6cjl7NDPr"}},{"cell_type":"code","execution_count":null,"source":["time2 = TimeTaken()\n","\n","#Compile the model\n","myModel.compile(loss='binary_crossentropy',\n","              optimizer=gctf.optimizers.rmsprop(learning_rate = 1e-4),\n","              metrics=['accuracy'])\n","\n","#Fit the model on training data\n","hist2 = myModel.fit(\n","      trainGen,\n","      steps_per_epoch=8,  \n","      epochs=10,\n","      verbose=1,\n","      validation_data = validationGen,\n","      validation_steps=8,\n","      callbacks = [time2])\n"],"outputs":[],"metadata":{"id":"cB7ikZcsKLMY"}},{"cell_type":"markdown","source":["  Compare the results of execution with and without GC"],"metadata":{"id":"MjNtejJzNFnV"}},{"cell_type":"code","execution_count":null,"source":["comparisonData = [[\"Model w/o gctf:\",sum(time1.times),hist1.history['accuracy'][-1],hist1.history['loss'][-1]],\n","                  [\"Model with gctf\",sum(time2.times),hist2.history['accuracy'][-1],hist2.history['loss'][-1]]] \n","\n","#Tabulate the comparisonData’s information using tabulate() method\n","print(tabulate(comparisonData, headers=[\"Type\",\"Execution time\", \"Accuracy\", \"Loss\"]))\n"],"outputs":[],"metadata":{"id":"6iUl9l0xTOYj"}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{"id":"PSYwMyNseyK-"}}],"metadata":{"colab":{"authorship_tag":"ABX9TyMFqak0Ci2uw/Nv/M3edQ+F","name":"1_Gradient_Centralization.ipynb","version":""},"kernelspec":{"name":"python3","display_name":"Python 3.8.8 64-bit ('base': conda)"},"language_info":{"name":"python","version":"3.8.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"interpreter":{"hash":"f60a20abaabf5a658075b37fac599269792a9493ddacd7c14d8505185d5625aa"}},"nbformat":4,"nbformat_minor":2}