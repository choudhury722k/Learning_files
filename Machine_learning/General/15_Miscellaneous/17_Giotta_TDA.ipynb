{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"1_Giotta_TDA.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMid8IOMOue/glG0KFeHZ0B"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Giotta-TDA"],"metadata":{"id":"kdrvAAu1sI7A"}},{"cell_type":"markdown","source":["A high-performance topological machine learning toolbox in Python\n","\n","giotto-tda is a high performance topological machine learning toolbox in Python built on top of scikit-learn and is distributed under the GNU AGPLv3 license. It is part of the Giotto family of open-source projects."],"metadata":{"id":"lM1CYhLWsLml"}},{"cell_type":"markdown","source":["To read about it more, please refer [this](https://analyticsindiamag.com/guide-to-giotto-tda-a-high-performance-topological-machine-learning-toolbox/) article."],"metadata":{"id":"Y-PreaSgsMcu"}},{"cell_type":"markdown","source":["# Code Implementation"],"metadata":{"id":"NKd2-kwbsc88"}},{"cell_type":"markdown","source":["## Classifying 3D Shapes\n","\n","Let’s see an example of this process to gain a better understanding. We use giotto_tda: a high performing topological machine learning toolkit in python. It integrates with sklearn really well and is very intuitive to use.\n","Setup"],"metadata":{"id":"kTSsT5RnsVmH"}},{"cell_type":"code","execution_count":null,"source":["!python -m pip install pip --upgrade --user -q --no-warn-script-location\n","!python -m pip install numpy pandas seaborn matplotlib scipy sklearn statsmodels tensorflow keras --user -q --no-warn-script-location"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["!python -m pip install -U giotto-tda --user -q --no-warn-script-location\n","!python -m pip install openml --user -q --no-warn-script-location\n","!python -m pip install delayed --user -q --no-warn-script-location\n","\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["import IPython\n","IPython.Application.instance().kernel.do_shutdown(True)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["from sklearn.datasets import make_circles\n","import matplotlib.pyplot as plt"],"outputs":[],"metadata":{"id":"vyIv_o9oZ-a1"}},{"cell_type":"code","execution_count":null,"source":["X=make_circles(100)\n","y=[1 if (i[0]>0.1 and i[1]>0.1) or (i[0]<-0.1 and i[1]<-0.1) else 0 for i in X[0]]\n","plt.scatter(X[0][:,0],X[0][:,1],c=y)\n","plt.axis('off')\n","plt.show()"],"outputs":[],"metadata":{"id":"FY4Zt00MaTvy"}},{"cell_type":"code","execution_count":null,"source":["import numpy as np\n","np.array(y)"],"outputs":[],"metadata":{"id":"Pw-kbbZkbBKn"}},{"cell_type":"markdown","source":["## Data\n","\n","We use the same data used in tutorials of giotto_data.Data is loaded from Princeton’s Computer Vision Course. "],"metadata":{"id":"cSzopohns1pS"}},{"cell_type":"code","execution_count":null,"source":["from openml.datasets.functions import get_dataset\n","df = get_dataset('shapes').get_data(dataset_format='dataframe')[0]\n","df.head()"],"outputs":[],"metadata":{"id":"HdG4nIg2pF21"}},{"cell_type":"code","execution_count":null,"source":["df['target'].map(lambda x:x[:-1]).value_counts()"],"outputs":[],"metadata":{"id":"Oy_dKRNypcfi"}},{"cell_type":"code","execution_count":null,"source":["from gtda.plotting import plot_point_cloud,plot_diagram\n","plot=plot_point_cloud(df.query('target == \"biplane0\"')[[\"x\", \"y\", \"z\"]].values)\n","plot"],"outputs":[],"metadata":{"id":"2u6S7qIfq6BO"}},{"cell_type":"code","execution_count":null,"source":["from gtda.plotting import plot_point_cloud,plot_diagram\n","plot=plot_point_cloud(df.query('target == \"human_arms_out0\"')[[\"x\", \"y\", \"z\"]].values)\n","plot"],"outputs":[],"metadata":{"id":"ZrggGzB75yP8"}},{"cell_type":"code","execution_count":null,"source":["type(plot)"],"outputs":[],"metadata":{"id":"JJl_SQ0vsgvC"}},{"cell_type":"code","execution_count":null,"source":["# plot.write_html('plot.html')"],"outputs":[],"metadata":{"id":"magkHkTgtBED"}},{"cell_type":"markdown","source":["There are 4 classes of 3D objects in data with 10 samples for each class. 400 points in 3D space represent each object.\n","\n","We have to transform the data into point clouds to work with the library"],"metadata":{"id":"J4zrh0iBtS6x"}},{"cell_type":"code","execution_count":null,"source":["import numpy as np\n","\n","point_clouds = np.asarray(\n","    [\n","        df.query(\"target == @shape\")[[\"x\", \"y\", \"z\"]].values\n","        for shape in df[\"target\"].unique()\n","    ]\n",")\n","point_clouds.shape"],"outputs":[],"metadata":{"id":"CEt9SvJ4tqma"}},{"cell_type":"markdown","source":["## Calculating Persistence Diagrams"],"metadata":{"id":"sx5Dw02qteiU"}},{"cell_type":"code","execution_count":null,"source":["from gtda.homology import VietorisRipsPersistence\n","\n","# Track connected components, loops, and voids\n","homology_dimensions = [0, 1, 2]\n","\n","persistence = VietorisRipsPersistence(\n","    metric=\"euclidean\",\n","    homology_dimensions=homology_dimensions,\n","    n_jobs=6,\n","    collapse_edges=True,\n",")\n","persistence_diagrams = persistence.fit_transform(point_clouds)\n","\n","#Example Persistence Diagram\n","plot_diagram(persistence_diagrams[10])"],"outputs":[],"metadata":{"id":"cXjB7t2su6gH"}},{"cell_type":"markdown","source":["## Persistence Entropy and Other Features\n","\n","We can get persistence entropies of each homology dimension using "],"metadata":{"id":"fqi0gpietj3T"}},{"cell_type":"code","execution_count":null,"source":["from gtda.diagrams import PersistenceEntropy\n","persistence_entropy = PersistenceEntropy(normalize=True)\n","# Calculate topological feature matrix\n","X = persistence_entropy.fit_transform(persistence_diagrams)\n","X.shape"],"outputs":[],"metadata":{"id":"g29wG8divtoT"}},{"cell_type":"markdown","source":["Since we used only 3 dimensions, we get only three numbers for each data point. To increase the number of features, we can calculate other types of features. Following are some examples."],"metadata":{"id":"gBjp8SFXtnUw"}},{"cell_type":"code","execution_count":null,"source":["from gtda.diagrams import NumberOfPoints,Amplitude\n","from sklearn.pipeline import make_union\n","\n","# Select a variety of metrics to calculate amplitudes\n","metrics = [\n","    {\"metric\": metric}\n","    for metric in [\"bottleneck\", \"wasserstein\", \"landscape\", \"persistence_image\"]\n","]\n","\n","# Concatenate to generate 3 + 3 + (4 x 3) = 18 topological features\n","feature_union = make_union(\n","    PersistenceEntropy(normalize=True),\n","    NumberOfPoints(n_jobs=-1),\n","    *[Amplitude(**metric, n_jobs=-1) for metric in metrics]\n",")"],"outputs":[],"metadata":{"id":"GXV0jYGnv_Ts"}},{"cell_type":"markdown","source":["## Classification Pipeline\n","\n","Finally, we can put all these things together and build a classification model."],"metadata":{"id":"aBpnRiKHttHR"}},{"cell_type":"code","execution_count":null,"source":["from gtda.pipeline import Pipeline\n","from sklearn.ensemble import RandomForestClassifier\n","\n","steps = [\n","    (\"persistence\", VietorisRipsPersistence(metric=\"euclidean\", homology_dimensions=homology_dimensions, n_jobs=6)),\n","    (\"features\", feature_union),\n","    (\"model\", RandomForestClassifier(oob_score=True)),\n","]\n","\n","pipeline = Pipeline(steps)"],"outputs":[],"metadata":{"id":"a60O3MFEwl91"}},{"cell_type":"code","execution_count":null,"source":["labels = np.zeros(40)\n","labels[10:20] = 1\n","labels[20:30] = 2\n","labels[30:] = 3"],"outputs":[],"metadata":{"id":"wBmWmoO51B9y"}},{"cell_type":"code","execution_count":null,"source":["pipeline.fit(point_clouds,labels)"],"outputs":[],"metadata":{"id":"GgjhChNMxPoT"}},{"cell_type":"code","execution_count":null,"source":["pipeline['model'].oob_score_"],"outputs":[],"metadata":{"id":"T8vM1Pejx5YB"}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{"id":"DPJwVTaUuNpj"}}]}