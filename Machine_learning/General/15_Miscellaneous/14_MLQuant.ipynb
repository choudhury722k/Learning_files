{"cells":[{"cell_type":"markdown","source":["# Apple's ML Quant"],"metadata":{"id":"LgupyDUPi-gB"}},{"cell_type":"markdown","source":["Large Neural Networks are difficult to use in production environments as they are memory intensive and are slow during inference. Most successful Deep Learning Models such as Transformers are being followed by their Lite Versions which dramatically speed up inference trading off accuracy. In this article, let’s explore Least Squares Quantization, an algorithm to speed up large neural networks by quantizing them while reducing the accuracy gap from the non-quantized  model."],"metadata":{"id":"KV3lgaZojBqG"}},{"cell_type":"markdown","source":["To read about it more, please refer [this](https://analyticsindiamag.com/what-is-apples-quant-for-neural-networks-quantization/) article."],"metadata":{"id":"o7iywmJdkaQF"}},{"cell_type":"markdown","source":["# Quantization Example"],"metadata":{"id":"l0ynkRaIkTFQ"}},{"cell_type":"markdown","source":[" Let’s see how it affects a model on the CIFAR 100 dataset."],"metadata":{"id":"8i1QhLY8mFKu"}},{"cell_type":"code","execution_count":1,"source":["!python -m pip install pip --upgrade --user -q\n","!python -m pip install numpy pandas seaborn matplotlib scipy sklearn statsmodels tensorflow keras --user -q"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":2,"source":["!git clone https://github.com/apple/ml-quant.git"],"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'ml-quant' already exists and is not an empty directory.\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":732,"status":"ok","timestamp":1624011185655,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"},"user_tz":-330},"id":"m8WXAd6DuViU","outputId":"6353351d-4b89-465b-8dd3-a8f94f427679"}},{"cell_type":"markdown","source":["CIFAR100 contains colour images that need to be classified into one of 100 classes."],"metadata":{"id":"D9WzTr87mJJ1"}},{"cell_type":"code","execution_count":3,"source":["%cd ml-quant\n","!python -m pip install -U pip wheel --user -q \n","!python -m pip install -r requirements.txt --user -q"],"outputs":[{"output_type":"stream","name":"stdout","text":["/home/aishwarya/machine-hack.py-practice/2_General_ML_AI/15_Miscellaneous/14_ML_Quant/ml-quant\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.5.0 requires tensorboard~=2.5, but you have tensorboard 2.0.0 which is incompatible.\u001b[0m\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6293,"status":"ok","timestamp":1624011192712,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"},"user_tz":-330},"id":"5g_kOwLMueVS","outputId":"eb28fdc7-743a-48c5-eb04-deea2bbc4a22"}},{"cell_type":"code","execution_count":4,"source":["!python -m pip install flit --user -q\n","import os\n","os.environ['FLIT_ROOT_INSTALL'] = '1'\n","!flit install -s"],"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?1l\u001b>Extras to install for deps 'all': {'test', 'doc', '.none'}        \u001b[32mI-flit.install\u001b[m\n","Installing requirements                                           \u001b[32mI-flit.install\u001b[m\n","Requirement already satisfied: pytest in /home/aishwarya/anaconda3/lib/python3.8/site-packages (from -r /tmp/tmpbkze5v38requirements.txt (line 1)) (6.2.3)\n","Collecting pytest-mypy\n","  Downloading pytest_mypy-0.8.1-py3-none-any.whl (6.7 kB)\n","Collecting pytest-flake8\n","  Downloading pytest_flake8-1.0.7-py2.py3-none-any.whl (6.4 kB)\n","Collecting pytest-cov\n","  Downloading pytest_cov-3.0.0-py3-none-any.whl (20 kB)\n","Collecting flake8-docstrings\n","  Downloading flake8_docstrings-1.6.0-py2.py3-none-any.whl (5.7 kB)\n","Collecting flake8-copyright\n","  Downloading flake8_copyright-0.2.2-py3-none-any.whl (5.0 kB)\n","Requirement already satisfied: sphinx in /home/aishwarya/anaconda3/lib/python3.8/site-packages (from -r /tmp/tmpbkze5v38requirements.txt (line 7)) (4.0.1)\n","Collecting sphinx-rtd-theme\n","  Downloading sphinx_rtd_theme-1.0.0-py2.py3-none-any.whl (2.8 MB)\n","     |████████████████████████████████| 2.8 MB 4.3 MB/s            \n","\u001b[?25hCollecting sphinx-autodoc-typehints\n","  Downloading sphinx_autodoc_typehints-1.12.0-py3-none-any.whl (9.4 kB)\n","Collecting m2r\n","  Downloading m2r-0.2.1.tar.gz (16 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: attrs>=19.2.0 in /home/aishwarya/anaconda3/lib/python3.8/site-packages (from pytest->-r /tmp/tmpbkze5v38requirements.txt (line 1)) (20.3.0)\n","Requirement already satisfied: iniconfig in /home/aishwarya/anaconda3/lib/python3.8/site-packages (from pytest->-r /tmp/tmpbkze5v38requirements.txt (line 1)) (1.1.1)\n","Requirement already satisfied: packaging in /home/aishwarya/.local/lib/python3.8/site-packages (from pytest->-r /tmp/tmpbkze5v38requirements.txt (line 1)) (21.0)\n","Requirement already satisfied: pluggy<1.0.0a1,>=0.12 in /home/aishwarya/anaconda3/lib/python3.8/site-packages (from pytest->-r /tmp/tmpbkze5v38requirements.txt (line 1)) (0.13.1)\n","Requirement already satisfied: py>=1.8.2 in /home/aishwarya/anaconda3/lib/python3.8/site-packages (from pytest->-r /tmp/tmpbkze5v38requirements.txt (line 1)) (1.10.0)\n","Requirement already satisfied: toml in /home/aishwarya/anaconda3/lib/python3.8/site-packages (from pytest->-r /tmp/tmpbkze5v38requirements.txt (line 1)) (0.10.2)\n","Requirement already satisfied: filelock>=3.0 in /home/aishwarya/anaconda3/lib/python3.8/site-packages (from pytest-mypy->-r /tmp/tmpbkze5v38requirements.txt (line 2)) (3.0.12)\n","Collecting mypy>=0.700\n","  Downloading mypy-0.910-cp38-cp38-manylinux2010_x86_64.whl (22.8 MB)\n","     |████████████████████████████████| 22.8 MB 228 kB/s            \n","\u001b[?25hRequirement already satisfied: flake8>=3.5 in /home/aishwarya/anaconda3/lib/python3.8/site-packages (from pytest-flake8->-r /tmp/tmpbkze5v38requirements.txt (line 3)) (3.9.0)\n","Collecting coverage[toml]>=5.2.1\n","  Downloading coverage-6.0.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (256 kB)\n","     |████████████████████████████████| 256 kB 2.7 MB/s            \n","\u001b[?25hRequirement already satisfied: pydocstyle>=2.1 in /home/aishwarya/anaconda3/lib/python3.8/site-packages (from flake8-docstrings->-r /tmp/tmpbkze5v38requirements.txt (line 5)) (6.0.0)\n","Requirement already satisfied: setuptools in /home/aishwarya/anaconda3/lib/python3.8/site-packages (from flake8-copyright->-r /tmp/tmpbkze5v38requirements.txt (line 6)) (52.0.0.post20210125)\n","Requirement already satisfied: sphinxcontrib-applehelp in /home/aishwarya/anaconda3/lib/python3.8/site-packages (from sphinx->-r /tmp/tmpbkze5v38requirements.txt (line 7)) (1.0.2)\n","Requirement already satisfied: requests>=2.5.0 in /home/aishwarya/anaconda3/lib/python3.8/site-packages (from sphinx->-r /tmp/tmpbkze5v38requirements.txt (line 7)) (2.25.1)\n","Requirement already satisfied: sphinxcontrib-qthelp in /home/aishwarya/anaconda3/lib/python3.8/site-packages (from sphinx->-r /tmp/tmpbkze5v38requirements.txt (line 7)) (1.0.3)\n","Requirement already satisfied: snowballstemmer>=1.1 in /home/aishwarya/anaconda3/lib/python3.8/site-packages (from sphinx->-r /tmp/tmpbkze5v38requirements.txt (line 7)) (2.1.0)\n","Requirement already satisfied: imagesize in /home/aishwarya/anaconda3/lib/python3.8/site-packages (from sphinx->-r /tmp/tmpbkze5v38requirements.txt (line 7)) (1.2.0)\n","Requirement already satisfied: Pygments>=2.0 in /home/aishwarya/anaconda3/lib/python3.8/site-packages (from sphinx->-r /tmp/tmpbkze5v38requirements.txt (line 7)) (2.8.1)\n","Requirement already satisfied: alabaster<0.8,>=0.7 in /home/aishwarya/anaconda3/lib/python3.8/site-packages (from sphinx->-r /tmp/tmpbkze5v38requirements.txt (line 7)) (0.7.12)\n","Requirement already satisfied: docutils<0.18,>=0.14 in /home/aishwarya/anaconda3/lib/python3.8/site-packages (from sphinx->-r /tmp/tmpbkze5v38requirements.txt (line 7)) (0.17.1)\n","Requirement already satisfied: MarkupSafe<2.0 in /home/aishwarya/anaconda3/lib/python3.8/site-packages (from sphinx->-r /tmp/tmpbkze5v38requirements.txt (line 7)) (1.1.1)\n","Requirement already satisfied: babel>=1.3 in /home/aishwarya/anaconda3/lib/python3.8/site-packages (from sphinx->-r /tmp/tmpbkze5v38requirements.txt (line 7)) (2.9.0)\n","Requirement already satisfied: sphinxcontrib-htmlhelp in /home/aishwarya/anaconda3/lib/python3.8/site-packages (from sphinx->-r /tmp/tmpbkze5v38requirements.txt (line 7)) (1.0.3)\n","Requirement already satisfied: sphinxcontrib-jsmath in /home/aishwarya/anaconda3/lib/python3.8/site-packages (from sphinx->-r /tmp/tmpbkze5v38requirements.txt (line 7)) (1.0.1)\n","Requirement already satisfied: sphinxcontrib-devhelp in /home/aishwarya/anaconda3/lib/python3.8/site-packages (from sphinx->-r /tmp/tmpbkze5v38requirements.txt (line 7)) (1.0.2)\n","Requirement already satisfied: Jinja2<3.0,>=2.3 in /home/aishwarya/anaconda3/lib/python3.8/site-packages (from sphinx->-r /tmp/tmpbkze5v38requirements.txt (line 7)) (2.11.3)\n","Requirement already satisfied: sphinxcontrib-serializinghtml in /home/aishwarya/anaconda3/lib/python3.8/site-packages (from sphinx->-r /tmp/tmpbkze5v38requirements.txt (line 7)) (1.1.4)\n","Requirement already satisfied: mistune in /home/aishwarya/.local/lib/python3.8/site-packages (from m2r->-r /tmp/tmpbkze5v38requirements.txt (line 10)) (0.8.4)\n","Requirement already satisfied: pytz>=2015.7 in /home/aishwarya/anaconda3/lib/python3.8/site-packages (from babel>=1.3->sphinx->-r /tmp/tmpbkze5v38requirements.txt (line 7)) (2021.1)\n","Requirement already satisfied: tomli in /home/aishwarya/.local/lib/python3.8/site-packages (from coverage[toml]>=5.2.1->pytest-cov->-r /tmp/tmpbkze5v38requirements.txt (line 4)) (1.2.2)\n","Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /home/aishwarya/anaconda3/lib/python3.8/site-packages (from flake8>=3.5->pytest-flake8->-r /tmp/tmpbkze5v38requirements.txt (line 3)) (0.6.1)\n","Collecting pyflakes<2.4.0,>=2.3.0\n","  Downloading pyflakes-2.3.1-py2.py3-none-any.whl (68 kB)\n","     |████████████████████████████████| 68 kB 2.5 MB/s            \n","\u001b[?25hCollecting pycodestyle<2.8.0,>=2.7.0\n","  Downloading pycodestyle-2.7.0-py2.py3-none-any.whl (41 kB)\n","     |████████████████████████████████| 41 kB 1.1 MB/s            \n","\u001b[?25hRequirement already satisfied: mypy-extensions<0.5.0,>=0.4.3 in /home/aishwarya/anaconda3/lib/python3.8/site-packages (from mypy>=0.700->pytest-mypy->-r /tmp/tmpbkze5v38requirements.txt (line 2)) (0.4.3)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /home/aishwarya/anaconda3/lib/python3.8/site-packages (from mypy>=0.700->pytest-mypy->-r /tmp/tmpbkze5v38requirements.txt (line 2)) (3.7.4.3)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/aishwarya/.local/lib/python3.8/site-packages (from requests>=2.5.0->sphinx->-r /tmp/tmpbkze5v38requirements.txt (line 7)) (1.26.7)\n","Requirement already satisfied: idna<3,>=2.5 in /home/aishwarya/anaconda3/lib/python3.8/site-packages (from requests>=2.5.0->sphinx->-r /tmp/tmpbkze5v38requirements.txt (line 7)) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /home/aishwarya/anaconda3/lib/python3.8/site-packages (from requests>=2.5.0->sphinx->-r /tmp/tmpbkze5v38requirements.txt (line 7)) (4.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /home/aishwarya/anaconda3/lib/python3.8/site-packages (from requests>=2.5.0->sphinx->-r /tmp/tmpbkze5v38requirements.txt (line 7)) (2020.12.5)\n","Requirement already satisfied: pyparsing>=2.0.2 in /home/aishwarya/.local/lib/python3.8/site-packages (from packaging->pytest->-r /tmp/tmpbkze5v38requirements.txt (line 1)) (3.0.1)\n","Building wheels for collected packages: m2r\n","  Building wheel for m2r (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for m2r: filename=m2r-0.2.1-py3-none-any.whl size=10537 sha256=081473af2b679386f56d23f934a8bb6317aad84666f38b54ca5a9217ee994d73\n","  Stored in directory: /home/aishwarya/.cache/pip/wheels/f0/0d/a1/905017ebb11fce6b0316028bf05fc5c4229fbadff0db60182d\n","Successfully built m2r\n","Installing collected packages: pyflakes, pycodestyle, coverage, mypy, sphinx-rtd-theme, sphinx-autodoc-typehints, pytest-mypy, pytest-flake8, pytest-cov, m2r, flake8-docstrings, flake8-copyright\n","  Attempting uninstall: pyflakes\n","    Found existing installation: pyflakes 2.2.0\n","    Uninstalling pyflakes-2.2.0:\n","      Successfully uninstalled pyflakes-2.2.0\n","  Attempting uninstall: pycodestyle\n","    Found existing installation: pycodestyle 2.6.0\n","    Uninstalling pycodestyle-2.6.0:\n","      Successfully uninstalled pycodestyle-2.6.0\n","Successfully installed coverage-6.0.2 flake8-copyright-0.2.2 flake8-docstrings-1.6.0 m2r-0.2.1 mypy-0.910 pycodestyle-2.7.0 pyflakes-2.3.1 pytest-cov-3.0.0 pytest-flake8-1.0.7 pytest-mypy-0.8.1 sphinx-autodoc-typehints-1.12.0 sphinx-rtd-theme-1.0.0\n","Symlinking quant -> /home/aishwarya/anaconda3/lib/python3.8/site-packages/quant  \u001b[32mI-flit.install\u001b[m\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23372,"status":"ok","timestamp":1624011220605,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"},"user_tz":-330},"id":"5HZiRK9lukaT","outputId":"0ed09911-01ac-4d09-b29d-102b77dafc94"}},{"cell_type":"code","execution_count":null,"source":["import IPython\n","IPython.Application.instance().kernel.do_shutdown(True)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":5,"source":["%load_ext tensorboard"],"outputs":[],"metadata":{"id":"xHPE-4KN7abT"}},{"cell_type":"markdown","source":["Let’s see how a full precision resnet model performs on this dataset.We can train resnet using the following command"],"metadata":{"id":"JYOlVke7mMih"}},{"cell_type":"code","execution_count":6,"source":["!python examples/cifar100/cifar100.py --config examples/cifar100/cifar100_fp.yaml --experiment-name cifar100-fp"],"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar100/cifar-100-python.tar.gz\n","169009152it [04:53, 575844.79it/s]                                              \n","Extracting data/cifar100/cifar-100-python.tar.gz to data/cifar100/\n","Files already downloaded and verified\n","Traceback (most recent call last):\n","  File \"examples/cifar100/cifar100.py\", line 24, in <module>\n","    platform.run(experiment)\n","  File \"/home/aishwarya/anaconda3/lib/python3.8/site-packages/quant/common/compute_platform.py\", line 107, in run\n","    experiment.run(\n","  File \"/home/aishwarya/anaconda3/lib/python3.8/site-packages/quant/common/experiment.py\", line 108, in run\n","    train_epoch_metrics, test_epoch_metrics = self.task_fn(\n","  File \"/home/aishwarya/anaconda3/lib/python3.8/site-packages/quant/common/tasks.py\", line 131, in classification_task\n","    model = get_model(\n","  File \"/home/aishwarya/anaconda3/lib/python3.8/site-packages/quant/common/initialization.py\", line 121, in get_model\n","    raise ValueError(\n","ValueError: Device only has 0 GPUs, but 1 are specified.\n"]}],"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"Cd7pj-sNuAoF"}},{"cell_type":"markdown","source":["Now let us see how a quantized model compares to this model. We will use knowledge distillation to teach the quantized model. Full precision model can be used as reference for this.\n","\n","To make the quantized model refer to the full precision model, we need to edit the config file and set the teacher path."],"metadata":{"id":"AqiDqczBmPo_"}},{"cell_type":"code","execution_count":7,"source":["!python examples/cifar100/cifar100.py --config examples/cifar100/cifar100_ls1_weight_ls2_activation_kd.yaml --experiment-name cifar100-ls2"],"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Traceback (most recent call last):\n","  File \"examples/cifar100/cifar100.py\", line 24, in <module>\n","    platform.run(experiment)\n","  File \"/home/aishwarya/anaconda3/lib/python3.8/site-packages/quant/common/compute_platform.py\", line 107, in run\n","    experiment.run(\n","  File \"/home/aishwarya/anaconda3/lib/python3.8/site-packages/quant/common/experiment.py\", line 108, in run\n","    train_epoch_metrics, test_epoch_metrics = self.task_fn(\n","  File \"/home/aishwarya/anaconda3/lib/python3.8/site-packages/quant/common/tasks.py\", line 124, in classification_task\n","    teacher, kd_loss = get_teacher_and_kd_loss(\n","  File \"/home/aishwarya/anaconda3/lib/python3.8/site-packages/quant/common/tasks.py\", line 59, in get_teacher_and_kd_loss\n","    with open(teacher_config_path) as f:\n","FileNotFoundError: [Errno 2] No such file or directory: 'experiments/cifar100-teacher/config.yaml'\n"]}],"metadata":{"id":"8cC1WhCkurQE"}},{"cell_type":"code","execution_count":8,"source":["train_loss,test_loss=[],[]\n","train_top1_accuracy,test_top1_accuracy=[],[]\n","train_top5_accuracy,test_top5_accuracy=[],[]\n","import tensorflow as tf\n","for e in tf.compat.v1.train.summary_iterator('experiments/cifar100-ls2/tensorboard/events.out.tfevents.1615783285.76b24c522ac8.17901.0'):\n","    for v in e.summary.value:\n","      if v.tag=='Top-1_Accuracy/train':\n","        train_top1_accuracy.append(v.simple_value)\n","      if v.tag=='Top-5_Accuracy/test':\n","        test_top1_accuracy.append(v.simple_value)\n","      if v.tag=='Top-1_Accuracy/train':\n","        train_top5_accuracy.append(v.simple_value)\n","      if v.tag=='Top-5_Accuracy/test':\n","        test_top5_accuracy.append(v.simple_value)\n","      if v.tag=='Loss/train':\n","        train_loss.append(v.simple_value)\n","      if v.tag=='Loss/test':\n","        test_loss.append(v.simple_value)"],"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From /home/aishwarya/anaconda3/lib/python3.8/site-packages/tensorflow/python/summary/summary_iterator.py:31: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use eager execution and: \n","`tf.data.TFRecordDataset(path)`\n"]},{"output_type":"error","ename":"NotFoundError","evalue":"experiments/cifar100-ls2/tensorboard/events.out.tfevents.1615783285.76b24c522ac8.17901.0; No such file or directory","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-12429b6fe290>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_top5_accuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_top5_accuracy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'experiments/cifar100-ls2/tensorboard/events.out.tfevents.1615783285.76b24c522ac8.17901.0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'Top-1_Accuracy/train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/summary/summary_iterator.py\u001b[0m in \u001b[0;36msummary_iterator\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mA\u001b[0m \u001b[0miterator\u001b[0m \u001b[0mthat\u001b[0m \u001b[0myields\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mEvent\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0mbuffers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m   \"\"\"\n\u001b[0;32m---> 95\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_SummaryIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/summary/summary_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tf_record_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_record\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_record_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m               instructions)\n\u001b[0;32m--> 337\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_deprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/lib/io/tf_record.py\u001b[0m in \u001b[0;36mtf_record_iterator\u001b[0;34m(path, options)\u001b[0m\n\u001b[1;32m    169\u001b[0m   \"\"\"\n\u001b[1;32m    170\u001b[0m   \u001b[0mcompression_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTFRecordOptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_compression_type_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_pywrap_record_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecordIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFoundError\u001b[0m: experiments/cifar100-ls2/tensorboard/events.out.tfevents.1615783285.76b24c522ac8.17901.0; No such file or directory"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":487},"executionInfo":{"elapsed":2858,"status":"error","timestamp":1624011101713,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"},"user_tz":-330},"id":"xDUmcrqeMDEn","outputId":"1c7ea4a0-78a4-49f7-e48a-f07dfb22e7c5"}},{"cell_type":"code","execution_count":null,"source":["train_loss_fp,test_loss_fp=[],[]\n","train_top1_accuracy_fp,test_top1_accuracy_fp=[],[]\n","train_top5_accuracy_fp,test_top5_accuracy_fp=[],[]\n","import tensorflow as tf\n","try:\n","  for e in tf.compat.v1.train.summary_iterator('experiments/cifar100-fp/tensorboard/events.out.tfevents.1615781108.76b24c522ac8.11165.0'):\n","        for v in e.summary.value:\n","          if v.tag=='Top-1_Accuracy/train':\n","            train_top1_accuracy_fp.append(v.simple_value)\n","          if v.tag=='Top-5_Accuracy/test':\n","            test_top1_accuracy_fp.append(v.simple_value)\n","          if v.tag=='Top-1_Accuracy/train':\n","            train_top5_accuracy_fp.append(v.simple_value)\n","          if v.tag=='Top-5_Accuracy/test':\n","            test_top5_accuracy_fp.append(v.simple_value)\n","          if v.tag=='Loss/train':\n","            train_loss_fp.append(v.simple_value)\n","          if v.tag=='Loss/test':\n","            test_loss_fp.append(v.simple_value)\n","except:\n","      pass"],"outputs":[],"metadata":{"id":"BcWkjjOXxB4X"}},{"cell_type":"code","execution_count":null,"source":["len(train_loss[::3][:-1]),len(test_loss)\n","import matplotlib.pyplot as plt\n","\n","plt.rcParams['font.size'] = '22'\n","fig, ax = plt.subplots(1,2,figsize=(30,10))\n","\n","ax[0].plot(train_loss[::3][:-1],label='train Loss Quantized Model')\n","ax[0].plot(test_loss,label='test Loss Quantized Model')\n","ax[0].legend(prop={\"size\":24})\n","ax[0].set_xlabel('Epochs', fontsize=24)\n","ax[0].set_ylabel('Loss', fontsize=24)\n","\n","ax[1].plot(train_loss_fp[::15][:-1],label='train Loss Full precision')\n","ax[1].plot(test_loss_fp,label='test Loss Full Precision')\n","ax[1].legend(prop={\"size\":24})\n","ax[1].set_xlabel('Epochs', fontsize=24)\n","ax[1].set_ylabel('Loss', fontsize=24)\n","\n","plt.show()"],"outputs":[],"metadata":{"id":"XGtzUX9ay87Y"}},{"cell_type":"code","execution_count":null,"source":["plt.rcParams['font.size'] = '22'\n","fig, ax = plt.subplots(1,2,figsize=(30,10))\n","\n","ax[0].plot(train_top1_accuracy[::3][:-1],label='train top1 accuracy Quantized Model')\n","ax[0].plot(test_top1_accuracy,label='test top1 accuracy Quantized Model')\n","ax[0].legend(prop={\"size\":24})\n","ax[0].set_xlabel('Epochs', fontsize=24)\n","ax[0].set_ylabel('Top1 Accuracy', fontsize=24)\n","\n","ax[1].plot(train_top1_accuracy_fp[::15][:-1],label='train top1 accuracy Full precision')\n","ax[1].plot(test_top1_accuracy_fp,label='test top1 accuracy Full Precision')\n","ax[1].legend(prop={\"size\":24})\n","ax[1].set_xlabel('Epochs', fontsize=24)\n","ax[1].set_ylabel('Top1 Accuracy', fontsize=24)\n","\n","plt.show()"],"outputs":[],"metadata":{"id":"_O257esEzjrf"}},{"cell_type":"code","execution_count":null,"source":["plt.rcParams['font.size'] = '22'\n","fig, ax = plt.subplots(1,2,figsize=(30,10))\n","\n","ax[0].plot(train_top5_accuracy[::3][:-1],label='train top5 accuracy Quantized Model')\n","ax[0].plot(test_top5_accuracy,label='test top5 accuracy Quantized Model')\n","ax[0].legend(prop={\"size\":24})\n","ax[0].set_xlabel('Epochs', fontsize=24)\n","ax[0].set_ylabel('Top5 Accuracy', fontsize=24)\n","\n","ax[1].plot(train_top5_accuracy_fp[::15][:-1],label='train top5 accuracy Full precision')\n","ax[1].plot(test_top5_accuracy_fp,label='test top5 accuracy Full Precision')\n","ax[1].legend(prop={\"size\":24})\n","ax[1].set_xlabel('Epochs', fontsize=24)\n","ax[1].set_ylabel('Top5 Accuracy', fontsize=24)\n","\n","plt.show()"],"outputs":[],"metadata":{"id":"T_LrcTz9ztQ0"}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{}}],"metadata":{"colab":{"authorship_tag":"ABX9TyNvx96rVdJmptIA2LfcMZZY","name":"1_MLQuant.ipynb","version":""},"kernelspec":{"name":"python3","display_name":"Python 3.8.8 64-bit ('base': conda)"},"language_info":{"name":"python","version":"3.8.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"interpreter":{"hash":"f60a20abaabf5a658075b37fac599269792a9493ddacd7c14d8505185d5625aa"}},"nbformat":4,"nbformat_minor":2}