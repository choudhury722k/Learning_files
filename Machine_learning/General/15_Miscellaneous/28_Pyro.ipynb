{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"1_Pyro.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN+LEn/dVxUXsXf6yhsAoRh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Pyro – A Deep Probabilistic Programming Language "],"metadata":{"id":"-4Dg8Cse9yXV"}},{"cell_type":"markdown","source":["Pyro is a state-of-the-art programming language for deep probabilistic modelling. It is a flexible and scalable probabilistic programming language (PPL). It unifies the modern concepts of deep learning and Bayesian modelling. It has been written in Python and built on top of Pytorch. The Uber AI Labs introduced it in 2017. A team now maintains it at the Broad Institute in collaboration with its developer community.\n","\n","Are you unfamiliar with the term ‘probabilistic programming’? Refer to the ‘probabilistic programming’ section of [this](https://analyticsindiamag.com/introduction-to-infer-net-a-framework-for-probabilistic-programming-in-dotnet/) article before proceeding!\n","\n","Before moving on to Pyro’s details, we will briefly talk about its base library PyTorch, which it utilizes as an underlying tensor computation engine."],"metadata":{"id":"w1ImiDkMBbVd"}},{"cell_type":"markdown","source":["To read about it more, please refer [this](https://analyticsindiamag.com/guide-to-pyro-a-deep-probabilistic-programming-language/) article."],"metadata":{"id":"L7GMV4uABhB2"}},{"cell_type":"markdown","source":["## Code Implementation"],"metadata":{"id":"Y88nrLHvBuUO"}},{"cell_type":"markdown","source":["## Installation of Pyro\n","\n","NOTE: Pyro supports Python 3.6+ versions.\n","\n","Pyro can be installed using pip command as follows:\n","\n","pip install pyro-ppl"],"metadata":{"id":"wRHNuo0oBpnJ"}},{"cell_type":"code","execution_count":null,"source":["!python -m pip install pip --upgrade --user -q\n","!python -m pip install numpy pandas seaborn matplotlib scipy sklearn statsmodels tensorflow keras torch --user -q"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["!python -m pip install pyro-ppl --user -q"],"outputs":[],"metadata":{"id":"2XGbk2jK3f1u"}},{"cell_type":"markdown","source":["Suppose we have a weighing scale that tells us the weight of an object it holds. But the scale lacks accuracy and gives different measurements each time we weigh a given object. Assume, the scale’s errors form a normal distribution around that object’s actual weight, with a standard deviation of 0.1kg. We describe the scaling process and infer the true weight using Pyro in the implementation below."],"metadata":{"id":"FIeO-LnrB_kZ"}},{"cell_type":"code","execution_count":null,"source":["import IPython\n","IPython.Application.instance().kernel.do_shutdown(True)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["Import the required libraries and modules"],"metadata":{"id":"P78WFPwBCDBI"}},{"cell_type":"code","execution_count":null,"source":["import torch\n","import pyro\n","#assert pyro.__version__.startswith('1.5.2') # I'm writing this tutorial with version\n","                                          # 1.3.1. \n","pyro.set_rng_seed(0)\n","\n","import torch.distributions as dist\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import time\n","\n","%matplotlib inline\n","\n","import seaborn as sns"],"outputs":[],"metadata":{"id":"_FThJI2m3iM7"}},{"cell_type":"markdown","source":["Define the method which gives measurement observations"],"metadata":{"id":"6Yll8fy8CKHk"}},{"cell_type":"code","execution_count":null,"source":["def measure(weight):\n","    \n","    my_dist = dist.Normal(weight, 0.1)\n","    observation = my_dist.sample()\n","    return observation"],"outputs":[],"metadata":{"id":"QiKYpElm38lh"}},{"cell_type":"markdown","source":["Test the results when some weight of say 0.6kg is placed on the scale multiple times"],"metadata":{"id":"fSZcbj7cCNIU"}},{"cell_type":"code","execution_count":null,"source":["print(measure(0.6))\n","print(measure(0.6))\n","print(measure(0.6))\n","print(measure(0.6))"],"outputs":[],"metadata":{"id":"_rlfHFMp4Djf"}},{"cell_type":"markdown","source":["Note: The output may vary as many times as you execute the code.\n","\n","It can be seen from the output that every time we do not get the same measurement results. The observations are not always shown to be 0.6.\n","\n","  Now suppose we do not insist upon getting the exact measurement but want to predict an observation’s probability. For instance, what is the probability that the observed measurement will be above 0.66?"],"metadata":{"id":"-d8b6Z7YCQU4"}},{"cell_type":"code","execution_count":null,"source":["from scipy.stats import norm\n","\n","rough_measure = np.sum([measure(0.6) > 0.66 for i in range(1000)])/1000\n","print(f'Rough Estimate: {rough_measure}')\n"," \n","reasonable_measure = np.sum([measure(0.6) > 0.66 for i in range(10000)])/10000\n","print(f'Eeasonable Estimate: {reasonable_measure}')\n"," \n","good_measure = np.sum([measure(0.6) > 0.66 for i in range(100000)])/100000\n","print(f'Good Estimate: {good_measure}')\n"," \n","true_measure = 1.0 - norm(0.6, 0.1).cdf(0.66) \n","#0.6 is mean and 0.1 is standard deviation of the normal distribution. cdf(x) means the probability that a random sample will be less than or equal to x\n","print(f'True Estimate: {true_measure}')\n","#’cdf’ in scipy.stat.norm.cdf stands for cumulative distribution function\n"],"outputs":[],"metadata":{"id":"hRAQwq5f4Hqu"}},{"cell_type":"markdown","source":["Note: The output may vary as per the output of measure() method in each step.\n","\n","The process done in this step involves somewhat tedious calculations though it gives satisfactory results. \n","\n","  Now suppose we have to handle complex queries and the distribution of weights is also not normal. For instance, we have some observations about an object as follows:"],"metadata":{"id":"J4S64kvxCXaX"}},{"cell_type":"markdown","source":["First, form a torch tensor (multi-dimensional matrix having elements of a common datatype) of your observations. "],"metadata":{"id":"L4nToPY0CbH2"}},{"cell_type":"code","execution_count":null,"source":["# Pyro only works on torch tensors\n","observations = torch.tensor([0.77, 0.88, 0.67, 0.77, 0.82, 0.71])\n","print(f'Mean = {torch.mean(observations)}.')"],"outputs":[],"metadata":{"id":"zelbEUev4PVu"}},{"cell_type":"markdown","source":["  Define the Pyro model"],"metadata":{"id":"RmtzujtICdJr"}},{"cell_type":"code","execution_count":null,"source":["# Import our libraries\n","import pyro.distributions as pyrodist\n","\n","\n","# Define the process\n","def model(observations):\n","    \n","    # 1. Let's define a prior distribution on the likely values of our weight.\n","    # We'll use the mean of the observations as our initial guess\n","    weight_prior = pyrodist.Normal(0.769, 1.0)\n","    \n","    # 2. Sample a value from the weight distributoin\n","    weight = pyro.sample(\"weight1\", weight_prior)\n","    \n","    # 3. Now use a that value to define our scale (remember our scale gives us values\n","    # from Normal(weight, 0.1))\n","    my_dist = pyrodist.Normal(weight, 0.1)\n","    \n","    \n","    # 4. For each of the observations, let's draw a sample from our distribution.\n","    # HOWEVER, this is an observed sample, it's a sample that should be in line with\n","    # the observations we have\n","    \n","    for i,observation in enumerate(observations):\n","        measurement = pyro.sample(f'obs_{i}', my_dist, obs=observation)\n"],"outputs":[],"metadata":{"id":"LCdSzAlu4WQs"}},{"cell_type":"markdown","source":["Infer the actual weight of the object for which we got the observations.\n","\n","We are using the Hamiltonian Monte Carlo (HMC) algorithm belonging to the Markov Chain Monte Carlo (MCMC) family of algorithms."],"metadata":{"id":"krTyfKFfCg_e"}},{"cell_type":"code","execution_count":null,"source":["from pyro.infer import MCMC, HMC\n","\n","# 1. Clear storage of named parameters\n","pyro.clear_param_store()\n","\n","# 2. Define the MCMC kernel function we will employ, and tell\n","# it to use the model function we defined as the basis for\n","# sampling\n","my_kernel = HMC(model)\n","\n","\n","# 3. Define the MCMC algorithm with our specific\n","# implementation of choice and the number of samples\n","# to use to evaluate the most likely distribution\n","# of \"weight1\".\n","my_mcmc = MCMC(my_kernel,\n","               num_samples=30000,\n","               warmup_steps=150)\n","\n","# 4. Run the algorithm, send our observations \n","# (notice this is the parameter model(observations) recieves)\n","my_mcmc.run(observations)"],"outputs":[],"metadata":{"id":"eL2LMRF14gcH"}},{"cell_type":"markdown","source":["Plot the samples "],"metadata":{"id":"cAUlS19RCoRI"}},{"cell_type":"code","execution_count":null,"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","plt.figure(figsize=(15, 5))\n","sns.distplot(my_mcmc.get_samples()['weight1'].numpy(), kde=False, label=\"wt_1\")\n","plt.legend()\n","plt.xlabel(\"Weight of the object in kg\")\n","plt.ylabel(\"No. of observed samples\")\n","plt.show()\n"],"outputs":[],"metadata":{"id":"lWz2Za9G4kq9"}},{"cell_type":"markdown","source":["Know the predicted most likely weight of the object from the model’s summary."],"metadata":{"id":"Ek2VcVqECqub"}},{"cell_type":"code","execution_count":null,"source":["my_mcmc.summary(prob=0.95)"],"outputs":[],"metadata":{"id":"-yaymt4T6_fc"}}]}