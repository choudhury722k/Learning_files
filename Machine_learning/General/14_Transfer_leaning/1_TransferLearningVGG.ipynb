{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"1_TransferLearningVGG.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"Muy67VgSDL_-"},"source":["# **In this practice session we will learn about transfer learning**\n","# **We will build an image classifier with the help of a pretrained model**\n","\n","\n","**Data pre-processing**\n","  *   Import the required libraries\n","  *   Load the pretrained model   \n","\n","\n","**Building the model**\n","  *   Use a random image for classification\n","  *   Train the transfer model \n","  *   Make predictions\n","\n"]},{"cell_type":"markdown","metadata":{"id":"2lLUBrOpDyUZ"},"source":["## **Import the libraries required**"]},{"cell_type":"code","metadata":{"id":"bbfidKaj7TId","trusted":true},"source":["#import libraries for VGG\n","import cv2\n","from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n","from keras.applications.vgg16 import VGG16\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JZBitblzD2ab"},"source":["## **Load the VGG model**"]},{"cell_type":"code","metadata":{"id":"-iBDwhoI8xb8","trusted":true},"source":["#load the model and print the summary\n","model = VGG16()\n","print(model.summary())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AQUgZBS0D6V1"},"source":["## **Load the model weights to train**"]},{"cell_type":"code","metadata":{"id":"gwxHC--l7per","trusted":true},"source":["#load model weights\n","model = VGG16(weights=\"imagenet\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TWZUZNKgD_QJ"},"source":["## **Upload a picture for the model to predict**"]},{"cell_type":"code","metadata":{"id":"Ojy0wIybCxhm","trusted":true},"source":["#get an image of your choice and load it\n","from skimage import io\n","cat = io.imread('https://static.toiimg.com/thumb/msid-67586673,width-800,height-600,resizemode-75,imgsize-3918697,pt-32,y_pad-40/67586673.jpghttps://static.scientificamerican.com/sciam/cache/file/92E141F8-36E4-4331-BB2EE42AC8674DD3_source.jpg')\n","cat = cv2.resize(cat, dsize=(224, 224), interpolation=cv2.INTER_CUBIC)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"q4likoAoNzY0"},"source":["io.imshow(cat);"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5h7UYZg5ED6c"},"source":["## **Reshape the image**"]},{"cell_type":"code","metadata":{"id":"JUwM_DMR-uWA","trusted":true},"source":["#reshape the image\n","x = preprocess_input(cat)\n","x = x.reshape((1, x.shape[0], x.shape[1], x.shape[2]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6JQF07BTEHjZ"},"source":["## **Make the model predictions on the image**"]},{"cell_type":"code","metadata":{"id":"wsj5UkH69LT9","trusted":true},"source":["#make the predictions\n","pred = model.predict(x)\n","label = decode_predictions(pred)\n","label = label[0][0]\n","# print the classification of the cat\n","print('%s (%.2f%%)' % (label[1], label[2]*100))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z0gNcQw594Y_","trusted":false},"source":[""],"execution_count":null,"outputs":[]}]}