{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVpI1C1eK6QF"
   },
   "source": [
    "# Datetime Parsing with Pandas\n",
    "\n",
    "Time-series analysis and forecasting is one of the most widely applied machine learning problems. It finds applications in weather forecasting, earthquake prediction, space science, e-commerce, stock market prediction, medical sciences, and signal processing. While dealing with a time-series dataset, the data may contain the date, month, day, and time in any format. This is because people tend to use different date and time formats. Moreover, Python assumes a non-numbered entry as an object and a numbered entry as an integer or float. Hence, it is important to inform Python about the date and time entries. \n",
    "\n",
    "\n",
    "References:\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html\n",
    "\n",
    "https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mb2uvruOcdA3"
   },
   "source": [
    "In this practice session, we learn how to parse datetime using the Pandas library. Pandas is famous for its datetime parsing, processing, analysis and plotting functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ZlRGQbGcnSr"
   },
   "source": [
    "# Code Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a2TqH6H6cred"
   },
   "source": [
    "Import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!python -m pip install pip --upgrade --user -q --no-warn-script-location\n",
    "!python -m pip install numpy pandas seaborn matplotlib scipy statsmodels sklearn tensorflow keras torch torchvision \\\n",
    "    tqdm scikit-image --user -q --no-warn-script-location\n",
    "\n",
    "import IPython\n",
    "IPython.Application.instance().kernel.do_shutdown(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WtqVdCU_KrPz"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fMpOQFxwLQ_C"
   },
   "source": [
    "## Import ForestFire time-series data file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jcts969sct4r"
   },
   "source": [
    "Load some simple time-series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "iWNff4CfLVZr",
    "outputId": "67bf1d52-4792-481f-d174-d043286c94f3"
   },
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/RajkumarGalaxy/dataset/master/TimeSeries/Algerian_forest_fires.csv'\n",
    "forestfire = pd.read_csv(url)\n",
    "forestfire.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0WRGVdLbcw8s"
   },
   "source": [
    "We observe that there are three separate columns for day, month and year. Let’s look at the data type of these attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Z1Oe6ZJWQH3",
    "outputId": "cb5c4bf8-f551-4a38-fa49-499b50d60530"
   },
   "outputs": [],
   "source": [
    "forestfire.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZjYvfUn8czm1"
   },
   "source": [
    "Day, month and year values are in integers. We have to convert them to the datetime64 data type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p7ONPzXrc52B"
   },
   "source": [
    "We used the to_datetime method available in Pandas to parse the day, month and year columns into a single date column. We can drop the first three columns as they are redundant.  Further, we can check attributes’ data types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "Z-UbwHZcebXE",
    "outputId": "6a877450-bc4d-4f2c-dd62-966861eef8cc"
   },
   "outputs": [],
   "source": [
    "forestfire['date'] = pd.to_datetime(forestfire[['day', 'month', 'year']])\n",
    "forestfire.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yjsgHBOkjG0t",
    "outputId": "44a5e8a9-be5c-454e-eec2-0b7b03cdbb55"
   },
   "outputs": [],
   "source": [
    "forestfire.drop(columns=['day','month','year'], inplace=True)\n",
    "forestfire.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Geka3tMc8q1"
   },
   "source": [
    "The parsed date can be broken down into elements, i.e., day, month and year back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "mjbquGPmkCzn",
    "outputId": "f180b889-9c76-402c-8658-a5ffafb8704c"
   },
   "outputs": [],
   "source": [
    "days = forestfire['date'].dt.day\n",
    "months = forestfire['date'].dt.month\n",
    "years = forestfire['date'].dt.year\n",
    "\n",
    "recon = pd.DataFrame(zip(days,months,years), columns = ['DAY','MONTH','YEAR'])\n",
    "recon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "id": "5TOeHHfekq_Q",
    "outputId": "d632a60b-e299-44a5-ee93-b5a56d78da80"
   },
   "outputs": [],
   "source": [
    "forestfire['date'].value_counts().plot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "id": "XVMlicUFm2hJ",
    "outputId": "063b612f-bff5-4eab-b854-3112c87234af"
   },
   "outputs": [],
   "source": [
    "forestfire['date'].value_counts().resample('M').plot.line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o_FtgY7Vn1kO"
   },
   "source": [
    "## Air Quality Time-series Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j5LgALAqdA0k"
   },
   "source": [
    "Let’s load another time-series dataset that contains both date and time, but in two separate columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "IBL7cIF-ntzb",
    "outputId": "d1741416-1214-4d98-fa20-56aed05f1dec"
   },
   "outputs": [],
   "source": [
    "airquality_url = 'https://raw.githubusercontent.com/RajkumarGalaxy/dataset/master/TimeSeries/AirQualityUCI.csv'\n",
    "# read first 5 columns for better visual clarity\n",
    "airquality = pd.read_csv(airquality_url, sep=';').iloc[:,:5]\n",
    "airquality.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0f5fiNMdDGP"
   },
   "source": [
    "This time-series dataset contains Date in one column and Time in another column. Check the data types of the attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EpOt55bdpgl8",
    "outputId": "c2eaff9d-3dbb-4023-ef35-ad4a1a8dcd8b"
   },
   "outputs": [],
   "source": [
    "airquality.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ZOMzbGUdFjp"
   },
   "source": [
    "As expected, both Date and Time columns are in object data type. In contrast to our previous example, the Date attribute is the DD/MM/YYYY format and the Time attribute is in the HH.MM.SS format. Whenever we know the format of either date or time, we should pass it as an argument to the to_datetime method. Refer to the official documentation here for more information about different formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LsihILyrptWi"
   },
   "outputs": [],
   "source": [
    "airquality['DATE'] = pd.to_datetime(airquality['Date'], format='%d/%m/%Y')\n",
    "airquality['TIME'] = pd.to_datetime(airquality['Time'], format='%H.%M.%S')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lCddbeGOdHoV"
   },
   "source": [
    "We removed the original Date and Time columns as they were redundant to the new ones. The new attributes DATE and TIME are of datetime64 data type. As we have split the date in the previous example, we can split the time into an hour, minute and second elements using the dt method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hO-gbo1K2Des",
    "outputId": "7a3790a2-9c6d-46c7-8a1d-5f3922edadd3"
   },
   "outputs": [],
   "source": [
    "airquality.drop(columns=['Date', 'Time'], inplace=True)\n",
    "airquality.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "4snVe3NHPMKv",
    "outputId": "d8de5655-6875-4012-fe3e-462012857695"
   },
   "outputs": [],
   "source": [
    "airquality['DAY'] = airquality['DATE'].dt.day\n",
    "airquality['MONTH'] = airquality['DATE'].dt.month\n",
    "airquality['YEAR'] = airquality['DATE'].dt.year\n",
    "\n",
    "airquality['HOUR'] = airquality['TIME'].dt.hour\n",
    "airquality['MINUTE'] = airquality['TIME'].dt.minute\n",
    "airquality['SECOND'] = airquality['TIME'].dt.second\n",
    "\n",
    "airquality.drop(columns=['DATE', 'TIME'], inplace=True)\n",
    "airquality.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E92wKAeldOUQ"
   },
   "source": [
    "We can recall this example from the origin. The original dataset had 2 datetime columns: date (as object), time (as object). We converted them into 2 columns of datetime64 data type. In the last step, we split each element to form 6 new columns. However, we can merge all these split elements into a single feature of datetime64 data type to have every detail of date and time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "ORBhU0fxQlsX",
    "outputId": "55e65c76-1fa4-441e-e41e-f58d243f7245"
   },
   "outputs": [],
   "source": [
    "airquality['parsed'] = pd.to_datetime(airquality[['DAY','MONTH','YEAR','HOUR','MINUTE','SECOND']])\n",
    "airquality.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lF0rQvN5dRWz"
   },
   "source": [
    "In the above step, the default format `YYYY-mm-dd HH:MM:SS` is presented. But, we can have parsed datetime in the format we wish using the strftime method. Refer to the official documentation here for more formats. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "Lv8cyAJWUQMt",
    "outputId": "fdc2d230-82fc-4706-e731-1cf4a7b91440"
   },
   "outputs": [],
   "source": [
    "airquality['formatted_date'] = pd.to_datetime(airquality[['DAY','MONTH','YEAR','HOUR','MINUTE','SECOND']]).dt.strftime('%d %b %Y, %I.%M.%S %p')\n",
    "# display last 8 columns only for better visual clarity\n",
    "airquality.head().iloc[:,-8:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3fdqjEgQYlHC"
   },
   "source": [
    "## Landslide Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKECskV_dVLG"
   },
   "source": [
    "We discuss some more interesting things about datetime parsing with a complex time-series dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "IiYqBpEyYoN6",
    "outputId": "a132df02-e5db-4f7a-9c4d-2ab76321ffd0"
   },
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/RajkumarGalaxy/dataset/master/TimeSeries/landslides_data.csv'\n",
    "# load limited features only - for better visual clarity\n",
    "landslides = pd.read_csv(url).loc[:,['date', 'country_code', 'state/province', 'hazard_type']]\n",
    "landslides.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nXK94MSYdXYT"
   },
   "source": [
    "It is observed that the feature `date` has different formats. Hence, we can not parse it with a predefined format. Let’s have a thorough check for any other formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2dcpJ-gFa56q",
    "outputId": "a14a850f-4e6d-44d9-e9b9-5940d201ebc5"
   },
   "outputs": [],
   "source": [
    "length = landslides['date'].str.len()\n",
    "length.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WuWnAR1JdbWl"
   },
   "source": [
    "Date is presented in five different lengths. Lengths 7 and 8 may refer to a common format. Length 10 may refer to another format. Lengths 16 and 17 may refer to some other format.\n",
    "\n",
    "Let’s do some analysis to find the hidden truth using NumPy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "ALb-0LL_b3c7",
    "outputId": "7e5c3f98-d3f8-4244-ab84-0f5a13629929"
   },
   "outputs": [],
   "source": [
    "ind_7 = np.where([length==7])[1][0]\n",
    "ind_8 = np.where([length==8])[1][0]\n",
    "ind_10 = np.where([length==10])[1][0]\n",
    "ind_16 = np.where([length==16])[1][0]\n",
    "ind_17 = np.where([length==17])[1][0]\n",
    "\n",
    "# load one example row for each date length\n",
    "landslides.loc[[ind_7,ind_8,ind_10,ind_16,ind_17]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h2EUdS_Bdd8S"
   },
   "source": [
    "As we guessed, there are three different date formats in the dataset. The date presented along with time is the least available format with just 4 rows. Hence, we drop these 4 rows for the sake of simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YzCSU_SOew4h"
   },
   "outputs": [],
   "source": [
    "drop_ind = np.where([length>=16])[1]\n",
    "landslides.drop(index=drop_ind, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XgYB38D-fstq",
    "outputId": "aa490ff0-caee-4bab-b43d-e8a23e240ba0"
   },
   "outputs": [],
   "source": [
    "length = landslides['date'].str.len()\n",
    "length.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PjqmF9oEdg-l"
   },
   "source": [
    "We need not worry about different formats in date. Pandas’ `to_datetime` method takes an optional boolean argument `infer_datetime_format`. If we pass `True` as the argument, Pandas will analyze the format and convert it suitably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "P9eNPfLcgJg1",
    "outputId": "284d2521-35cc-40a5-9cad-fcdae741f01e"
   },
   "outputs": [],
   "source": [
    "landslides['parsed_date'] = pd.to_datetime(landslides['date'], infer_datetime_format=True)\n",
    "landslides.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MlEOTKGEdnHl"
   },
   "source": [
    "Let’s remove the original column to avoid redundancy. We can explore some more features that Pandas provide along with datetime parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "31EIHKk-iA1R",
    "outputId": "806b1fed-08cd-4693-d426-66b6381d9f9f"
   },
   "outputs": [],
   "source": [
    "landslides.drop(columns=['date'], inplace=True)\n",
    "landslides.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DYDhwNBddpZx"
   },
   "source": [
    "We can calculate the number of landslides per day by analyzing the parsed_date and plot it using Pandas plotting. Pandas plotting is a simple interface built on top of Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "9xmnkCO9iXAH",
    "outputId": "6c6caf52-999d-4993-ebc9-40d203c0d0af"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "landslides['parsed_date'].value_counts().sort_values().plot.line()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMZAV3USdsjH"
   },
   "source": [
    "Pandas provides a powerful analysis method, named resample for datetime64 features. This method permits different analysis year-wise, month-wise, day-wise, and so on. This helps us find the pattern among the time-series data.\n",
    "\n",
    "The total number of yearly landslides can be calculated as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "AeBUJOVajPIv",
    "outputId": "3f6cad18-399d-408a-b636-9ad14f622747"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "landslides['parsed_date'].value_counts().resample('Y').sum().plot.bar(color='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iopavewidv1D"
   },
   "source": [
    "Year-wise mean slides can be calculated as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 418
    },
    "id": "DsjjrV2zkdoh",
    "outputId": "31e544bf-0189-447b-d4d8-accf097a668b"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "landslides['parsed_date'].value_counts().resample('Y').mean().plot.bar(color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A6AePbpZdyiu"
   },
   "source": [
    "According to the plot, the year 2010 had more landslides than any other year (as per the dataset). \n",
    "\n",
    "The total number of landslides calculated in a month-wise manner is as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "oXg8UmD4mNME",
    "outputId": "56f7e2ae-f088-4b41-ac7d-7b381ef19f81"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "landslides['parsed_date'].value_counts().resample('M').sum().plot.area(color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MqArsKEsd2S-"
   },
   "source": [
    "#**Related Articles:**\n",
    "\n",
    "> * [Date Time Parsing with Pandas](https://analyticsindiamag.com/datetime-parsing-with-pandas/)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO95P0HJV11CqrohzyRrUZN",
   "collapsed_sections": [],
   "name": "2_Date_Time_Parsing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
