{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"18_Tensorflow_Core.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOyPOLp+LYKrSa/2CwM17hG"},"kernelspec":{"name":"python3","display_name":"Python 3.8.8 64-bit ('base': conda)"},"language_info":{"name":"python","version":"3.8.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"interpreter":{"hash":"f60a20abaabf5a658075b37fac599269792a9493ddacd7c14d8505185d5625aa"}},"cells":[{"cell_type":"markdown","source":["# **Tensorflow Core**"],"metadata":{"id":"PVZtxGu3ihLy"}},{"cell_type":"markdown","source":["Time series refers to plotting data points in sequential time order. Now those data points can use a data of an athlete’s performance, cricket player according to most run in one-day, weather reading every month, the daily closing price of company stock. Time series analysis is also the same term, but it is concerned with taking that data-points and cleaning, understanding, and forecasting them using some tools or programming languages. Now time series is sometimes called panel data. Panel data is a general class, multidimensional dataset, on the side time series dataset is a one-dimensional panel."],"metadata":{"id":"O0XFe-JAkiLG"}},{"cell_type":"markdown","source":["To read about it more, please refer [this](https://analyticsindiamag.com/time-series-forecasting-using-tensorflow-core/) article."],"metadata":{"id":"_TsJj05slL-Z"}},{"cell_type":"markdown","source":["# **Tensorflow models for forecasting**"],"metadata":{"id":"zbjscXablRb5"}},{"cell_type":"markdown","source":["Now time series forecasting or predictive modeling can be done using any framework, TensorFlow provides us a few different styles of models for like Convolution Neural Network (CNN), Recurrent Neural Networks (RNN), you can forecast a single time step using a single feature or you can forecast multiple steps and make all predictions at once using Single-shot."],"metadata":{"id":"OYiXChLLle-J"}},{"cell_type":"markdown","source":["## **Setup**"],"metadata":{"id":"4WFW9Wv_lg26"}},{"cell_type":"markdown","source":["The necessary module you need import to get started they will help you in modeliing, visulization, file handling, data exploration and all sort of thing."],"metadata":{"id":"c_zBJqMqljtS"}},{"cell_type":"code","execution_count":null,"source":["\n","!python -m pip install pip --upgrade --user -q --no-warn-script-location\n","!python -m pip install numpy pandas seaborn matplotlib scipy statsmodels sklearn tensorflow keras torch torchvision \\\n","    tqdm scikit-image pmdarima --user -q --no-warn-script-location\n","\n","import IPython\n","IPython.Application.instance().kernel.do_shutdown(True)\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["import os\n","import datetime\n","import IPython\n","import IPython.display\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import tensorflow as tf\n","mpl.rcParams['figure.figsize'] = (8, 6)\n","mpl.rcParams['axes.grid'] = False"],"outputs":[],"metadata":{"id":"K2HArReBidtj","executionInfo":{"status":"ok","timestamp":1623658515070,"user_tz":-330,"elapsed":2924,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"markdown","source":["Lets’s take the [Weather dataset](https://www.bgc-jena.mpg.de/wetter/) from Max Planck Institute for Biogeochemistry , this dataset contains 14 different feature: air temperature, humidity, atmospheric pressure. From 2003 these datapoints were collected on basis of every 10 minute. Let’s explore the dataset:"],"metadata":{"id":"cv9Nq1LllorE"}},{"cell_type":"code","execution_count":null,"source":["#download the zip file of dataset\n","file_path = tf.keras.utils.get_file(\n","origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip',\n","    fname='jena_climate_2009_2016.csv.zip',\n","    extract=True)\n","csv_path, _ = os.path.splitext(file_path)\n","#explore the dataset\n","df = pd.read_csv(csv_path)\n","df = df[5::6]\n","date_time = pd.to_datetime(df.pop('Date Time'), format='%d.%m.%Y %H:%M:%S')\n","df.head()"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":223},"id":"CDnIUxdtlvEU","executionInfo":{"status":"ok","timestamp":1623658541769,"user_tz":-330,"elapsed":1548,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"504ac238-db45-414f-806c-eda1d3d82d1c"}},{"cell_type":"code","execution_count":null,"source":["#Data visualization over the years with some features\n","plot_cols = ['T (degC)', 'p (mbar)', 'rho (g/m**3)']\n","plot_features = df[plot_cols]\n","plot_features.index = date_time\n","_ = plot_features.plot(subplots=True)\n","plot_features = df[plot_cols][:480]\n","plot_features.index = date_time[:480]\n","_ = plot_features.plot(subplots=True)"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":540},"id":"OIGu8IAilzUE","executionInfo":{"status":"ok","timestamp":1623658547741,"user_tz":-330,"elapsed":3498,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"64b2dfe3-303c-4efd-c682-72340fc96ba6"}},{"cell_type":"markdown","source":["Let’s clean data for better modelling and visualization:"],"metadata":{"id":"-Aypm0iol18g"}},{"cell_type":"code","execution_count":null,"source":["wv = df['wv (m/s)']\n","bad_wv = wv == -9999.0\n","wv[bad_wv] = 0.0\n","max_wv = df['max. wv (m/s)']\n","bad_max_wv = max_wv == -9999.0\n","max_wv[bad_max_wv] = 0.0\n","df['wv (m/s)'].min()\n","#convert wind direction and velocity column into a wind vector\n","wv = df.pop('wv (m/s)')\n","max_wv = df.pop('max. wv (m/s)')\n","# Convertion to radians.\n","wd_rad = df.pop('wd (deg)')*np.pi / 180\n","#wind x and y components.\n","df['Wx'] = wv*np.cos(wd_rad)\n","df['Wy'] = wv*np.sin(wd_rad)\n","# max wind x and y components dataframe.\n","df['max Wx'] = max_wv*np.cos(wd_rad)\n","df['max Wy'] = max_wv*np.sin(wd_rad)\n","#let’s plot\n","plt.hist2d(df['Wx'], df['Wy'], bins=(50, 50), vmax=400)\n","plt.colorbar()\n","plt.xlabel('Wind X [m/s]')\n","plt.ylabel('Wind Y [m/s]')\n","ax = plt.gca()\n","ax.axis('tight')"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":301},"id":"80rqA-Zxl5R7","executionInfo":{"status":"ok","timestamp":1623658569518,"user_tz":-330,"elapsed":709,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"acf6612c-323a-4308-8836-70c4b830b134"}},{"cell_type":"markdown","source":["Let’s convert date time in seconds and convert the signals to sin cos format :"],"metadata":{"id":"NMt6l7orl7Aj"}},{"cell_type":"code","execution_count":null,"source":["timestamp_s = date_time.map(datetime.datetime.timestamp)\n","day = 24*60*60\n","year = (365.2425)*day\n","df['Day sin'] = np.sin(timestamp_s * (2 * np.pi / day))\n","df['Day cos'] = np.cos(timestamp_s * (2 * np.pi / day))\n","df['Year sin'] = np.sin(timestamp_s * (2 * np.pi / year))\n","df['Year cos'] = np.cos(timestamp_s * (2 * np.pi / year))"],"outputs":[],"metadata":{"id":"mjXSUFi7l9AP","executionInfo":{"status":"ok","timestamp":1623658585130,"user_tz":-330,"elapsed":1059,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"markdown","source":["Plot  time of day signal sin and cos function"],"metadata":{"id":"yDvjRPnCl80R"}},{"cell_type":"code","execution_count":null,"source":["plt.plot(np.array(df['Day sin'])[:25])\n","plt.plot(np.array(df['Day cos'])[:25])\n","plt.xlabel('Time [h]')\n","plt.title('Time of day signal')"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":313},"id":"SK43tXc5mA5W","executionInfo":{"status":"ok","timestamp":1623658600469,"user_tz":-330,"elapsed":503,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"6ef34778-af88-46a2-ec62-d13351367279"}},{"cell_type":"markdown","source":["Split the data for time series forecasting"],"metadata":{"id":"OdPu4DkSmCjz"}},{"cell_type":"code","execution_count":null,"source":["column_indices = {name: i for i, name in enumerate(df.columns)}\n","n = len(df)\n","train_df = df[0:int(n*0.7)]\n","val_df = df[int(n*0.7):int(n*0.9)]\n","test_df = df[int(n*0.9):]\n","num_features = df.shape[1]"],"outputs":[],"metadata":{"id":"kVGuZUV6mEK8","executionInfo":{"status":"ok","timestamp":1623658613360,"user_tz":-330,"elapsed":414,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"markdown","source":["Data normalization:as it is a crucial step before training your neural network, for normalization we are going to subtract the mean and divide by the standard deviation."],"metadata":{"id":"JJT4aiMamF6T"}},{"cell_type":"code","execution_count":null,"source":["train_mean = train_df.mean()\n","train_std = train_df.std()\n","\n","train_df = (train_df - train_mean) / train_std\n","val_df = (val_df - train_mean) / train_std\n","test_df = (test_df - train_mean) / train_std"],"outputs":[],"metadata":{"id":"yCggY_T5mHfV","executionInfo":{"status":"ok","timestamp":1623658627287,"user_tz":-330,"elapsed":612,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"markdown","source":["Let’s plot the violenplot of all the feature to see if data is biased "],"metadata":{"id":"jPOWxHHImJEK"}},{"cell_type":"code","execution_count":null,"source":["df_std = (df - train_mean) / train_std\n","df_std = df_std.melt(var_name='Column', value_name='Normalized')\n","plt.figure(figsize=(12, 6))\n","ax = sns.violinplot(x='Column', y='Normalized', data=df_std)\n","_ = ax.set_xticklabels(df.keys(), rotation=90)"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":467},"id":"4AWR8tC2mLO1","executionInfo":{"status":"ok","timestamp":1623658649208,"user_tz":-330,"elapsed":6738,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"b309aa64-bff5-4a5f-d78e-62b01334de92"}},{"cell_type":"markdown","source":["## **Data Windowing**"],"metadata":{"id":"HEf3OE-VmNK0"}},{"cell_type":"markdown","source":["In tensorflow, we have to do data windowing of our input dataframe, so that it can be used in further multiple models and we can see which forecast better. Also, rest of this section defines a WindowGenerator class. This class will contain all the logic for the input and label indices.\n","\n","It also handles the indexes and offset, split window feature into (feauture, labels) pairs and plot the content of resulting window. Also this class will generate batches of these windows from train, test, and evaluation dataset, using tf.data.Dataset."],"metadata":{"id":"qW3scN3Gm7CB"}},{"cell_type":"code","execution_count":null,"source":["class WindowGenerator():\n","  def __init__(self, input_width, label_width, shift,\n","               train_df=train_df, val_df=val_df, test_df=test_df,\n","               label_columns=None):\n","    # Store the raw data.\n","    self.train_df = train_df\n","    self.val_df = val_df\n","    self.test_df = test_df\n","\n","    # Work out the label column indices.\n","    self.label_columns = label_columns\n","    if label_columns is not None:\n","      self.label_columns_indices = {name: i for i, name in\n","                                    enumerate(label_columns)}\n","    self.column_indices = {name: i for i, name in\n","                           enumerate(train_df.columns)}\n","\n","    # Work out the window parameters.\n","    self.input_width = input_width\n","    self.label_width = label_width\n","    self.shift = shift\n","\n","    self.total_window_size = input_width + shift\n","\n","    self.input_slice = slice(0, input_width)\n","    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n","\n","    self.label_start = self.total_window_size - self.label_width\n","    self.labels_slice = slice(self.label_start, None)\n","    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n","\n","  def __repr__(self):\n","    return '\\n'.join([\n","        f'Total window size: {self.total_window_size}',\n","        f'Input indices: {self.input_indices}',\n","        f'Label indices: {self.label_indices}',\n","        f'Label column name(s): {self.label_columns}'])"],"outputs":[],"metadata":{"id":"4dNgXC4Lm9XC","executionInfo":{"status":"ok","timestamp":1623658847911,"user_tz":-330,"elapsed":406,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"markdown","source":["With the help of above code you can create window of your choice, let’s create a demo window:"],"metadata":{"id":"z4ROhldjm_Ml"}},{"cell_type":"code","execution_count":null,"source":["w1 = WindowGenerator(input_width=6, label_width=1, shift=1,\n","                     label_columns=['T (degC)'])\n","w1"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DQkn8omJnA7q","executionInfo":{"status":"ok","timestamp":1623658862573,"user_tz":-330,"elapsed":596,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"011e5cff-244d-4d07-9540-99c274763edf"}},{"cell_type":"markdown","source":["Split\n","Given a list consecutive inputs, the `split_window` method will convert them to a window of inputs and a window of labels.\n","\n","The example `w2`, above, will be split like this:\n","\n","![The initial window is all consecutive samples, this splits it into an (inputs, labels) pairs](images/split_window.png)\n","\n","This diagram doesn't show the `features` axis of the data, but this `split_window` function also handles the `label_columns` so it can be used for both the single output and multi-output examples."],"metadata":{"id":"kJaUyTWQJd-L"}},{"cell_type":"code","execution_count":null,"source":["def split_window(self, features):\n","  inputs = features[:, self.input_slice, :]\n","  labels = features[:, self.labels_slice, :]\n","  if self.label_columns is not None:\n","    labels = tf.stack(\n","        [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n","        axis=-1)\n","\n","  # Slicing doesn't preserve static shape information, so set the shapes\n","  # manually. This way the `tf.data.Datasets` are easier to inspect.\n","  inputs.set_shape([None, self.input_width, None])\n","  labels.set_shape([None, self.label_width, None])\n","\n","  return inputs, labels\n","\n","WindowGenerator.split_window = split_window"],"outputs":[],"metadata":{"id":"W4KbxfzqkXPW","executionInfo":{"status":"ok","timestamp":1623660711406,"user_tz":-330,"elapsed":547,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"markdown","source":["Create tensorflow dataset using tf.data.Datasets utilities and create a make_dataset function that will take the time-series dataframe."],"metadata":{"id":"SpZZP_SanL67"}},{"cell_type":"markdown","source":[],"metadata":{"id":"h3SM4sVLuBSX"}},{"cell_type":"code","execution_count":null,"source":["def make_dataset(self, data):\n","  data = np.array(data, dtype=np.float32)\n","  ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n","      data=data,\n","      targets=None,\n","      sequence_length=self.total_window_size,\n","      sequence_stride=1,\n","      shuffle=True,\n","      batch_size=32,)\n","  ds = ds.map(self.split_window)\n","  return ds\n","WindowGenerator.make_dataset = make_dataset"],"outputs":[],"metadata":{"id":"_9g14QscnN6B","executionInfo":{"status":"ok","timestamp":1623658915815,"user_tz":-330,"elapsed":459,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"markdown","source":["Now WindowGenerator is holding the train, test and validation data, Let’s procede further for training\n"],"metadata":{"id":"l682RlrsnRIv"}},{"cell_type":"code","execution_count":null,"source":["def make_dataset(self, data):\n","  data = np.array(data, dtype=np.float32)\n","  ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n","      data=data,\n","      targets=None,\n","      sequence_length=self.total_window_size,\n","      sequence_stride=1,\n","      shuffle=True,\n","      batch_size=32,)\n","  ds = ds.map(self.split_window)\n","  return ds\n","WindowGenerator.make_dataset = make_dataset"],"outputs":[],"metadata":{"id":"rfa_BIMPnNwY","executionInfo":{"status":"ok","timestamp":1623658937421,"user_tz":-330,"elapsed":412,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"markdown","source":["## **Using Tensorflow Single Step model**"],"metadata":{"id":"qNSIBS9YnVW3"}},{"cell_type":"markdown","source":["inputs(t=0) –>\tModel –>\tPredictions(t=) \tLabels(t=2)"],"metadata":{"id":"lHIhT2z_naR9"}},{"cell_type":"markdown","source":["This model is used when we have this sort of simplest data to forecast and it return a single predicted value(predicting 1hour in future).\n","\n","As we already setup the WindoowGenerator object, let’s configure it to run for single step model i.e. (input, label) pair."],"metadata":{"id":"522spcy0ndHi"}},{"cell_type":"code","execution_count":null,"source":["def make_dataset(self, data):\n","  data = np.array(data, dtype=np.float32)\n","  ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n","      data=data,\n","      targets=None,\n","      sequence_length=self.total_window_size,\n","      sequence_stride=1,\n","      shuffle=True,\n","      batch_size=32,)\n","  ds = ds.map(self.split_window)\n","  return ds\n","WindowGenerator.make_dataset = make_dataset"],"outputs":[],"metadata":{"id":"rFEsEGPnnguj","executionInfo":{"status":"ok","timestamp":1623658992514,"user_tz":-330,"elapsed":392,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"markdown","source":["The `WindowGenerator` object holds training, validation and test data. Add properties for accessing them as `tf.data.Datasets` using the above `make_dataset` method. Also add a standard example batch for easy access and plotting:"],"metadata":{"id":"FDAewAtFtymL"}},{"cell_type":"code","execution_count":null,"source":["@property\n","def train(self):\n","  return self.make_dataset(self.train_df)\n","\n","@property\n","def val(self):\n","  return self.make_dataset(self.val_df)\n","\n","@property\n","def test(self):\n","  return self.make_dataset(self.test_df)\n","\n","@property\n","def example(self):\n","  \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n","  result = getattr(self, '_example', None)\n","  if result is None:\n","    # No example batch was found, so get one from the `.train` dataset\n","    result = next(iter(self.train))\n","    # And cache it for next time\n","    self._example = result\n","  return result\n","\n","WindowGenerator.train = train\n","WindowGenerator.val = val\n","WindowGenerator.test = test\n","WindowGenerator.example = example"],"outputs":[],"metadata":{"id":"zTNG6U3It02_","executionInfo":{"status":"ok","timestamp":1623660649068,"user_tz":-330,"elapsed":684,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"markdown","source":["Create baseline class to compare your model outputs with it:"],"metadata":{"id":"iAdeBSkMnjF3"}},{"cell_type":"code","execution_count":null,"source":["class Baseline(tf.keras.Model):\n","  def __init__(self, label_index=None):\n","    super().__init__()\n","    self.label_index = label_index\n","\n","  def call(self, inputs):\n","    if self.label_index is None:\n","      return inputs\n","    result = inputs[:, :, self.label_index]\n","    return result[:, :, tf.newaxis]"],"outputs":[],"metadata":{"id":"KoGdnUfvnktu","executionInfo":{"status":"ok","timestamp":1623660649464,"user_tz":-330,"elapsed":8,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"markdown","source":["Evaluate the model:"],"metadata":{"id":"wC-yhBhsnmri"}},{"cell_type":"code","execution_count":null,"source":["single_step_window = WindowGenerator(\n","    input_width=1, label_width=1, shift=1,\n","    label_columns=['T (degC)'])\n","single_step_window"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ErcQL212ppDB","executionInfo":{"status":"ok","timestamp":1623660650565,"user_tz":-330,"elapsed":15,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"35daf662-fb84-41b6-cf62-93900ccb1e04"}},{"cell_type":"code","execution_count":null,"source":["baseline = Baseline(label_index=column_indices['T (degC)'])\n","baseline.compile(loss=tf.losses.MeanSquaredError(),\n","                 metrics=[tf.metrics.MeanAbsoluteError()])\n","val_performance = {}\n","performance = {}\n","val_performance['Baseline'] = baseline.evaluate(single_step_window.val)\n","performance['Baseline'] = baseline.evaluate(single_step_window.test, verbose=0)"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w8eU6FktnoYL","executionInfo":{"status":"ok","timestamp":1623660724385,"user_tz":-330,"elapsed":4674,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"51721249-0fca-40da-f657-47b3302b8a1f"}},{"cell_type":"markdown","source":["Let’s create a wider WindowGenerator that generates window 24h "],"metadata":{"id":"3CihsNfwo4go"}},{"cell_type":"code","execution_count":null,"source":["wide_window = WindowGenerator(\n","    input_width=24, label_width=24, shift=1,\n","    label_columns=['T (degC)'])\n","\n","wide_window"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Go9P7aYyo6Yg","executionInfo":{"status":"ok","timestamp":1623660724387,"user_tz":-330,"elapsed":14,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"675a4b5a-5ec3-4ef4-9ba1-bc33f97f18d9"}},{"cell_type":"code","execution_count":null,"source":["print('Input shape:', wide_window.example[0].shape)\n","print('Output shape:', baseline(wide_window.example[0]).shape)"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nkhe3RVto-i-","executionInfo":{"status":"ok","timestamp":1623660726065,"user_tz":-330,"elapsed":8,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"b8762e71-a969-41ff-f746-c18eb961161a"}},{"cell_type":"markdown","source":["## **Plot baseline model forecasting**"],"metadata":{"id":"YMvvfSCkpBDJ"}},{"cell_type":"code","execution_count":null,"source":["def plot(self, model=None, plot_col='T (degC)', max_subplots=3):\n","  inputs, labels = self.example\n","  plt.figure(figsize=(12, 8))\n","  plot_col_index = self.column_indices[plot_col]\n","  max_n = min(max_subplots, len(inputs))\n","  for n in range(max_n):\n","    plt.subplot(max_n, 1, n+1)\n","    plt.ylabel(f'{plot_col} [normed]')\n","    plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n","             label='Inputs', marker='.', zorder=-10)\n","\n","    if self.label_columns:\n","      label_col_index = self.label_columns_indices.get(plot_col, None)\n","    else:\n","      label_col_index = plot_col_index\n","\n","    if label_col_index is None:\n","      continue\n","\n","    plt.scatter(self.label_indices, labels[n, :, label_col_index],\n","                edgecolors='k', label='Labels', c='#2ca02c', s=64)\n","    if model is not None:\n","      predictions = model(inputs)\n","      plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n","                  marker='X', edgecolors='k', label='Predictions',\n","                  c='#ff7f0e', s=64)\n","\n","    if n == 0:\n","      plt.legend()\n","\n","  plt.xlabel('Time [h]')\n","\n","WindowGenerator.plot = plot"],"outputs":[],"metadata":{"id":"Sn7tV5zcuOfe","executionInfo":{"status":"ok","timestamp":1623660753407,"user_tz":-330,"elapsed":413,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"code","execution_count":null,"source":["wide_window.plot(baseline)"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":497},"id":"hdi3KMEupEBd","executionInfo":{"status":"ok","timestamp":1623660756300,"user_tz":-330,"elapsed":1268,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"13609446-11eb-4954-d164-25893aa6534f"}},{"cell_type":"markdown","source":["#**Related Articles:**\n","\n","> * [Tensorflow Core](https://analyticsindiamag.com/time-series-forecasting-using-tensorflow-core/)\n","\n","> * [LSTM RNN on Foreign Exchange Rate Prediction](https://analyticsindiamag.com/foreign-exchange-rate-prediction-using-lstm-recurrent-neural-network/)\n","\n","> * [Pyflux](https://analyticsindiamag.com/pyflux-guide-python-library-for-time-series-analysis-and-prediction/)\n","\n","> * [Atspy](https://analyticsindiamag.com/hands-on-guide-to-atspy-for-automating-the-time-series-forecasting/)\n","\n","> * [AutoTS](https://analyticsindiamag.com/hands-on-guide-to-autots-effective-model-selection-for-multiple-time-series/)"],"metadata":{"id":"MqArsKEsd2S-"}}]}