{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"21_TadGAN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMhZqMINcnDLNDurGdwnaqf"},"kernelspec":{"name":"python3","display_name":"Python 3.8.8 64-bit ('base': conda)"},"language_info":{"name":"python","version":"3.8.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"interpreter":{"hash":"f60a20abaabf5a658075b37fac599269792a9493ddacd7c14d8505185d5625aa"}},"cells":[{"cell_type":"markdown","source":["# **TadGAN**"],"metadata":{"id":"6di-lq8LQkfj"}},{"cell_type":"markdown","source":["Recently, a group of researchers from MIT came up with an idea of Time Series Anomaly Detection using Generative Adversarial Networks(TadGAN)- combining deep learning based approaches and GAN approaches together and developed a benchmarking system for Time Series Anomaly Detection. You can read more about the algorithmic part, here.\n","\n","In this analysis, we are going to discuss practical implementation of TadGAN through Orion. Orion is a machine learning python-based library for unsupervised time series anomaly detection. This toolkit provides various verified pipelines known as Orion pipelines and uses various AutoML tools developed under DATA TO AI at MIT. Lets dig in!"],"metadata":{"id":"HoMT8jhtQiQy"}},{"cell_type":"markdown","source":["To read about it more, please refer [this](https://analyticsindiamag.com/hands-on-guide-to-tadgan-with-python-codes/) article."],"metadata":{"id":"MlCB2FbmQnxS"}},{"cell_type":"markdown","source":["# **Installing Orion Library**"],"metadata":{"id":"ii1eV98Ja71a"}},{"cell_type":"markdown","source":["Easiest way to install is through pip."],"metadata":{"id":"ovnaVSD2Q1vr"}},{"cell_type":"code","execution_count":null,"source":["\n","!python -m pip install pip --upgrade --user -q --no-warn-script-location\n","!python -m pip install numpy pandas seaborn matplotlib scipy statsmodels sklearn tensorflow keras torch torchvision \\\n","    tqdm scikit-image pmdarima --user -q --no-warn-script-location\n","\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["import IPython\n","IPython.Application.instance().kernel.do_shutdown(True)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# install dependencies then restart kernel and run again\n","!python -m pip install orion-ml --user -q\n","!python -m pip install 'urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1' --user -q\n","\n","# ! git clone https://github.com/signals-dev/Orion.git\n","#moving all the required modules in current working directory\n","# ! git clone https://github.com/signals-dev/Orion.git\n","# ! mv Orion/notebooks/tulog/* ."],"outputs":[],"metadata":{"id":"5h-jxv6_X54T"}},{"cell_type":"code","execution_count":null,"source":["import IPython\n","IPython.Application.instance().kernel.do_shutdown(True)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["# **Importing required libraries**"],"metadata":{"id":"Jt8iCtqcuGYg"}},{"cell_type":"markdown","source":["Importing all the required modules and functions"],"metadata":{"id":"CjuROEoMQ3_A"}},{"cell_type":"code","execution_count":null,"source":["# general imports \n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","#importing sklearn module\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import MinMaxScaler\n","#utils.py contains all the plot function.\n","from utils import plot, plot_ts, plot_rws, plot_error, unroll_ts"],"outputs":[],"metadata":{"id":"7YaVs_YSuGFn","executionInfo":{"status":"ok","timestamp":1623673814945,"user_tz":-330,"elapsed":390,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"markdown","source":["# **Importing the dataset**"],"metadata":{"id":"01B5ObECi4Il"}},{"cell_type":"markdown","source":["The dataset which will be taking,  is NYC taxi dataset. This dataset is maintained by the Numenta community. The full raw version is maintained by The New York City Taxi and Limousine Commission (TLC). The processed dataset contains the demand over a period of 7 months recorded in every 30 minutes."],"metadata":{"id":"GnIfzuZ5Q8oE"}},{"cell_type":"code","execution_count":null,"source":["#importing data module to load the dataset\n","from orion.data import load_signal, load_anomalies\n","#Import nyc_taxi dataset\n","signal = 'nyc_taxi'\n","# load_signal function load the given dataset\n","df = load_signal(signal)\n","# Since this dataset is already labelled, we will use load_anomalies functions to get all the known anomalies.\n","known_anomalies = load_anomalies(signal)\n","df.head(5)"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"upbjy6rsbTlu","executionInfo":{"status":"ok","timestamp":1623673817336,"user_tz":-330,"elapsed":640,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"eeb37a43-6a18-4a0b-cc32-1bea7983c5e0"}},{"cell_type":"markdown","source":["Plotting the dataset with the known anomalies. The blue color represents all the data points and the light pink colored patch represents the known anomaly.\n"],"metadata":{"id":"v2htGVqmQ_RS"}},{"cell_type":"code","execution_count":null,"source":["#the pink-colored patch represent known anomaly\n","plot(df, known_anomalies)"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":291},"id":"O2ElKLXwiMzq","executionInfo":{"status":"ok","timestamp":1623673820622,"user_tz":-330,"elapsed":2450,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"bf46f79a-3716-4cad-ba84-1edaf704460d"}},{"cell_type":"markdown","source":["# **ORION API**"],"metadata":{"id":"7SRpNSVaz4ws"}},{"cell_type":"markdown","source":["Through this API, we will be doing anomaly detection, using TadGAN model. As stated earlier, there are many pipelines like ARIMA, LSTM, etc, available in Orion, you can use any of them. Our main focus will be TadGAN pipeline. The procedure to use this library is easy as scikit-learn. At first, we train the data using the fit method and to do anomaly detection, we use the detect method. In this case, we will be using the fit_detect method. This process might take some time. Once it is over, it can be easily visualized and results can be seen."],"metadata":{"id":"Fz5lLPSvRBvf"}},{"cell_type":"code","execution_count":null,"source":["#importing Orion pipeline\n","from orion import Orion\n","#loading the TadGAN pipeline\n","orion = Orion(pipeline='tadgan.json')\n","#fitting the data to the TadGAN pipeline of Orion and detecting the outliers.\n","anomalies = orion.fit_detect(df)"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"WLSpLGnhq8QI","executionInfo":{"status":"error","timestamp":1623673821509,"user_tz":-330,"elapsed":898,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"53199d9a-1f57-4fcd-b3ae-dd34de41423d"}},{"cell_type":"markdown","source":["# **Visualize the output**"],"metadata":{"id":"yQfmG7Vd4JE0"}},{"cell_type":"markdown","source":["Letâ€™s plot the result."],"metadata":{"id":"vfQnJ45_REBZ"}},{"cell_type":"code","execution_count":null,"source":["plot(df, [anomalies, known_anomalies])\n","anomalies.head(5)"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":189},"id":"F_fha1Dm1V7k","executionInfo":{"status":"error","timestamp":1623669990800,"user_tz":-330,"elapsed":554,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"8157d081-e082-49ec-b575-425996061b6d"}},{"cell_type":"markdown","source":["# **Tracing Back to the functioning Model**"],"metadata":{"id":"d5bcefgIEkU3"}},{"cell_type":"markdown","source":["We have directly passed tadgan.json into the Orion pipeline and abracadabra, we got the results directly. This process is not easy as it seems. If we carefully look into tadgan.json file, we will get to know that it is actually doing multiple processing like data-preprocessing, model training, to post-processing functionalities. As defined by the author, these functions inside this file are called primitives. Each primitive is responsible for a specific task which we will be looking further into this article."],"metadata":{"id":"YZwZ0ITGRG-b"}},{"cell_type":"markdown","source":["![image.png](data:image/png;base64,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)"],"metadata":{"id":"Gv7kkb9SRIPB"}},{"cell_type":"markdown","source":["### **Primitives**"],"metadata":{"id":"hKS5lSP1FCSi"}},{"cell_type":"code","execution_count":null,"source":["import json\n","with open(\"tadgan.json\") as f:\n","  primitives = json.load(f)[\"primitives\"]\n","print(primitives) "],"outputs":[],"metadata":{"id":"BvYPuiMTFKkl","executionInfo":{"status":"aborted","timestamp":1623669922179,"user_tz":-330,"elapsed":38,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"markdown","source":["## **Data Preparation**"],"metadata":{"id":"9bhepoggE1l5"}},{"cell_type":"markdown","source":["### **1. Data Frequency**"],"metadata":{"id":"n78GMTipE76V"}},{"cell_type":"code","execution_count":null,"source":["def time_segments_aggregate(X, interval, time_column, method=['mean']):\n","    \"\"\"Aggregate values over given time span.\n","    Args:\n","        X (ndarray or pandas.DataFrame):\n","            N-dimensional sequence of values.\n","        interval (int):\n","            Integer denoting time span to compute aggregation of.\n","        time_column (int):\n","            Column of X that contains time values.\n","        method (str or list):\n","            Optional. String describing aggregation method or list of strings describing multiple\n","            aggregation methods. If not given, `mean` is used.\n","    Returns:\n","        ndarray, ndarray:\n","            * Sequence of aggregated values, one column for each aggregation method.\n","            * Sequence of index values (first index of each aggregated segment).\n","    \"\"\"\n","    #checking for the input datatype as numpy array and converting it to dataframe\n","    if isinstance(X, np.ndarray):\n","        X = pd.DataFrame(X)\n","    #sorting the values on timestamp column and setting it as a index\n","    X = X.sort_values(time_column).set_index(time_column)\n","\n","    if isinstance(method, str):\n","        method = [method]\n","\n","    start_ts = X.index.values[0]\n","    max_ts = X.index.values[-1]\n","\n","    values = list()\n","    index = list()\n","    while start_ts <= max_ts:\n","        end_ts = start_ts + interval\n","        subset = X.loc[start_ts:end_ts - 1]\n","        aggregated = [\n","            getattr(subset, agg)(skipna=True).values\n","            for agg in method\n","        ]\n","        values.append(np.concatenate(aggregated))\n","        index.append(start_ts)\n","        start_ts = end_ts\n","\n","    return np.asarray(values), np.asarray(index)\n","#here df is the given dataframe and \"timestamp\" is the required column to be altered.\n","X, index = time_segments_aggregate(df, interval=1800, time_column='timestamp')"],"outputs":[],"metadata":{"id":"x80h-_e7EADR","executionInfo":{"status":"aborted","timestamp":1623669922180,"user_tz":-330,"elapsed":38,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"markdown","source":["### **2. Data Imputation**"],"metadata":{"id":"smclFQNaG7Q-"}},{"cell_type":"code","execution_count":null,"source":["#Using the simple scikit imputer\n","imp = SimpleImputer()\n","X = imp.fit_transform(X)"],"outputs":[],"metadata":{"id":"aJAGpnZZGo3Y","executionInfo":{"status":"aborted","timestamp":1623669922182,"user_tz":-330,"elapsed":39,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"markdown","source":["### **3. Data Normalization**"],"metadata":{"id":"OFgcl9eHHQFj"}},{"cell_type":"code","execution_count":null,"source":["#Normalizing the data using scikit-learn MinMaxScalar\n","scaler = MinMaxScaler(feature_range=(-1, 1))\n","X = scaler.fit_transform(X)"],"outputs":[],"metadata":{"id":"ru3bKbf_HPfn","executionInfo":{"status":"aborted","timestamp":1623669922184,"user_tz":-330,"elapsed":40,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"markdown","source":["### **4. Data Slicing**"],"metadata":{"id":"TESksNfmNKhb"}},{"cell_type":"code","execution_count":null,"source":["def rolling_window_sequences(X, index, window_size, target_size, step_size, target_column,\n","                             drop=None, drop_windows=False):\n","    \"\"\"Create rolling window sequences out of time series data.\n","    The function creates an array of input sequences and an array of target sequences by rolling\n","    over the input sequence with a specified window.\n","    Optionally, certain values can be dropped from the sequences.\n","    Args:\n","        X (ndarray):\n","            N-dimensional sequence to iterate over.\n","        index (ndarray):\n","            Array containing the index values of X.\n","        window_size (int):\n","            Length of the input sequences.\n","        target_size (int):\n","            Length of the target sequences.\n","        step_size (int):\n","            Indicating the number of steps to move the window forward each round.\n","        target_column (int):\n","            Indicating which column of X is the target.\n","        drop (ndarray or None or str or float or bool):\n","            Optional. Array of boolean values indicating which values of X are invalid, or value\n","            indicating which value should be dropped. If not given, `None` is used.\n","        drop_windows (bool):\n","            Optional. Indicates whether the dropping functionality should be enabled. If not\n","            given, `False` is used.\n","    Returns:\n","        ndarray, ndarray, ndarray, ndarray:\n","            * input sequences.\n","            * target sequences.\n","            * first index value of each input sequence.\n","            * first index value of each target sequence.\n","    \"\"\"\n","    out_X = list()\n","    out_y = list()\n","    X_index = list()\n","    y_index = list()\n","    target = X[:, target_column]\n","\n","    if drop_windows:\n","        if hasattr(drop, '__len__') and (not isinstance(drop, str)):\n","            if len(drop) != len(X):\n","                raise Exception('Arrays `drop` and `X` must be of the same length.')\n","        else:\n","            if isinstance(drop, float) and np.isnan(drop):\n","                drop = np.isnan(X)\n","            else:\n","                drop = X == drop\n","\n","    start = 0\n","    max_start = len(X) - window_size - target_size + 1\n","    while start < max_start:\n","        end = start + window_size\n","\n","        if drop_windows:\n","            drop_window = drop[start:end + target_size]\n","            to_drop = np.where(drop_window)[0]\n","            if to_drop.size:\n","                start += to_drop[-1] + 1\n","                continue\n","\n","        out_X.append(X[start:end])\n","        out_y.append(target[end:end + target_size])\n","        X_index.append(index[start])\n","        y_index.append(index[end])\n","        start = start + step_size\n","\n","    return np.asarray(out_X), np.asarray(out_y), np.asarray(X_index), np.asarray(y_index)\n","#the target value; the value at time t.\n","#previous observed values, this is determined by the window width.\n","X, y, X_index, y_index = rolling_window_sequences(X, index, \n","                                                  window_size=100, \n","                                                  target_size=1, \n","                                                  step_size=1,\n","                                                  target_column=0)"],"outputs":[],"metadata":{"id":"MKr7smnJHk61","executionInfo":{"status":"aborted","timestamp":1623669922185,"user_tz":-330,"elapsed":41,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"code","execution_count":null,"source":["print(\"Training data input shape: {}\".format(X.shape))\n","print(\"Training data index shape: {}\".format(X_index.shape))\n","print(\"Training y shape: {}\".format(y.shape))\n","print(\"Training y index shape: {}\".format(y_index.shape))"],"outputs":[],"metadata":{"id":"hJky_njgNy_p","executionInfo":{"status":"aborted","timestamp":1623669922187,"user_tz":-330,"elapsed":43,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"code","execution_count":null,"source":["#function from utils.py module. Representing all the windows that has been created by slicing\n","#Here X represents the input used to train the model. In the previous example, we see X has 10222 training data points.\n","#Notice that 100 represents the window size. On the other hand, y is the real signal after processing, \n","#which we will use later on to calculate the error between the reconstructed and real signal.\n","plot_rws(X)"],"outputs":[],"metadata":{"id":"Ow2BdTMQOA4b","executionInfo":{"status":"aborted","timestamp":1623669922188,"user_tz":-330,"elapsed":43,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"markdown","source":["## **Training and Detection**"],"metadata":{"id":"6essJA4wQMnS"}},{"cell_type":"markdown","source":["As stated in the Research Paper, the architecture of this model requires four neural networks.\n","\n","> * encoder: maps X to its latent representation Z.\n","> * generator: maps the latent variable Z back to X, which we will denote later on as X_hat.\n","> * criticX: distinguishes between the real time series sequences from X and generated time series from generator(Z) or X_hat.\n","> * criticZ: measures the performance of the mapping into latent space or in simpler words, it discriminates between Z and encoder(X).\n","\n","More details of the composition of each network is mentioned in model.py. Specifying all the parameters below, fitting the model to the input X."],"metadata":{"id":"58o7Aze7Rmjt"}},{"cell_type":"code","execution_count":null,"source":["from model import hyperparameters\n","from orion.primitives.tadgan import TadGAN\n","\n","hyperparameters[\"epochs\"] = 35\n","hyperparameters[\"shape\"] = (100, 1) # based on the window size\n","hyperparameters[\"optimizer\"] = \"keras.optimizers.Adam\"\n","hyperparameters[\"learning_rate\"] = 0.0005\n","hyperparameters[\"latent_dim\"] = 20\n","hyperparameters[\"batch_size\"] = 64\n","\n","tgan = TadGAN(**hyperparameters)\n","tgan.fit(X)"],"outputs":[],"metadata":{"id":"6sqBEo20OGKa","executionInfo":{"status":"aborted","timestamp":1623669922189,"user_tz":-330,"elapsed":44,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"code","execution_count":null,"source":["# reconstructing the signal\n","X_hat, critic = tgan.predict(X)\n","# visualize X_hat\n","plot_rws(X_hat)"],"outputs":[],"metadata":{"id":"UbWFr7y9Rf_6","executionInfo":{"status":"aborted","timestamp":1623669922190,"user_tz":-330,"elapsed":44,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"code","execution_count":null,"source":["# flatten the predicted windows \n","y_hat = unroll_ts(X_hat)\n","# plot the time series data \n","plot_ts([y, y_hat], labels=['original', 'reconstructed'])"],"outputs":[],"metadata":{"id":"7YA7Gtc7g1YT","executionInfo":{"status":"aborted","timestamp":1623669922191,"user_tz":-330,"elapsed":45,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"code","execution_count":null,"source":["# pair-wise error calculation\n","error = np.zeros(shape=y.shape)\n","length = y.shape[0]\n","for i in range(length):\n","    error[i] = abs(y_hat[i] - y[i])\n","\n","# visualize the error curve\n","fig = plt.figure(figsize=(30, 3))\n","plt.plot(error)\n","plt.show()"],"outputs":[],"metadata":{"id":"qZKy7ZlKgmeP","executionInfo":{"status":"aborted","timestamp":1623669922192,"user_tz":-330,"elapsed":46,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"markdown","source":["## **Error Computation**"],"metadata":{"id":"J_sZVaLGhtuC"}},{"cell_type":"markdown","source":["In the TadGAN pipeline, we use tadgan.score_anomalies to perform error calculation. It is a smoothed error function that uses a window based method to smooth the curve then uses either: area, point difference, or dtw as a measure of discrepancy.\n","\n","> * Area: It captures the general shape of actual and reconstructed signals and then compares them. \n","> * Point: It compares each point between the original and reconstructed signal. It is considered as a  strict method and does not allow any mistakes.\n","> * Dynamic Time Warping (DTW): It compares two signals together using any pairwise distance measure but it allows for one signal to be lagging behind another. A lenient method.\n","\n","Plotting the error"],"metadata":{"id":"FNOaPAEgRw6t"}},{"cell_type":"code","execution_count":null,"source":["from orion.primitives.tadgan import score_anomalies\n","error, true_index, true, pred = score_anomalies(X, X_hat, critic, X_index, rec_error_type=\"dtw\", comb=\"mult\")\n","pred = np.array(pred).mean(axis=2)\n","# visualize the error curve\n","plot_error([[true, pred], error])"],"outputs":[],"metadata":{"id":"zxchjaB0g7tg","executionInfo":{"status":"aborted","timestamp":1623669922193,"user_tz":-330,"elapsed":47,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"code","execution_count":null,"source":["# threshold to classify the high peak data points as anomolous points\n","thresh = 10\n","\n","intervals = list()\n","\n","i = 0\n","max_start = len(error)\n","while i < max_start:\n","    j = i\n","    start = index[i]\n","    while error[i] > thresh:\n","        i += 1\n","    \n","    end = index[i]\n","    if start != end:\n","        intervals.append((start, end, np.mean(error[j: i+1])))\n","        \n","    i += 1\n","        \n","intervals"],"outputs":[],"metadata":{"id":"Z0yV9UGDidfn","executionInfo":{"status":"aborted","timestamp":1623669922193,"user_tz":-330,"elapsed":47,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"code","execution_count":null,"source":["anomalies = pd.DataFrame(intervals, columns=['start', 'end', 'score'])\n","#now plotting the actual data, known anomalies and predicted anomalies\n","plot(df, [anomalies, known_anomalies])"],"outputs":[],"metadata":{"id":"DjiR_Nj7jjkJ","executionInfo":{"status":"aborted","timestamp":1623669922194,"user_tz":-330,"elapsed":47,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"code","execution_count":null,"source":["from orion.primitives.timeseries_anomalies import find_anomalies\n","# find anomalies\n","intervals = find_anomalies(error, index, \n","                           window_size_portion=0.33, \n","                           window_step_size_portion=0.1, \n","                           fixed_threshold=True)\n","intervals"],"outputs":[],"metadata":{"id":"JkP0GXmJkJ0k","executionInfo":{"status":"aborted","timestamp":1623669922195,"user_tz":-330,"elapsed":48,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"code","execution_count":null,"source":["# visualize the result\n","anomalies = pd.DataFrame(intervals, columns=['start', 'end', 'score'])\n","plot(df, [anomalies, known_anomalies])"],"outputs":[],"metadata":{"id":"FnP7KThaltyV","executionInfo":{"status":"aborted","timestamp":1623669922195,"user_tz":-330,"elapsed":48,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"markdown","source":["# **End-to-End Pipeline Configuration**"],"metadata":{"id":"2_iDISEFm2tC"}},{"cell_type":"code","execution_count":null,"source":["from orion import Orion\n","#paramter dictionary contains the parameter which are to be overridden.\n","parameters = {\n","    \"mlprimitives.custom.timeseries_preprocessing.time_segments_aggregate#1\": {\n","            \"interval\": 3600 # hour level\n","        },\n","    'orion.primitives.tadgan.TadGAN#1': {\n","        'epochs': 15,\n","        }\n","}\n","\n","orion = Orion(\n","    'tadgan.json',\n","    parameters\n",")\n","\n","anomalies = orion.fit_detect(df)"],"outputs":[],"metadata":{"id":"Pl1BhWW9lzVC","executionInfo":{"status":"aborted","timestamp":1623669922196,"user_tz":-330,"elapsed":49,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"code","execution_count":null,"source":["#Plotting the anomalies\n","plot(df, [anomalies, known_anomalies])"],"outputs":[],"metadata":{"id":"ljQ1fun6rkjE","executionInfo":{"status":"aborted","timestamp":1623669922196,"user_tz":-330,"elapsed":49,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"markdown","source":["# **Evaluation Methods**"],"metadata":{"id":"A41tbfGzzYdG"}},{"cell_type":"markdown","source":["## **Dummy Dataset**"],"metadata":{"id":"w-REed-12ORu"}},{"cell_type":"code","execution_count":null,"source":["#Let's assume that the signal starts at timestamp 1, and ends at timestamp 20. \n","#We can then see that the ground truth contains three anomalies, namely (5, 8), (12, 13), and (17, 18),\n","#where (i, j) expresses the starting timestamp i and ending timestamp j.\n","#We can also see that, we detected two anomalies, namely (5, 8) and (12, 15). So how can we compare both sets?\n","import numpy as np\n","# to reproduce the same dummy signal\n","np.random.seed(0)\n","# dummy data\n","start, end = (1, 20)\n","signal = np.random.rand(end - start, 1)\n","ground_truth = [\n","    (5, 8),\n","    (12, 13),\n","    (17, 18)\n","]\n","anomalies = [\n","    (5, 8),\n","    (12, 15)\n","]"],"outputs":[],"metadata":{"id":"8shWxSvxzX9H","executionInfo":{"status":"aborted","timestamp":1623669922197,"user_tz":-330,"elapsed":49,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"code","execution_count":null,"source":["#plotting the dummy dataset with the anomaly\n","import matplotlib.pyplot as plt\n","\n","time = range(start, end)\n","plt.plot(time, signal)\n","\n","# ground truth\n","for i, (t1, t2) in enumerate(ground_truth):\n","    plt.axvspan(t1, t2+1, color=\"g\", alpha=0.2, label=\"ground_truth\")\n","\n","# detected\n","for i, (t1, t2) in enumerate(anomalies):\n","    plt.axvspan(t1, t2+1, color=\"r\", alpha=0.2, label=\"detected\")\n","\n","    \n","plt.title(\"Example\")\n","plt.xlabel(\"Time\")\n","plt.ylabel(\"value\")\n","plt.show()"],"outputs":[],"metadata":{"id":"__OWm-RSu7hX","executionInfo":{"status":"aborted","timestamp":1623669922197,"user_tz":-330,"elapsed":47,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"markdown","source":["### **Evaluation of dummy dataset through weighted segment**"],"metadata":{"id":"qK9X8lPj5p_N"}},{"cell_type":"code","execution_count":null,"source":["#we can use orion.evaluation subpackage to compute multiple metrics using the weighted segment approach. \n","#For example to compute the accuracy, we use contextual_accuracy(..., weighted=True). \n","#There are other metrics available, for reference checkout the orion.evaluation documentation.\n","from orion.evaluation.contextual import contextual_accuracy, contextual_f1_score\n","accuracy = contextual_accuracy(ground_truth, anomalies, start=start, end=end)\n","f1_score = contextual_f1_score(ground_truth, anomalies, start=start, end=end)\n","print(\"Accuracy score = {:0.3f}\".format(accuracy))\n","print(\"F1 score = {:0.3f}\".format(f1_score))"],"outputs":[],"metadata":{"id":"kMFhTQGK3Jjo","executionInfo":{"status":"aborted","timestamp":1623669922199,"user_tz":-330,"elapsed":48,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"markdown","source":["### **Evaluation of dummy dataset through overlapping segment**"],"metadata":{"id":"oLOjvvMQ7UM7"}},{"cell_type":"code","execution_count":null,"source":["#Similarly, we can use the same metric functions, but with parameter weighted=False. \n","#Note: overlap segment approach, does not account for true negatives. \n","#Reason being, anomalies in time series data are rare and so \"normal\" instances will skew the value of the computed metric. \n","#Therefore, using this approach we cannot compute metrics such as the accuracy. \n","f1_score = contextual_f1_score(ground_truth, anomalies, start=start, end=end, weighted=False)\n","print(\"F1 score = {:0.3f}\".format(f1_score))"],"outputs":[],"metadata":{"id":"4slXP1nJ57by","executionInfo":{"status":"aborted","timestamp":1623669922199,"user_tz":-330,"elapsed":47,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"markdown","source":["## **Pipelin Evaluation End-to-End**"],"metadata":{"id":"B0e2QqSO7_Wh"}},{"cell_type":"code","execution_count":null,"source":["from orion import Orion\n","from orion.data import load_signal, load_anomalies\n","#Importing all the methods for evaluation\n","from orion.evaluation.contextual import contextual_accuracy, contextual_f1_score, contextual_precision\n","metrics = [\n","    'f1',\n","    'recall',\n","    'precision',\n","]\n","orion = Orion(\n","    'tadgan.json'\n",")\n","signal = 'nyc_taxi'\n","# load signal\n","df = load_signal(signal)\n","# load ground truth anomalies\n","ground_truth = load_anomalies(signal)\n","#Evaluation scores mentioned in the metrics list\n","scores = orion.evaluate(df, ground_truth, fit=True, metrics=metrics)"],"outputs":[],"metadata":{"id":"PQcF6xJJ7xbh","executionInfo":{"status":"aborted","timestamp":1623669922200,"user_tz":-330,"elapsed":47,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"code","execution_count":null,"source":["scores"],"outputs":[],"metadata":{"id":"IBZKV4n98AoU","executionInfo":{"status":"aborted","timestamp":1623669922201,"user_tz":-330,"elapsed":46,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"markdown","source":["#**Related Articles:**\n","\n","> * [TadGAN](https://analyticsindiamag.com/hands-on-guide-to-tadgan-with-python-codes/)\n","\n","> * [Pastas](https://analyticsindiamag.com/guide-to-pastas-a-python-framework-for-hydrogeological-time-series-analysis/)\n","\n","> * [Bitcoin Price Prediction](https://analyticsindiamag.com/guide-to-implementing-time-series-analysis-predicting-bitcoin-price-with-rnn/)\n","\n","> * [Time Series Forecasting with Darts](https://analyticsindiamag.com/hands-on-guide-to-darts-a-python-tool-for-time-series-forecasting/)\n","\n","> * [Guide to Time Series Forecasting with GluonTS](https://analyticsindiamag.com/gluonts-pytorchts-for-time-series-forecasting/)\n","\n","> * [Tensorflow Core](https://analyticsindiamag.com/time-series-forecasting-using-tensorflow-core/)\n","\n"],"metadata":{"id":"MqArsKEsd2S-"}}]}