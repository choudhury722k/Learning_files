{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"20_Darts.ipynb","provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyPGVJaOXtuOmBBhl5WSHxIi"},"kernelspec":{"name":"python3","display_name":"Python 3.8.8 64-bit ('base': conda)"},"language_info":{"name":"python","version":"3.8.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"interpreter":{"hash":"f60a20abaabf5a658075b37fac599269792a9493ddacd7c14d8505185d5625aa"}},"cells":[{"cell_type":"markdown","source":["# **Darts**"],"metadata":{"id":"GnyPMBI3zPNG"}},{"cell_type":"markdown","source":["For a number of datasets, forecasting the time-series columns plays an important role in the decision making process for the model. Unit8.co developed a library to make the forecasting of time-series easy called darts. The idea behind this was to make darts as simple to use as sklearn for time-series. Darts attempts to smooth the overall process of using time series in machine learning. "],"metadata":{"id":"aPMWGo5izVHb"}},{"cell_type":"markdown","source":["To read about it more, please refere [this](https://analyticsindiamag.com/hands-on-guide-to-darts-a-python-tool-for-time-series-forecasting/) article."],"metadata":{"id":"2djfVAyRzV0g"}},{"cell_type":"markdown","source":["# **Implementation of darts on time-series data**"],"metadata":{"id":"SlJ6xsqazdJ1"}},{"cell_type":"markdown","source":["Darts is open-source and can be installed with the pip command. To install darts use:"],"metadata":{"id":"oqByXGhuzf6D"}},{"cell_type":"code","execution_count":null,"source":["\n","!python -m pip install pip --upgrade --user -q --no-warn-script-location\n","!python -m pip install numpy pandas seaborn matplotlib scipy statsmodels sklearn tensorflow keras torch torchvision \\\n","    tqdm scikit-image pmdarima u8darts --user -q --no-warn-script-location\n","import IPython\n","IPython.Application.instance().kernel.do_shutdown(True)\n"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["## Dataset"],"metadata":{"id":"xeRGoznazjFZ"}},{"cell_type":"markdown","source":["Next, choose any time-series dataset of your choice. I have selected the monthly production of beer in Australia dataset. To download this click [here](https://www.kaggle.com/shenba/time-series-datasets?select=monthly-beer-production-in-austr.csv). Let us now load the dataset and import the libraries needed."],"metadata":{"id":"zeBgt8UezmH1"}},{"cell_type":"code","execution_count":null,"source":["# !unzip australia_beer_datasets.zip"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DQZE8Kp60y3x","executionInfo":{"status":"ok","timestamp":1623662484513,"user_tz":-330,"elapsed":416,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"b89d8291-e2b6-48d0-aa4e-1a2cb28140eb"}},{"cell_type":"code","execution_count":null,"source":["import pandas as pd\n","from darts import TimeSeries\n","\n","beer_data = pd.read_csv('monthly-beer-production-in-austr.csv')\n","beer_data.head()"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"8qlXpK_u04wQ","executionInfo":{"status":"ok","timestamp":1623662543899,"user_tz":-330,"elapsed":424,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"d68569b8-ea24-40d4-febf-c5bb782e05ac"}},{"cell_type":"markdown","source":["The dataset contains two columns- the month with the year and the beer production in that time period. "],"metadata":{"id":"3tebvq2r7JL5"}},{"cell_type":"markdown","source":["### Train-test split"],"metadata":{"id":"qRgFwF927K-3"}},{"cell_type":"markdown","source":["Let us now use the TimeSeries class and split the data into train and test. We will use a method called from_dataframe for doing this and pass column names in the method. Then, we will split the data based on the time period. The dataset has around 477 columns, so I chose the 275th time period to make the split (1978-10)."],"metadata":{"id":"C3_k01fU7gg5"}},{"cell_type":"code","execution_count":null,"source":["get_data = TimeSeries.from_dataframe(beer_data, 'Month', 'Monthly beer production')\n","traindata, testdata = get_data.split_before(pd.Timestamp('1978-10'))"],"outputs":[],"metadata":{"id":"b5FzJqUf7gOc","executionInfo":{"status":"ok","timestamp":1623664251658,"user_tz":-330,"elapsed":637,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"markdown","source":["### Modelling"],"metadata":{"id":"xrUFaZh87mYo"}},{"cell_type":"markdown","source":["Training of the model is very simple with darts. An exponential smoothing model is used here to fit the data. Similar to sklearn, fit() method is used to fit the dataset. "],"metadata":{"id":"snVMDMdP7qVW"}},{"cell_type":"code","execution_count":null,"source":["from darts.models import ExponentialSmoothing\n","\n","beer_model = ExponentialSmoothing()\n","beer_model.fit(traindata)"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xUZxyI0H7pqt","executionInfo":{"status":"ok","timestamp":1623664289217,"user_tz":-330,"elapsed":4998,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"70d8ef44-4aef-4e0b-ab23-99834732ade9"}},{"cell_type":"markdown","source":["This completes the training part. Let us now make predictions and plot the graph"],"metadata":{"id":"f0LoT9z47ud8"}},{"cell_type":"code","execution_count":null,"source":["prediction = beer_model.predict(len(testdata))\n","\n","print(\"predicted\" ,prediction[:5])\n","print(\"actual\",testdata[:5])"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7L1sNMQz7wVn","executionInfo":{"status":"ok","timestamp":1623664318684,"user_tz":-330,"elapsed":386,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"808c1177-0872-4988-cd5e-ddb01dbe8d2b"}},{"cell_type":"code","execution_count":null,"source":["import matplotlib.pyplot as plt\n","\n","get_data.plot(label='actual')\n","prediction.plot(label='predict', lw=3)\n","plt.legend()"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":296},"id":"EN1FYP3V73wS","executionInfo":{"status":"ok","timestamp":1623664332543,"user_tz":-330,"elapsed":1436,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"fc9592ce-e015-4930-82cd-5ed8b911d58c"}},{"cell_type":"markdown","source":["#**Related Articles:**\n","\n","> * [Time Series Forecasting with Darts](https://analyticsindiamag.com/hands-on-guide-to-darts-a-python-tool-for-time-series-forecasting/)\n","\n","> * [Guide to Time Series Forecasting with GluonTS](https://analyticsindiamag.com/gluonts-pytorchts-for-time-series-forecasting/)\n","\n","> * [Tensorflow Core](https://analyticsindiamag.com/time-series-forecasting-using-tensorflow-core/)\n","\n","> * [LSTM RNN on Foreign Exchange Rate Prediction](https://analyticsindiamag.com/foreign-exchange-rate-prediction-using-lstm-recurrent-neural-network/)\n","\n","> * [Pyflux](https://analyticsindiamag.com/pyflux-guide-python-library-for-time-series-analysis-and-prediction/)\n","\n","> * [Atspy](https://analyticsindiamag.com/hands-on-guide-to-atspy-for-automating-the-time-series-forecasting/)\n","\n"],"metadata":{"id":"MqArsKEsd2S-"}}]}