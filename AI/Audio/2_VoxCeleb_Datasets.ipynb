{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"3_VoxCeleb_Datasets.ipynb","provenance":[],"authorship_tag":"ABX9TyMJ0tcQ2DasTnf7ntaniDLi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **VoxCeleb Datasets**"],"metadata":{"id":"RUQY1zhNVcuL"}},{"cell_type":"markdown","source":["Audio-Visual datasets is used in industry such, e.g. Alexa voice service as automatic speech recognition. In health care, the voice is routed through a speech-recognition machine for lip reading of patient, military services as High-performance fighter aircraft and digital detection system, lip-reading without any voice of dumb people, language learning as a second language."],"metadata":{"id":"0sU8ZUPwVfTW"}},{"cell_type":"markdown","source":["VoxCeleb Dataset is developed by the VGG, Department of Engineering Science, University of Oxford, UK. To visit the VGG Dataset, click [here](https://www.robots.ox.ac.uk/~vgg/data/). These are the primary researchers who work on creating VoxCeleb dataset from youtube. "],"metadata":{"id":"c_EFQYTwVhWE"}},{"cell_type":"markdown","source":["## **Dataset**"],"metadata":{"id":"Pkz84SnFW2l5"}},{"cell_type":"markdown","source":["To download the dataset visit the [following page](https://www.robots.ox.ac.uk/~vgg/data/voxceleb/). You need to send a request form to get access to the Dataset Only for Research purposes."],"metadata":{"id":"kahLbtdFWqU0"}},{"cell_type":"markdown","source":["### **Using PyTorch:**"],"metadata":{"id":"oZ2qgMXJW4ii"}},{"cell_type":"code","execution_count":null,"source":["\n","!python -m pip install pip --upgrade --user -q --no-warn-script-location\n","!python -m pip install numpy pandas seaborn matplotlib scipy statsmodels sklearn nltk gensim tensorflow keras torch torchvision \\\n","    tqdm scikit-image pillow librosa --user -q --no-warn-script-location\n","\n","import IPython\n","IPython.Application.instance().kernel.do_shutdown(True)\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["import pandas as pd\n","import numpy as np\n","from torch.utils.data import Dataset\n","import utility as ut\n","import os\n","import torch\n","class AudioDataset(Dataset):\n","    \"\"\"Audio dataset\"\"\"\n","    def __init__(self, csv_file, base_audio_path, stft_transform=None):\n","        self._base_audio_path = base_audio_path\n","        self._table = pd.read_csv(csv_file)\n","        self._audio_data = {}\n","        self._stft_transform = stft_transform\n","        # removed samples from *.csv whose *.wav files are not available\n","        indices_to_remove = []\n","        for idx in range(len(self._table)):\n","            wav_name = os.path.join(self._base_audio_path, self._table.wav_name[idx],)\n","            if not os.path.exists(wav_name):\n","                indices_to_remove.append(idx)\n","        self._table = self._table.drop(indices_to_remove)\n","        self._table = self._table.reset_index()\n","    def __len__(self):\n","        return len(self._table)\n","    def __getitem__(self, idx):\n","        wav_name = os.path.join(self._base_audio_path, self._table.wav_name[idx])\n","        if wav_name in self._audio_data:\n","            wav_data = self._audio_data[wav_name]\n","        else:\n","            wav_data = ut.load_audio_sample(wav_name)\n","            self._audio_data[wav_name] = wav_data\n","        # create sample\n","        wav_data = ut.create_audio_sample(wav_data)\n","        audio_stft = ut.extract_spectrum(wav_data)\n","        audio_stft = np.vstack((audio_stft.real, audio_stft.imag))\n","        if self._stft_transform:\n","            audio_stft = self._stft_transform(audio_stft)\n","        audio_stft = audio_stft.reshape((1, *audio_stft.shape))\n","        audio_stft = torch.from_numpy(audio_stft.astype(dtype=np.float32))\n","        labels =torch.from_numpy(np.array(self._table.target[idx]).astype(dtype=np.float32))\n","        return (audio_stft, labels)\n"],"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-0671dc4001d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mutility\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mut\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utility'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":389},"id":"HU62QhCkNgKk","executionInfo":{"status":"error","timestamp":1623218872683,"user_tz":-330,"elapsed":3707,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"b8033ec6-6cc2-402f-d4be-87b2bd7c5b4a"}},{"cell_type":"markdown","source":["# **Related Articles:**\n","\n","> * [Voxceleb Datasets](https://analyticsindiamag.com/guide-to-voxceleb-datasets-for-visual-audio-of-human-speech/)\n","\n","> * [FreeSound Datasets](https://analyticsindiamag.com/datasets-freesound-pytorch-research/)\n","\n","> * [LibriSpeech Datasets](https://analyticsindiamag.com/librispeech-datasets/)\n","\n","> * [Simple Transformers](https://analyticsindiamag.com/speech-classification-in-3-minutes/)\n","\n","> * [Create your own Speech Classifier](https://analyticsindiamag.com/speech-classification-in-3-minutes/)"],"metadata":{"id":"agPHjISycAxz"}}]}