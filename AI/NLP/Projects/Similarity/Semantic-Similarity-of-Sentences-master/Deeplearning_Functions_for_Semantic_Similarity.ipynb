{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deeplearning Functions for Semantic Similarity",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "42j1B4KoByRG",
        "colab_type": "code",
        "outputId": "7ae3ef7d-6bdb-4fe2-cef9-6d70e481d29e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import spacy\n",
        "import os\n",
        "import string\n",
        "import gensim\n",
        "from keras.layers import *\n",
        "from keras.activations import softmax\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Nadam, Adam\n",
        "from keras.regularizers import l2\n",
        "import keras.backend as K\n",
        "from gensim.models.fasttext import FastText"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDNL_RBYHXV6",
        "colab_type": "code",
        "outputId": "60695efd-b5bf-4741-c9ac-a945fbd755e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "train = pd.read_csv(\"/content/train_2.csv\")\n",
        "train = train.dropna()\n",
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "      <th>Q1</th>\n",
              "      <th>Q2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "      <td>['step', 'step', 'guide', 'invest', 'share', '...</td>\n",
              "      <td>['step', 'step', 'guide', 'invest', 'share', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "      <td>['story', 'kohinoor', 'kohinoor', 'diamond']</td>\n",
              "      <td>['would', 'happen', 'indian', 'government', 's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "      <td>['increase', 'speed', 'internet', 'connection'...</td>\n",
              "      <td>['internet', 'speed', 'increased', 'hacking', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "      <td>['mentally', 'lonely', 'solve']</td>\n",
              "      <td>['find', 'remainder', 'math2324math', 'divided...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "      <td>['one', 'dissolve', 'water', 'quikly', 'sugar'...</td>\n",
              "      <td>['fish', 'would', 'survive', 'salt', 'water']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...                                                 Q2\n",
              "0   0  ...  ['step', 'step', 'guide', 'invest', 'share', '...\n",
              "1   1  ...  ['would', 'happen', 'indian', 'government', 's...\n",
              "2   2  ...  ['internet', 'speed', 'increased', 'hacking', ...\n",
              "3   3  ...  ['find', 'remainder', 'math2324math', 'divided...\n",
              "4   4  ...      ['fish', 'would', 'survive', 'salt', 'water']\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8iBJ32aHi9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LEN = 30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXoqfvHpHlBt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -c http://nlp.stanford.edu/data/glove.840B.300d.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPyLpg56pcDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -c https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.en.vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaD0Ri6qqSzH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -c https://raw.githubusercontent.com/satojkovic/cnn-text-classification-tf/use_fasttext/util_fasttext.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-q0CIBjcqrag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python util_fasttext.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQQc7ndtHlJD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"/content/glove.840B.300d.zip\", \"r\") as zipread:\n",
        "  zipread.extractall(\"/content/\")\n",
        "  zipread.close"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbdpNIQZHlLQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_pretrained_embedding(pretrained_weights_path, trainable=False, **kwargs):\n",
        "    \"Create embedding layer from a pretrained weights array\"\n",
        "    pretrained_weights = np.load(pretrained_weights_path)\n",
        "    in_dim, out_dim = pretrained_weights.shape\n",
        "    embedding = Embedding(in_dim, out_dim, weights=[pretrained_weights], trainable=False, **kwargs)\n",
        "    return embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2waoGNlHlN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unchanged_shape(input_shape):\n",
        "    \"Function for Lambda layer\"\n",
        "    return input_shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80aSrTouHlQ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def substract(input_1, input_2):\n",
        "    \"Substract element-wise\"\n",
        "    neg_input_2 = Lambda(lambda x: -x, output_shape=unchanged_shape)(input_2)\n",
        "    out_ = Add()([input_1, neg_input_2])\n",
        "    return out_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhymubafHlUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def submult(input_1, input_2):\n",
        "    \"Get multiplication and subtraction then concatenate results\"\n",
        "    mult = Multiply()([input_1, input_2])\n",
        "    sub = substract(input_1, input_2)\n",
        "    out_= Concatenate()([sub, mult])\n",
        "    return out_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkN6T55-HlE6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def apply_multiple(input_, layers):\n",
        "    \"Apply layers to input then concatenate result\"\n",
        "    if not len(layers) > 1:\n",
        "        raise ValueError('Layers list should contain more than 1 layer')\n",
        "    else:\n",
        "        agg_ = []\n",
        "        for layer in layers:\n",
        "            agg_.append(layer(input_))\n",
        "        out_ = Concatenate()(agg_)\n",
        "    return out_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOi7gYg-Z0oK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def time_distributed(input_, layers):\n",
        "    \"Apply a list of layers in TimeDistributed mode\"\n",
        "    out_ = []\n",
        "    node_ = input_\n",
        "    for layer_ in layers:\n",
        "        node_ = TimeDistributed(layer_)(node_)\n",
        "    out_ = node_\n",
        "    return out_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLhCuOk2Z0sa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def soft_attention_alignment(input_1, input_2):\n",
        "    \"Align text representation with neural soft attention\"\n",
        "    attention = Dot(axes=-1)([input_1, input_2])\n",
        "    w_att_1 = Lambda(lambda x: softmax(x, axis=1),\n",
        "                     output_shape=unchanged_shape)(attention)\n",
        "    w_att_2 = Permute((2,1))(Lambda(lambda x: softmax(x, axis=2),\n",
        "                             output_shape=unchanged_shape)(attention))\n",
        "    in1_aligned = Dot(axes=1)([w_att_1, input_1])\n",
        "    in2_aligned = Dot(axes=1)([w_att_2, input_2])\n",
        "    return in1_aligned, in2_aligned"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYkVzTKEZ0vm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decomposable_attention(pretrained_embedding='../data/fasttext_matrix.npy', \n",
        "                           projection_dim=300, projection_hidden=0, projection_dropout=0.2,\n",
        "                           compare_dim=500, compare_dropout=0.2,\n",
        "                           dense_dim=300, dense_dropout=0.2,\n",
        "                           lr=1e-3, activation='elu', maxlen=MAX_LEN):\n",
        "    # Based on: https://arxiv.org/abs/1606.01933\n",
        "    \n",
        "    q1 = Input(name='q1',shape=(maxlen,))\n",
        "    q2 = Input(name='q2',shape=(maxlen,))\n",
        "    \n",
        "    # Embedding\n",
        "    embedding = create_pretrained_embedding(pretrained_embedding, \n",
        "                                            mask_zero=False)\n",
        "    q1_embed = embedding(q1)\n",
        "    q2_embed = embedding(q2)\n",
        "    \n",
        "    # Projection\n",
        "    projection_layers = []\n",
        "    if projection_hidden > 0:\n",
        "        projection_layers.extend([\n",
        "                Dense(projection_hidden, activation=activation),\n",
        "                Dropout(rate=projection_dropout),\n",
        "            ])\n",
        "    projection_layers.extend([\n",
        "            Dense(projection_dim, activation=None),\n",
        "            Dropout(rate=projection_dropout),\n",
        "        ])\n",
        "    q1_encoded = time_distributed(q1_embed, projection_layers)\n",
        "    q2_encoded = time_distributed(q2_embed, projection_layers)\n",
        "    \n",
        "    # Attention\n",
        "    q1_aligned, q2_aligned = soft_attention_alignment(q1_encoded, q2_encoded)    \n",
        "    \n",
        "    # Compare\n",
        "    q1_combined = Concatenate()([q1_encoded, q2_aligned, submult(q1_encoded, q2_aligned)])\n",
        "    q2_combined = Concatenate()([q2_encoded, q1_aligned, submult(q2_encoded, q1_aligned)]) \n",
        "    compare_layers = [\n",
        "        Dense(compare_dim, activation=activation),\n",
        "        Dropout(compare_dropout),\n",
        "        Dense(compare_dim, activation=activation),\n",
        "        Dropout(compare_dropout),\n",
        "    ]\n",
        "    q1_compare = time_distributed(q1_combined, compare_layers)\n",
        "    q2_compare = time_distributed(q2_combined, compare_layers)\n",
        "    \n",
        "    # Aggregate\n",
        "    q1_rep = apply_multiple(q1_compare, [GlobalAvgPool1D(), GlobalMaxPool1D()])\n",
        "    q2_rep = apply_multiple(q2_compare, [GlobalAvgPool1D(), GlobalMaxPool1D()])\n",
        "    \n",
        "    # Classifier\n",
        "    merged = Concatenate()([q1_rep, q2_rep])\n",
        "    dense = BatchNormalization()(merged)\n",
        "    dense = Dense(dense_dim, activation=activation)(dense)\n",
        "    dense = Dropout(dense_dropout)(dense)\n",
        "    dense = BatchNormalization()(dense)\n",
        "    dense = Dense(dense_dim, activation=activation)(dense)\n",
        "    dense = Dropout(dense_dropout)(dense)\n",
        "    out_ = Dense(1, activation='sigmoid')(dense)\n",
        "    \n",
        "    model = Model(inputs=[q1, q2], outputs=out_)\n",
        "    model.compile(optimizer=Adam(lr=lr), loss='binary_crossentropy', \n",
        "                  metrics=['binary_crossentropy','accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2iocE23Z0zj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def esim(pretrained_embedding='/content/fasttext_embedding_en.npy', \n",
        "         maxlen=MAX_LEN, \n",
        "         lstm_dim=300, \n",
        "         dense_dim=300, \n",
        "         dense_dropout=0.5):\n",
        "             \n",
        "    # Based on arXiv:1609.06038\n",
        "    q1 = Input(name='q1',shape=(maxlen,))\n",
        "    q2 = Input(name='q2',shape=(maxlen,))\n",
        "    \n",
        "    # Embedding\n",
        "    embedding = create_pretrained_embedding(pretrained_embedding, mask_zero=False)\n",
        "    bn = BatchNormalization(axis=2)\n",
        "    q1_embed = bn(embedding(q1))\n",
        "    q2_embed = bn(embedding(q2))\n",
        "\n",
        "    # Encode\n",
        "    encode = Bidirectional(LSTM(lstm_dim, return_sequences=True))\n",
        "    q1_encoded = encode(q1_embed)\n",
        "    q2_encoded = encode(q2_embed)\n",
        "    \n",
        "    # Attention\n",
        "    q1_aligned, q2_aligned = soft_attention_alignment(q1_encoded, q2_encoded)\n",
        "    \n",
        "    # Compose\n",
        "    q1_combined = Concatenate()([q1_encoded, q2_aligned, submult(q1_encoded, q2_aligned)])\n",
        "    q2_combined = Concatenate()([q2_encoded, q1_aligned, submult(q2_encoded, q1_aligned)]) \n",
        "       \n",
        "    compose = Bidirectional(LSTM(lstm_dim, return_sequences=True))\n",
        "    q1_compare = compose(q1_combined)\n",
        "    q2_compare = compose(q2_combined)\n",
        "    \n",
        "    # Aggregate\n",
        "    q1_rep = apply_multiple(q1_compare, [GlobalAvgPool1D(), GlobalMaxPool1D()])\n",
        "    q2_rep = apply_multiple(q2_compare, [GlobalAvgPool1D(), GlobalMaxPool1D()])\n",
        "    \n",
        "    # Classifier\n",
        "    merged = Concatenate()([q1_rep, q2_rep])\n",
        "    \n",
        "    dense = BatchNormalization()(merged)\n",
        "    dense = Dense(dense_dim, activation='elu')(dense)\n",
        "    dense = BatchNormalization()(dense)\n",
        "    dense = Dropout(dense_dropout)(dense)\n",
        "    dense = Dense(dense_dim, activation='elu')(dense)\n",
        "    dense = BatchNormalization()(dense)\n",
        "    dense = Dropout(dense_dropout)(dense)\n",
        "    out_ = Dense(1, activation='sigmoid')(dense)\n",
        "    \n",
        "    model = Model(inputs=[q1, q2], outputs=out_)\n",
        "    model.compile(optimizer=Adam(lr=1e-3), loss='binary_crossentropy', metrics=['binary_crossentropy','accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}