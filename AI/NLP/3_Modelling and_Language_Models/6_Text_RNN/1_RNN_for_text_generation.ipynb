{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"1_RNN_for_text_generation.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3.8.8 64-bit ('base': conda)"},"language_info":{"name":"python","version":"3.8.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"interpreter":{"hash":"f60a20abaabf5a658075b37fac599269792a9493ddacd7c14d8505185d5625aa"}},"cells":[{"cell_type":"markdown","source":["# **RNN for Text Generation**"],"metadata":{"id":"1lfTrzvgzSkR"}},{"cell_type":"markdown","source":["In this session, we will train a Recurrent Neural Network (RNN) in PyTorch on the names belonging to several languages. After successful training, the RNN model will predict names belonging to a language that start with an input alphabet letter."],"metadata":{"id":"iplAOofezVWt"}},{"cell_type":"markdown","source":["## **Implementation in PyTorch**"],"metadata":{"id":"ZYlnuJjHzXpH"}},{"cell_type":"markdown","source":["Now, we will import all the required libraries."],"metadata":{"id":"EjRNVRzG1Hiu"}},{"cell_type":"code","execution_count":null,"source":["!python -m pip install pip --upgrade --user -q --no-warn-script-location\n","!python -m pip install numpy pandas seaborn matplotlib scipy statsmodels sklearn torch nltk gensim --user -q --no-warn-script-location\n","\n","import IPython\n","IPython.Application.instance().kernel.do_shutdown(True)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["from __future__ import unicode_literals, print_function, division\n","from io import open\n","import glob\n","import os\n","import unicodedata\n","import string\n","import torch\n","import torch.nn as nn\n","import random\n","import time\n","import math\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker"],"outputs":[],"metadata":{"id":"HDvJiZf3xD5a"}},{"cell_type":"markdown","source":["The below code snippet will read the dataset."],"metadata":{"id":"94O75vlC1gHF"}},{"cell_type":"code","execution_count":1,"source":["!wget https://download.pytorch.org/tutorial/data.zip"],"outputs":[{"output_type":"stream","name":"stdout","text":["--2021-10-28 12:52:33--  https://download.pytorch.org/tutorial/data.zip\n","Resolving download.pytorch.org (download.pytorch.org)... 18.66.78.69, 18.66.78.33, 18.66.78.3, ...\n","Connecting to download.pytorch.org (download.pytorch.org)|18.66.78.69|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2882130 (2.7M) [application/zip]\n","Saving to: ‘data.zip’\n","\n","data.zip            100%[===================>]   2.75M  3.85MB/s    in 0.7s    \n","\n","2021-10-28 12:52:35 (3.85 MB/s) - ‘data.zip’ saved [2882130/2882130]\n","\n"]}],"metadata":{"id":"-58ydTqnct_C"}},{"cell_type":"code","execution_count":null,"source":["all_let = string.ascii_letters + \" .,;'-\"\n","n_let = len(all_let) + 1\n","\n","def getFiles(path):\n","  return glob.glob(path)\n","\n","# Unicode string to ASCII\n","def unicodeToAscii(s):\n","    return ''.join(\n","        c for c in unicodedata.normalize('NFD', s)\n","        if unicodedata.category(c) != 'Mn'\n","        and c in all_let\n","    )\n","\n","# Read a file and split into lines\n","def getLines(filename):\n","    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n","    return [unicodeToAscii(line) for line in lines]\n","\n","# Build the cat_lin dictionary, a list of lines per category\n","cat_lin = {}\n","all_ctg = []\n","for filename in getFiles('data/names/*.txt'):\n","    categ = os.path.splitext(os.path.basename(filename))[0]\n","    all_ctg.append(categ)\n","    lines = getLines(filename)\n","    cat_lin[categ] = lines\n","\n","n_ctg = len(all_ctg)"],"outputs":[],"metadata":{"id":"Qu8_JDI51kQU"}},{"cell_type":"markdown","source":["In the next step, we will define the module class to generate the names. The module will be a recurrent neural network."],"metadata":{"id":"s-OVRJBu24z6"}},{"cell_type":"code","execution_count":null,"source":["class NameGeneratorModule(nn.Module):\n","  def __init__(self, inp_size, hid_size, op_size):\n","      super(NameGeneratorModule, self).__init__()\n","      self.hid_size = hid_size\n","\n","      self.i2h = nn.Linear(n_ctg + inp_size + hid_size, hid_size)\n","      self.i2o = nn.Linear(n_ctg + inp_size + hid_size, op_size)\n","      self.o2o = nn.Linear(hid_size + op_size, op_size)\n","      \n","      self.dropout = nn.Dropout(0.1)\n","      self.softmax = nn.LogSoftmax(dim=1)\n","\n","  def forward(self, category, input, hidden):\n","      inp_comb = torch.cat((category, input, hidden), 1)\n","      hidden = self.i2h(inp_comb)\n","      output = self.i2o(inp_comb)\n","      op_comb = torch.cat((hidden, output), 1)\n","      output = self.o2o(op_comb)\n","      output = self.dropout(output)\n","      output = self.softmax(output)\n","      return output, hidden\n","\n","  def initHidden(self):\n","      return torch.zeros(1, self.hid_size)"],"outputs":[],"metadata":{"id":"3IKQdZAo27St"}},{"cell_type":"markdown","source":["The below functions will be used to pick the random item from a list and a random line from a category"],"metadata":{"id":"yh0CD8W729x9"}},{"cell_type":"code","execution_count":null,"source":["def randChoice(l):\n","    return l[random.randint(0, len(l) - 1)]\n","\n","def randTrainPair():\n","    category = randChoice(all_ctg)\n","    line = randChoice(cat_lin[category])\n","    return category, line"],"outputs":[],"metadata":{"id":"kZDqKmHF2_yg"}},{"cell_type":"markdown","source":["The below functions will convert the data to the compatible format for the RNN module."],"metadata":{"id":"a8dvY_RZ3Cpt"}},{"cell_type":"code","execution_count":null,"source":["def categ_Tensor(categ):\n","    li = all_ctg.index(categ)\n","    tensor = torch.zeros(1, n_ctg)\n","    tensor[0][li] = 1\n","    return tensor\n","\n","def inp_Tensor(line):\n","    tensor = torch.zeros(len(line), 1, n_let)\n","    for li in range(len(line)):\n","        letter = line[li]\n","        tensor[li][0][all_let.find(letter)] = 1\n","    return tensor\n","\n","def tgt_Tensor(line):\n","    letter_indexes = [all_let.find(line[li]) for li in range(1, len(line))]\n","    letter_indexes.append(n_let - 1) # EOS\n","    return torch.LongTensor(letter_indexes)\n"],"outputs":[],"metadata":{"id":"qcCkso-i3FEZ"}},{"cell_type":"markdown","source":["The below function will create random training examples including category, input and target tensors."],"metadata":{"id":"9xV9e_7Y3Hfr"}},{"cell_type":"code","execution_count":null,"source":["def rand_train_exp():\n","    category, line = randTrainPair()\n","    category_tensor = categ_Tensor(category)\n","    input_line_tensor = inp_Tensor(line)\n","    target_line_tensor = tgt_Tensor(line)\n","    return category_tensor, input_line_tensor, target_line_tensor"],"outputs":[],"metadata":{"id":"x9Ugzz3m3Jov"}},{"cell_type":"markdown","source":["The below function will define the loss criteria for the RNN module."],"metadata":{"id":"NfqATDji3LiP"}},{"cell_type":"code","execution_count":null,"source":["#Loss\n","criterion = nn.NLLLoss()\n","#Learning rate\n","lr_rate = 0.0005\n","\n","def train(category_tensor, input_line_tensor, target_line_tensor):\n","    target_line_tensor.unsqueeze_(-1)\n","    hidden = model.initHidden()\n","\n","    model.zero_grad()\n","\n","    loss = 0\n","\n","    for i in range(input_line_tensor.size(0)):\n","        output, hidden = model(category_tensor, input_line_tensor[i], hidden)\n","        l = criterion(output, target_line_tensor[i])\n","        loss += l\n","\n","    loss.backward()\n","\n","    for p in model.parameters():\n","        p.data.add_(p.grad.data, alpha=-lr_rate)\n","\n","    return output, loss.item() / input_line_tensor.size(0)"],"outputs":[],"metadata":{"id":"QE4E3RWO3OQ8"}},{"cell_type":"markdown","source":["To show time during training, the bellow function is defined."],"metadata":{"id":"ujDrsS1I3V3L"}},{"cell_type":"code","execution_count":null,"source":["def time_taken(since):\n","    now = time.time()\n","    s = now - since\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)"],"outputs":[],"metadata":{"id":"hUuHmRoj3Xw8"}},{"cell_type":"markdown","source":["In the next step, we will define our RNN model."],"metadata":{"id":"QgihdZfc3juI"}},{"cell_type":"code","execution_count":null,"source":["model = NameGeneratorModule(n_let, 128, n_let)"],"outputs":[],"metadata":{"id":"KFMkpqwC3lZ8"}},{"cell_type":"markdown","source":["We will see the parameters of the defined RNN model."],"metadata":{"id":"uySSghZB3v1q"}},{"cell_type":"code","execution_count":null,"source":["print(model)"],"outputs":[],"metadata":{"id":"HG3fjGY93x6j"}},{"cell_type":"code","execution_count":null,"source":["def rand_train_exp():\n","    category, line = randTrainPair()\n","    category_tensor = categ_Tensor(category)\n","    input_line_tensor = inp_Tensor(line)\n","    target_line_tensor = tgt_Tensor(line)\n","    return category_tensor, input_line_tensor, target_line_tensor"],"outputs":[],"metadata":{"id":"pK8H8Y2qGRcV"}},{"cell_type":"markdown","source":["In the next step, the model will be trained in 10,000 epochs."],"metadata":{"id":"ak17WgaN3yrU"}},{"cell_type":"code","execution_count":null,"source":["epochs = 100000\n","print_every = 5000\n","plot_every = 500\n","all_losses = []\n","total_loss = 0 # Reset every plot_every iters\n","#rnn = RNN(n_letters, 128, n_letters)\n","start = time.time()\n","\n","for iter in range(1, epochs + 1):\n","    output, loss = train(*rand_train_exp())\n","    total_loss += loss\n","\n","    if iter % print_every == 0:\n","        print('Time: %s, Epoch: (%d - Total Iterations: %d%%),  Loss: %.4f' % (time_taken(start), iter, iter / epochs * 100, loss))\n","\n","    if iter % plot_every == 0:\n","        all_losses.append(total_loss / plot_every)\n","        total_loss = 0"],"outputs":[],"metadata":{"id":"3KW8-B3X33yy"}},{"cell_type":"markdown","source":["We will visualize the training loss."],"metadata":{"id":"qEH1g4qzAesz"}},{"cell_type":"code","execution_count":null,"source":["plt.figure(figsize=(7,7))\n","plt.title(\"Loss\")\n","plt.plot(all_losses)\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Loss\")\n","plt.show()"],"outputs":[],"metadata":{"id":"xxLDhU5lAgl-"}},{"cell_type":"markdown","source":["Finally, we will sample our model to test it on generating the names belonging to languages when given a starting alphabet letter."],"metadata":{"id":"qI_zjW5mAj7y"}},{"cell_type":"code","execution_count":null,"source":["max_length = 20\n","# Sample from a category and starting letter\n","def sample_model(category, start_letter='A'):\n","    with torch.no_grad():  # no need to track history in sampling\n","        category_tensor = categ_Tensor(category)\n","        input = inp_Tensor(start_letter)\n","        hidden = model.initHidden()\n","\n","        output_name = start_letter\n","\n","        for i in range(max_length):\n","            output, hidden = model(category_tensor, input[0], hidden)\n","            topv, topi = output.topk(1)\n","            topi = topi[0][0]\n","            if topi == n_let - 1:\n","                break\n","            else:\n","                letter = all_let[topi]\n","                output_name += letter\n","            input = inp_Tensor(letter)\n","\n","        return output_name\n","\n","# Get multiple samples from one category and multiple starting letters\n","def sample_names(category, start_letters='XYZ'):\n","    for start_letter in start_letters:\n","        print(sample_model(category, start_letter))"],"outputs":[],"metadata":{"id":"gvOhaxLiAmwu"}},{"cell_type":"markdown","source":["Now, we will check the sampled model to generate names when given a language and the starting alphabet letter."],"metadata":{"id":"nud4RGRLApGE"}},{"cell_type":"code","execution_count":null,"source":["print(\"Italian:-\")\n","sample_names('Italian', 'BPRT')\n","print(\"\\nKorean:-\")\n","sample_names('Korean', 'CMRS')\n","print(\"\\nRussian:-\")\n","sample_names('Russian', 'AJLN')\n","print(\"\\nVietnamese:-\")\n","sample_names('Vietnamese', 'LMT')"],"outputs":[],"metadata":{"id":"wisW8SQLAsbW"}},{"cell_type":"markdown","source":["# **Related Articles:**\n","\n","> * [Text Generation using RNN](https://analyticsindiamag.com/recurrent-neural-network-in-pytorch-for-text-generation/)\n","\n","> * [SVD in Recommender System](https://analyticsindiamag.com/singular-value-decomposition-svd-application-recommender-system/)\n","\n","> * [TF-IDF from Scratch in Python](https://analyticsindiamag.com/hands-on-implementation-of-tf-idf-from-scratch-in-python/)\n","\n","> * [Continuous Bag of Words](https://analyticsindiamag.com/the-continuous-bag-of-words-cbow-model-in-nlp-hands-on-implementation-with-codes/)\n","\n","> * [NLP Case Study of Documents Similarity](https://analyticsindiamag.com/nlp-case-study-identify/)\n","\n","> * [Review Classification](https://analyticsindiamag.com/step-by-step-guide-to-reviews-classification-using-svc-naive-bayes-random-forest/)\n","\n"],"metadata":{"id":"prpNOPgzWgiU"}}]}