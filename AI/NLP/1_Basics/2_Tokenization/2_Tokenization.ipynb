{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"2_Tokenization.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNW12nEnqM7fdk5vcOAV67p"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Tokenization**"],"metadata":{"id":"yg8RunAxZqdE"}},{"cell_type":"markdown","source":["we will start with the first step of data pre-processing i.e Tokenization. Further, we will implement different methods in python to perform tokenization of text data."],"metadata":{"id":"_s9lO6AFZta_"}},{"cell_type":"markdown","source":["## **Tokenize Words Using NLTK**"],"metadata":{"id":"tVbmSA_iZvWV"}},{"cell_type":"markdown","source":["Letâ€™s start with the tokenization of words using the NLTK library. It breaks the given string and returns a list of strings by the white specified separator."],"metadata":{"id":"GrPHO8b-ZygE"}},{"cell_type":"code","execution_count":null,"source":["!python -m pip install pip --upgrade --user -q --no-warn-script-location\n","!python -m pip install numpy pandas seaborn matplotlib scipy statsmodels sklearn nltk gensim --user -q --no-warn-script-location\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["!python -m spacy download en --user -q -no-warn-script-location"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["import IPython\n","IPython.Application.instance().kernel.do_shutdown(True)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["#download packages\n","import nltk\n","nltk.download(\"punkt\")"],"outputs":[],"metadata":{"id":"Xm-H7DP1Z6HX"}},{"cell_type":"code","execution_count":null,"source":["#Tokenize words\n","from nltk.tokenize import word_tokenize \n","text = \"Machine learning is a method of data analysis that automates analytical model building\"\n","word_tokenize(text)"],"outputs":[],"metadata":{"id":"qQ0PhhpiW6-Y"}},{"cell_type":"markdown","source":["Here, we tokenize the sentences instead of words by a full stop (.) separator."],"metadata":{"id":"3_YujdhAZ2A9"}},{"cell_type":"code","execution_count":null,"source":["#Tokenize Sentence\n","from nltk.tokenize import sent_tokenize \n","text = \"Machine learning is a method of data analysis that automates analytical model building. It is a branch of artificial intelligence based on the idea that systems can learn from data, identify patterns and make decisions with minimal human intervention.\"\n","sent_tokenize(text) "],"outputs":[],"metadata":{"id":"Pnh4lTtcZ4QL"}},{"cell_type":"code","execution_count":null,"source":["#Tokenize words of different words\n","import nltk\n","nltk.download('punkt')\n","import nltk.data \n","spanish_tokenizer = nltk.data.load('tokenizers/punkt/PY3/spanish.pickle') \n","text = 'Hola amigo. Me llamo Ankit.'\n","spanish_tokenizer.tokenize(text)"],"outputs":[],"metadata":{"id":"MxiZjGodaE7p"}},{"cell_type":"markdown","source":["## **Regular Expression**"],"metadata":{"id":"eBlxJojnaHA9"}},{"cell_type":"markdown","source":["Regex function is used to match or find strings using a sequence of patterns consisting of letters and numbers. We will re library to tokenize words and sentences of a paragraph."],"metadata":{"id":"LkZxpfH5aKTU"}},{"cell_type":"code","execution_count":null,"source":["from nltk.tokenize import RegexpTokenizer \n","tokenizer = RegexpTokenizer(\"[\\w']+\") \n","text = \"Machine learning is a method of data analysis that automates analytical model building\"\n","tokenizer.tokenize(text)"],"outputs":[],"metadata":{"id":"GbsO-QyCaL9i"}},{"cell_type":"code","execution_count":null,"source":["#Split Sentences\n","import re\n","text = \"\"\"Machine learning is a method of data analysis that automates analytical model building. It is a branch of artificial intelligence based on the idea that systems can learn from data, identify patterns and make decisions with minimal human intervention.\"\"\"\n","sentences = re.compile('[.!?] ').split(text)\n","sentences"],"outputs":[],"metadata":{"id":"3oW3eJjJaOMs"}},{"cell_type":"markdown","source":["## **Split()**"],"metadata":{"id":"Y3kbP_fZaT7Y"}},{"cell_type":"markdown","source":["split() method is used to break the given string in a sentence and return a list of strings by the specified separator."],"metadata":{"id":"sDrUWnIeaWmO"}},{"cell_type":"code","execution_count":null,"source":["text = \"\"\"Machine learning is a method of data analysis that automates analytical model building\"\"\"\n","# Splits at space \n","text.split()"],"outputs":[],"metadata":{"id":"b_Cm5kv_aYaR"}},{"cell_type":"code","execution_count":null,"source":["#Split Sentence\n","text = \"\"\"Machine learning is a method of data analysis that automates analytical model building.It is a branch of artificial intelligence based on the idea that systems can learn from data, identify patterns and make decisions with minimal human intervention.\"\"\"\n","# Splits at space \n","text.split('.')"],"outputs":[],"metadata":{"id":"19kAdyjVaahr"}},{"cell_type":"markdown","source":["## **Spacy**"],"metadata":{"id":"3HL2d5FCacTo"}},{"cell_type":"markdown","source":["Spacy is an open-source library used for tokenization of words and sentences. We will load en_core_web_sm  which supports the English language."],"metadata":{"id":"AbpZOSgmafHJ"}},{"cell_type":"code","execution_count":null,"source":["import spacy\n","sp = spacy.load('en_core_web_sm')\n","sentence = sp(u'Machine learning is a method of data analysis that automates analytical model building.')\n","print(sentence)\n","L=[]\n","for word in sentence:\n","    L.append(word)"],"outputs":[],"metadata":{"id":"nY_dk3k4ahId"}},{"cell_type":"code","execution_count":null,"source":["#Split Sentences\n","sentence = sp(u'Machine learning is a method of data analysis that automates analytical model building. It is a branch of artificial intelligence based on the idea that systems can learn from data, identify patterns and make decisions with minimal human intervention.')\n","print(sentence)\n","x = []\n","for sent in sentence.sents:\n","    x.append(sent.text)"],"outputs":[],"metadata":{"id":"xsCFIBy6ajkp"}},{"cell_type":"markdown","source":["## **Gensim**"],"metadata":{"id":"i7xogZzba4xA"}},{"cell_type":"markdown","source":["The last method that we will cover in this article is gensim. It is an open-source python library for topic modelling and similarity retrieval of large datasets."],"metadata":{"id":"PSltsjm7a8zD"}},{"cell_type":"code","execution_count":null,"source":["from gensim.utils import tokenize\n","text = \"\"\"Artificial intelligence, the ability of a digital computer or computer-controlled robot to perform tasks commonly associated with intelligent beings.\"\"\"\n","list(tokenize(text))"],"outputs":[],"metadata":{"id":"VSi_UADQa-5s"}},{"cell_type":"code","execution_count":null,"source":["#Split Sentence\n","from gensim.summarization.textcleaner import split_sentences\n","text = \"\"\"Artificial intelligence, the ability of a digital computer or computer-controlled robot to perform tasks commonly associated with intelligent beings. The term is frequently applied to the project of developing systems endowed with the intellectual processes characteristic of humans, such as the ability to reason, discover meaning, generalize, or learn from past experience.\"\"\"\n","split1 = split_sentences(text)"],"outputs":[],"metadata":{"id":"tza_jHrrbBss"}},{"cell_type":"code","execution_count":null,"source":["split1"],"outputs":[],"metadata":{"id":"z4UHB6lqbDlv"}},{"cell_type":"markdown","source":["# **Read more articles on:**\n","\n","> * [Spacy Basics](https://analyticsindiamag.com/nlp-deep-learning-nlp-framework-nlp-model/)\n","\n","> * [StanfordCore NLP](https://analyticsindiamag.com/how-to-use-stanza-by-stanford-nlp-group-with-python-code/)\n","\n","> * [Tokenization in NLP](https://analyticsindiamag.com/hands-on-guide-to-different-tokenization-methods-in-nlp/)"],"metadata":{"id":"prpNOPgzWgiU"}}]}