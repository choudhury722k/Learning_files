{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"1_AlexNet_With_Keras.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyP/f4dnFXwC3dTAbGEvxvPc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **AlexNet With Keras**"],"metadata":{"id":"gsHhzcQooMoS"}},{"cell_type":"markdown","source":["The computer vision is being applied in a variety of applications across the domains and thanks to the deep learning that is continuously giving new frameworks to be used in the computer vision space. As of now, there may be more than hundreds of deep learning models that have proven their capabilities in handling millions of images and producing accurate results. Every deep learning model has a specific architecture and is trained in that specific way. Convolutional neural networks are one of the popular deep learning models that have a wide range of applications in the field of computer vision."],"metadata":{"id":"BQGg6dWFpHs_"}},{"cell_type":"markdown","source":["There is a variety of Convolutional Neural Network (CNN) architectures. AlexNet is one of the variants of CNN which is also referred to as a Deep Convolutional Neural Network. In this article, we will discuss the architecture and implementation of AlexNet using Keras library without using transfer learning approach. In the end, we will evaluate the performance of this model in classification."],"metadata":{"id":"J6T-zJUJpJ1C"}},{"cell_type":"markdown","source":["To read about the architecture of AlexNet, please refer [this](https://analyticsindiamag.com/hands-on-guide-to-implementing-alexnet-with-keras-for-multi-class-image-classification/) article."],"metadata":{"id":"vdeBIYYDpKel"}},{"cell_type":"markdown","source":["## **Implementing in Keras**"],"metadata":{"id":"BiEY86NepVMh"}},{"cell_type":"markdown","source":["Here, we will implement the Alexnet in Keras as per the model description given in the research work, Please note that we will not use it a pre-trained model."],"metadata":{"id":"jHcpBPCGqtcB"}},{"cell_type":"markdown","source":["In the first step, we will define the AlexNet network using Keras library. The parameters of the network will be kept according to the above descriptions, that is 5 convolutional layers with kernel size 11 x 11, 5 x 5, 3 x 3, 3 x 3 respectively, 3 fully connected layers, ReLU as an activation function at all layers except at the output layer. Since we will test this model in CIFAR10 classification, at the output layer we will define a Dense layer with 10 nodes."],"metadata":{"id":"6YmONsCiq9nk"}},{"cell_type":"code","execution_count":null,"source":["!python -m pip install pip --upgrade --user -q --no-warn-script-location\n","!python -m pip install numpy pandas seaborn matplotlib scipy statsmodels sklearn tensorflow keras opencv-python pillow scikit-image --user -q --no-warn-script-location\n","\n","import IPython\n","IPython.Application.instance().kernel.do_shutdown(True)\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["#Importing library\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n","from keras.layers.normalization import BatchNormalization\n","import numpy as np\n","\n","np.random.seed(1000)\n","\n","#Instantiation\n","AlexNet = Sequential()\n","\n","#1st Convolutional Layer\n","AlexNet.add(Conv2D(filters=96, input_shape=(32,32,3), kernel_size=(11,11), strides=(4,4), padding='same'))\n","AlexNet.add(BatchNormalization())\n","AlexNet.add(Activation('relu'))\n","AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n","\n","#2nd Convolutional Layer\n","AlexNet.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1,1), padding='same'))\n","AlexNet.add(BatchNormalization())\n","AlexNet.add(Activation('relu'))\n","AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n","\n","#3rd Convolutional Layer\n","AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n","AlexNet.add(BatchNormalization())\n","AlexNet.add(Activation('relu'))\n","\n","#4th Convolutional Layer\n","AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n","AlexNet.add(BatchNormalization())\n","AlexNet.add(Activation('relu'))\n","\n","#5th Convolutional Layer\n","AlexNet.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\n","AlexNet.add(BatchNormalization())\n","AlexNet.add(Activation('relu'))\n","AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n","\n","#Passing it to a Fully Connected layer\n","AlexNet.add(Flatten())\n","# 1st Fully Connected Layer\n","AlexNet.add(Dense(4096, input_shape=(32,32,3,)))\n","AlexNet.add(BatchNormalization())\n","AlexNet.add(Activation('relu'))\n","# Add Dropout to prevent overfitting\n","AlexNet.add(Dropout(0.4))\n","\n","#2nd Fully Connected Layer\n","AlexNet.add(Dense(4096))\n","AlexNet.add(BatchNormalization())\n","AlexNet.add(Activation('relu'))\n","#Add Dropout\n","AlexNet.add(Dropout(0.4))\n","\n","#3rd Fully Connected Layer\n","AlexNet.add(Dense(1000))\n","AlexNet.add(BatchNormalization())\n","AlexNet.add(Activation('relu'))\n","#Add Dropout\n","AlexNet.add(Dropout(0.4))\n","\n","#Output Layer\n","AlexNet.add(Dense(10))\n","AlexNet.add(BatchNormalization())\n","AlexNet.add(Activation('softmax'))\n","\n","#Model Summary\n","AlexNet.summary()"],"outputs":[],"metadata":{"id":"SaG__vxdq9cI"}},{"cell_type":"markdown","source":["Once the model is defined, we will compile this model and use Adam as an optimizer. We could use stochastic gradient descent (sgd) as well."],"metadata":{"id":"PpGCpskWrC6F"}},{"cell_type":"code","execution_count":null,"source":["# Compiling the model\n","AlexNet.compile(loss = keras.losses.categorical_crossentropy, optimizer= 'adam', metrics=['accuracy'])"],"outputs":[],"metadata":{"id":"Jzd7CZxqoJyq"}},{"cell_type":"markdown","source":["Now, as we are ready with our model, we will check its performance in classification. For the same, we will use the CIFAR10 dataset that is a popular benchmark in image classification. The CIFAR-10 dataset is a publically available image data set provided by the Canadian Institute for Advanced Research (CIFAR). It consists of 60000 32×32 colour images in 10 classes, with 6000 images per class. The 10 different classes represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. There are 50000 training images and 10000 test images in this dataset."],"metadata":{"id":"rhFY6lB9rHxe"}},{"cell_type":"code","execution_count":null,"source":["#Keras library for CIFAR dataset\n","from keras.datasets import cifar10\n","(x_train, y_train),(x_test, y_test)=cifar10.load_data()\n","\n","#Train-validation-test split\n","from sklearn.model_selection import train_test_split\n","x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=.3)\n","\n","#Dimension of the CIFAR10 dataset\n","print((x_train.shape,y_train.shape))\n","print((x_val.shape,y_val.shape))\n","print((x_test.shape,y_test.shape))"],"outputs":[],"metadata":{"id":"1iw-6pePrKap"}},{"cell_type":"code","execution_count":null,"source":["#Onehot Encoding the labels.\n","from sklearn.utils.multiclass import unique_labels\n","from keras.utils.np_utils import to_categorical\n","\n","#Since we have 10 classes we should expect the shape[1] of y_train,y_val and y_test to change from 1 to 10\n","y_train=to_categorical(y_train)\n","y_val=to_categorical(y_val)\n","y_test=to_categorical(y_test)\n","\n","#Verifying the dimension after one hot encoding\n","print((x_train.shape,y_train.shape))\n","print((x_val.shape,y_val.shape))\n","print((x_test.shape,y_test.shape))"],"outputs":[],"metadata":{"id":"RVSg0BN6rMqN"}},{"cell_type":"code","execution_count":null,"source":["#Image Data Augmentation\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True,zoom_range=.1 )\n","\n","val_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True,zoom_range=.1)\n","\n","test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip= True,zoom_range=.1)\n","\n","#Fitting the augmentation defined above to the data\n","train_generator.fit(x_train)\n","val_generator.fit(x_val)\n","test_generator.fit(x_test)"],"outputs":[],"metadata":{"id":"eXBx4YShrRPe"}},{"cell_type":"markdown","source":["After preprocessing the CIFAR10 dataset, we are ready now to train our defined AlexNet model. We will use the learning rate annealer in this experiment. The learning rate annealer decreases the learning rate after a certain number of epochs if the error rate does not change. Here, through this technique, we will monitor the validation accuracy and if it seems to be a plateau in 3 epochs, it will reduce the learning rate by 0.01."],"metadata":{"id":"qAe4FinXrUdg"}},{"cell_type":"code","execution_count":null,"source":["#Learning Rate Annealer\n","from keras.callbacks import ReduceLROnPlateau\n","lrr= ReduceLROnPlateau(   monitor='val_acc',   factor=.01,   patience=3,  min_lr=1e-5) "],"outputs":[],"metadata":{"id":"s97VDtH1rWyx"}},{"cell_type":"markdown","source":["To train the model, we will define below the number of epochs, the number of batches and the learning rate."],"metadata":{"id":"HLTBYXzwrYz-"}},{"cell_type":"code","execution_count":null,"source":["#Defining the parameters\n","batch_size= 100\n","epochs=100\n","learn_rate=.001"],"outputs":[],"metadata":{"id":"5p4pFFsYravN"}},{"cell_type":"markdown","source":["Now, we will train our defined AlexNet model."],"metadata":{"id":"154QUb1lrcSQ"}},{"cell_type":"code","execution_count":null,"source":["#Training the model\n","AlexNet.fit_generator(train_generator.flow(x_train, y_train, batch_size=batch_size), epochs = epochs, steps_per_epoch = x_train.shape[0]//batch_size, validation_data = val_generator.flow(x_val, y_val, batch_size=batch_size), validation_steps = 250, callbacks = [lrr], verbose=1)"],"outputs":[],"metadata":{"id":"WZ2f9S6breWq"}},{"cell_type":"code","execution_count":null,"source":["#After successful training, we will visualize its performance.\n","\n","import matplotlib.pyplot as plt\n","#Plotting the training and validation loss\n","\n","f,ax=plt.subplots(2,1) #Creates 2 subplots under 1 column\n","\n","#Assigning the first subplot to graph training loss and validation loss\n","ax[0].plot(AlexNet.history.history['loss'],color='b',label='Training Loss')\n","ax[0].plot(AlexNet.history.history['val_loss'],color='r',label='Validation Loss')\n","\n","#Plotting the training accuracy and validation accuracy\n","ax[1].plot(AlexNet.history.history['accuracy'],color='b',label='Training  Accuracy')\n","ax[1].plot(AlexNet.history.history['val_accuracy'],color='r',label='Validation Accuracy')\n","\n","plt.legend()"],"outputs":[],"metadata":{"id":"jOD694cdrhuh"}},{"cell_type":"markdown","source":["We will see the classification performance using a non-normalized and a normalized confusion matrices. For this purpose, first, we will define a function through which the confusion matrices will be plotted."],"metadata":{"id":"tATR_gxNrksw"}},{"cell_type":"code","execution_count":null,"source":["#Defining function for confusion matrix plot\n","def plot_confusion_matrix(y_true, y_pred, classes,\n","                          normalize=False,\n","                          title=None,\n","                          cmap=plt.cm.Blues):\n","    if not title:\n","        if normalize:\n","            title = 'Normalized confusion matrix'\n","        else:\n","            title = 'Confusion matrix, without normalization'\n","\n","    # Compute confusion matrix\n","    cm = confusion_matrix(y_true, y_pred)\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        print(\"Normalized confusion matrix\")\n","    else:\n","        print('Confusion matrix, without normalization')\n","\n","#Print Confusion matrix\n","    fig, ax = plt.subplots(figsize=(7,7))\n","    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n","    ax.figure.colorbar(im, ax=ax)\n","    # We want to show all ticks...\n","    ax.set(xticks=np.arange(cm.shape[1]),\n","           yticks=np.arange(cm.shape[0]),\n","           xticklabels=classes, yticklabels=classes,\n","           title=title,\n","           ylabel='True label',\n","           xlabel='Predicted label')\n","\n","    # Rotate the tick labels and set their alignment.\n","    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n","             rotation_mode=\"anchor\")\n","    # Loop over data dimensions and create text annotations.\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","    for i in range(cm.shape[0]):\n","        for j in range(cm.shape[1]):\n","            ax.text(j, i, format(cm[i, j], fmt),\n","                    ha=\"center\", va=\"center\",\n","                    color=\"white\" if cm[i, j] > thresh else \"black\")\n","    fig.tight_layout()\n","    return ax\n","\n","np.set_printoptions(precision=2)"],"outputs":[],"metadata":{"id":"efB0-CFRrnKo"}},{"cell_type":"markdown","source":["In the next step, we will predict the class labels for the test images using the trained AlexNet model."],"metadata":{"id":"9kisARYLrpKA"}},{"cell_type":"code","execution_count":null,"source":["#Making prediction\n","y_pred=AlexNet.predict_classes(x_test)\n","y_true=np.argmax(y_test,axis=1)\n","\n","#Plotting the confusion matrix\n","from sklearn.metrics import confusion_matrix\n","confusion_mtx=confusion_matrix(y_true,y_pred)\n","\n","class_names=['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n","\n","# Plotting non-normalized confusion matrix\n","plot_confusion_matrix(y_true, y_pred, classes = class_names,title = 'Confusion matrix, without normalization')"],"outputs":[],"metadata":{"id":"IQAWk4Turr8Y"}},{"cell_type":"code","execution_count":null,"source":["# Plotting normalized confusion matrix\n","plot_confusion_matrix(y_true, y_pred, classes=class_names, normalize=True, title='Normalized confusion matrix')"],"outputs":[],"metadata":{"id":"JvzxCpQUrvDc"}},{"cell_type":"markdown","source":["The average accuracy score in classifying the unseen test data will be obtained now."],"metadata":{"id":"DNzJ0ullrxYh"}},{"cell_type":"code","execution_count":null,"source":["#Classification accuracy\n","from sklearn.metrics import accuracy_score\n","acc_score = accuracy_score(y_true, y_pred)\n","print('Accuracy Score = ', acc_score)"],"outputs":[],"metadata":{"id":"Ia9EGlEnrzbR"}},{"cell_type":"markdown","source":["#**Related Articles:**\n","\n","> * [Multi Class Classification with AlexNet](https://analyticsindiamag.com/hands-on-guide-to-implementing-alexnet-with-keras-for-multi-class-image-classification/)\n","\n","> * [Object Detection with YOLO](https://analyticsindiamag.com/hands-on-guide-to-object-detection-using-yolo/)\n","\n","> * [Neural Style Transfer](https://analyticsindiamag.com/hands-on-guide-to-neural-style-transfer-using-tensorflow-hub-module/)\n","\n","> * [ResNet50 in PyTorch](https://analyticsindiamag.com/hands-on-guide-to-implement-resnet50-in-pytorch-with-tpu/)\n","\n","> * [CNN Model – To Count Fingers](https://analyticsindiamag.com/how-to-implement-cnn-model-to-count-fingers-and-distinguish-between-left-and-right-hand/)"],"metadata":{"id":"1ZtPNx78qe5T"}}]}