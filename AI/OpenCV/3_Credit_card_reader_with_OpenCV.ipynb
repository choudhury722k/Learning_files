{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"1_Credit_card_reader_with_OpenCV.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPsu+4s3nk8w8uI1JLkBIgX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#**Credit Card Reader with OpenCV**"],"metadata":{"id":"j8tgMMPZFjfF"}},{"cell_type":"markdown","source":["Optical character recognition has seen many applications in machine learning and deep learning. One such practical application of OCR is for identification of credit card type and number on the card. This could be of great help of banks and other financial institutions for digitally recognising the card numbers and type of card. It can also be useful for UPI services where the user can just scan the card instead of typing in the details. OCR is usually handled by a library called Tesseract. But, here we will use OpenCV to read the credit card and identify the type and number on the card. "],"metadata":{"id":"BX0cR-YGFoRb"}},{"cell_type":"markdown","source":["## **Getting a Font Reference**"],"metadata":{"id":"sJ4PbDLeGL5K"}},{"cell_type":"markdown","source":["On a typical credit card, you can see that the numbers are in a slightly different font. For these numbers to be read by the machine, we need to show the machine and save the font of these numbers. The font on the cards is called MICR which stands for magnetic ink character recognition code. So, let us now write the code in OpenCV and perform a template matching so that this font is understood for recognition later. "],"metadata":{"id":"kQ30jW5wHGS0"}},{"cell_type":"markdown","source":["### **Import the Required Libraries**"],"metadata":{"id":"J3bpilLsIEo6"}},{"cell_type":"code","execution_count":null,"source":["!python -m pip install pip --upgrade --user -q --no-warn-script-location\n","!python -m pip install numpy pandas seaborn matplotlib scipy statsmodels sklearn nltk gensim scikit-image opencv-python pillow dlib imutils --user -q --no-warn-script-location\n","\n","import IPython\n","IPython.Application.instance().kernel.do_shutdown(True)\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["import cv2\n","import imutils\n","from imutils import contours\n","import numpy as np\n","from matplotlib import pyplot as plt"],"outputs":[],"metadata":{"id":"nVZN2zcaFnvj","executionInfo":{"status":"ok","timestamp":1624278876289,"user_tz":-330,"elapsed":8,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"markdown","source":["### **Get the reference image**"],"metadata":{"id":"yqaFhDOWFnfR"}},{"cell_type":"markdown","source":["You can download this image [here](https://enacademic.com/pictures/enwiki/79/OCR-A_char_digits.svg). Once this is done, let us read the image and perform some basic image processing on this. We will convert the image to greyscale and apply a binary inversion threshold on it."],"metadata":{"id":"gpgxMTxFJZfK"}},{"cell_type":"code","execution_count":null,"source":["template = cv2.imread('numbers.png')\n","template = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n","template = cv2.threshold(template, 10, 255, cv2.THRESH_BINARY_INV)[1]"],"outputs":[],"metadata":{"id":"-1J3mW3IJk5h","executionInfo":{"status":"ok","timestamp":1624278891468,"user_tz":-330,"elapsed":507,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"markdown","source":["### **Getting the contours for the image**"],"metadata":{"id":"yqgsXu-EKHOQ"}},{"cell_type":"markdown","source":["Next, we need to find contours in the above image and after locating each digit we will sort them and put them in a dictionary for further reference. To contour the image we will do the following steps. "],"metadata":{"id":"vZIzVbaeKKp3"}},{"cell_type":"code","execution_count":null,"source":["get_contour = cv2.findContours(template.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n","get_contour = imutils.grab_contours(get_contour)\n","print(get_contour)\n","print(type(get_contour))\n","get_contour = contours.sort_contours(get_contour, method=\"left-to-right\")[0]\n","numbers = {}"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5eYLnms7KSet","executionInfo":{"status":"ok","timestamp":1624278894050,"user_tz":-330,"elapsed":645,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"c0ea88fe-57b6-4e39-854b-daccc7f8820d"}},{"cell_type":"markdown","source":["Next, we will find a bounding box for these digits by looping over them and then finding the region of interest and then appending them to the dictionary created above. We will also define two kennels one rectangle and one square to get the structure of the boxes."],"metadata":{"id":"Eo88v6d0KVG4"}},{"cell_type":"code","execution_count":null,"source":["for (key,val) in enumerate(get_contour):\n","    (s1, s2, s3, s4) = cv2.boundingRect(val)\n","    region= template[s2:s2 + s4, s1:s1 + s3]\n","    region= cv2.resize(region, (57, 88))\n","    numbers[key] = region\n","kernel_1 = cv2.getStructuringElement(cv2.MORPH_RECT, (10, 5))\n","kernel_2 = cv2.getStructuringElement(cv2.MORPH_RECT, (4, 4))"],"outputs":[],"metadata":{"id":"56dTOWN2KX0P","executionInfo":{"status":"ok","timestamp":1624278895853,"user_tz":-330,"elapsed":6,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"markdown","source":["The dictionary contains keys as the numbers for 0 to 9 and the values are arrays which represent these numbers."],"metadata":{"id":"HCuHpTFlKbBB"}},{"cell_type":"code","execution_count":null,"source":["numbers.keys()"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Eivot2HYVKtp","executionInfo":{"status":"ok","timestamp":1624278897679,"user_tz":-330,"elapsed":5,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"a9b99201-8eae-467e-af99-2f794f79922e"}},{"cell_type":"markdown","source":["Now that we have the template matching ready for the card, we can go ahead and select a credit card image and read that. I have selected an image from google. You can download the image by clicking on this [link](https://www.hsbc.co.in/content/dam/hsbc/in/images/hsbc-premier-mastercard.png/_jcr_content/renditions/cq5dam.web.1280.1280.png)."],"metadata":{"id":"SsS52zFiKkZG"}},{"cell_type":"markdown","source":["### **Image processing in OpenCV**"],"metadata":{"id":"bwHaGeTsKpT9"}},{"cell_type":"markdown","source":["Let us now read this image and perform some basic pre-processing on the image. "],"metadata":{"id":"AfhZZXxNK0UM"}},{"cell_type":"code","execution_count":null,"source":["card = cv2.imread('master.png')\n","card = imutils.resize(card, width=300)\n","card_grey = cv2.cvtColor(card, cv2.COLOR_BGR2GRAY)"],"outputs":[],"metadata":{"id":"mh9Bp7DEK2Gd","executionInfo":{"status":"ok","timestamp":1624278999633,"user_tz":-330,"elapsed":371,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"markdown","source":["The image in greyscale looks like this"],"metadata":{"id":"jxePgFMNLBnd"}},{"cell_type":"code","execution_count":null,"source":["plt.figure()\n","plt.imshow(card_grey)\n","plt.show()"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":352},"id":"wombAlh5LBdD","executionInfo":{"status":"error","timestamp":1624279002354,"user_tz":-330,"elapsed":10,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"e4832bb1-cf48-4f39-91fd-1518611f0176"}},{"cell_type":"markdown","source":["Now we need to separate the light-coloured numbers from the dark background so that they can be detected. To do this, we will use a morphological operation called top-hat. Then, we will use a gradient called Sobel gradient and scale the image. "],"metadata":{"id":"nEnX62mgLGLM"}},{"cell_type":"markdown","source":["### **Morphology and scaling**"],"metadata":{"id":"t84usWtaLHvE"}},{"cell_type":"code","execution_count":null,"source":["morph = cv2.morphologyEx(card_grey, cv2.MORPH_TOPHAT, kernel_1)\n","sobel = cv2.Sobel(morph, ddepth=cv2.CV_32F, dx=1, dy=0, ksize=-1)\n","sobel = np.absolute(sobel)\n","(minimum, maximum) = (np.min(sobel), np.max(sobel))\n","sobel = (255 * ((sobel - minimum) / (maximum - minimum)))\n","sobel = sobel.astype(\"uint8\")"],"outputs":[],"metadata":{"id":"bxorrtntLAZe"}},{"cell_type":"markdown","source":["\n","\n","As you can see above, there are gaps that exist between the numbers and it can become a hurdle for the machine as they consider even the gaps as characters. To close them we need to use a technique called Otsu threshold. "],"metadata":{"id":"XZYQDeTmLSzU"}},{"cell_type":"code","execution_count":null,"source":["sobel = cv2.morphologyEx(sobel, cv2.MORPH_CLOSE, kernel_1)\n","out = cv2.threshold(sobel, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n","out = cv2.morphologyEx(out, cv2.MORPH_CLOSE, kernel_2)"],"outputs":[],"metadata":{"id":"Z2mqIAqlLWEd"}},{"cell_type":"markdown","source":["The next step is to group the digits and find their locations and apply the bounding boxes around them. To do this we will have to loop through the contours and apply the boxes. "],"metadata":{"id":"_ozXEE-wLXu0"}},{"cell_type":"code","execution_count":null,"source":["contours = cv2.findContours(out.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","contours = imutils.grab_contours(contours)\n","locations = []\n","for (key, vals) in enumerate(contours):\n","    (s1, s2, s3, s4) = cv2.boundingRect(vals)\n","    arr = s3 / float(s4)\n","    if arr > 2.5 and arr < 4.0:\n","        if (s3 > 40 and s3 < 55) and (s4 > 10 and s4 < 20):\n","            locations.append((s1, s2, s3, s4))\n","locations = sorted(locations, key=lambda s1:s1[0])\n","final_locs = []"],"outputs":[],"metadata":{"id":"CYUlvJSwLavr"}},{"cell_type":"markdown","source":["Now that we got the locations and applied the boxes around the numbers, we now need to perform the final part which is the OCR on these 4 groups of numbers. "],"metadata":{"id":"u_HsURT8LchR"}},{"cell_type":"markdown","source":["### **Extracting the numbers**"],"metadata":{"id":"rx2Bh-8OLgy2"}},{"cell_type":"markdown","source":["To do this phase we will go over the groups of digits and collect the region of interests from the bounding boxes. Then we will apply contours on them and sort the numbers from left to right. Next, we will extract the numbers in the bounding boxes and then compare them with our template to identify the digits. Finally, we will apply a correlation-based template matching and store the outputs. "],"metadata":{"id":"AwYU7Z5CLjSA"}},{"cell_type":"code","execution_count":null,"source":["for (idx, (group1, group2, group3, group4)) in enumerate(locations):\n","    detection = []\n","    get_group = card_grey[group2 - 5:group2 + group4 + 5, group1 - 5:group1 + group3 + 5]\n","    get_group = cv2.threshold(get_group, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n","    nums = cv2.findContours(get_group.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","    nums = imutils.grab_contours(nums)\n","    nums = contours.sort_contours(nums, method=\"left-to-right\")[0]\n","    for val in nums:\n","      (s1, s2, s3, s4) = cv2.boundingRect(val)\n","      regions = get_group[s2:s2 + s4, s1:s1 + s3]\n","      regions = cv2.resize(regions, (57, 88))\n","      final_vals = []\n","      for (num, numROI) in numbers.items():\n","        res = cv2.matchTemplate(regions, numROI, cv2.TM_CCOEFF)\n","        (_, mark, _, _) = cv2.minMaxLoc(res)\n","        final_vals.append(mark)\n","      detection.append(str(np.argmax(final_vals)))\n","    cv2.rectangle(image, (group1 - 5, group2 - 5),\n","      (group1 + group3 + 5, group2 + group4 + 5), (0, 0, 255), 2)\n","    cv2.putText(image, \"\".join(detection), (group1, group2 - 15),\n","    cv2.FONT_HERSHEY_SIMPLEX, 0.65, (0, 0, 255), 2)\n","    final_locs.extend(detection)"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":441},"id":"39srh9n_Llg-","executionInfo":{"status":"error","timestamp":1622447871212,"user_tz":-330,"elapsed":396,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"3e091526-0651-4040-a456-da7ce8f7a631"}},{"cell_type":"code","execution_count":null,"source":["\t# loop over the digit contours\n","\tfor c in digitCnts:\n","\t\t# compute the bounding box of the individual digit, extract\n","\t\t# the digit, and resize it to have the same fixed size as\n","\t\t# the reference OCR-A images\n","\t\t(x, y, w, h) = cv2.boundingRect(c)\n","\t\troi = group[y:y + h, x:x + w]\n","\t\troi = cv2.resize(roi, (57, 88))\n","\t\t# initialize a list of template matching scores\t\n","\t\tscores = []\n","\t\t# loop over the reference digit name and digit ROI\n","\t\tfor (digit, digitROI) in digits.items():\n","\t\t\t# apply correlation-based template matching, take the\n","\t\t\t# score, and update the scores list\n","\t\t\tresult = cv2.matchTemplate(roi, digitROI,\n","\t\t\t\tcv2.TM_CCOEFF)\n","\t\t\t(_, score, _, _) = cv2.minMaxLoc(result)\n","\t\t\tscores.append(score)\n","\t\t# the classification for the digit ROI will be the reference\n","\t\t# digit name with the *largest* template matching score\n","\t\tgroupOutput.append(str(np.argmax(scores)))"],"outputs":[],"metadata":{"id":"WygdoODjarzc"}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{"id":"-9ZnycQ5ZYt_"}},{"cell_type":"markdown","source":["Lastly, for the detection of the type of card, we need a dictionary that contains the first numbers as key and name of the card as values. Usually, in Indian cards, visa cards start with 4 and MasterCard start with 5."],"metadata":{"id":"P724Jl1kLsXO"}},{"cell_type":"code","execution_count":null,"source":["starting_digit = {\n","    \"4\": \"Visa\",\n","    \"5\": \"MasterCard\"\n","}"],"outputs":[],"metadata":{"id":"433ZiC_zLu6y"}},{"cell_type":"markdown","source":["Now we can print the output"],"metadata":{"id":"B9FlPoenLuj2"}},{"cell_type":"code","execution_count":null,"source":["print(\"Credit Card Type: {}\".format(starting_digit[final_locs[0]]))\n","print(\"Credit Card digits: {}\".format(\"\".join(final_locs)))\n","plt.imshow(cv2.cvtColor(card, cv2.COLOR_BGR2RGB))\n","plt.title('card')\n","plt.show()"],"outputs":[],"metadata":{"id":"ttVcloYZLzVM"}},{"cell_type":"markdown","source":["#**Related Articles:**\n","\n","> * [Credit Card Reader](https://analyticsindiamag.com/how-i-created-the-credit-card-reader-using-opencv/)\n","\n","> * [Real Time GUI Interactions with OpenCV](https://analyticsindiamag.com/real-time-gui-interactions-with-opencv-in-python/)\n","\n","> * [Image Processing with OpenCV](https://analyticsindiamag.com/image-processing-with-opencv-in-python/)\n","\n","> * [Getting started with OpenCV]((https://analyticsindiamag.com/getting-started-with-opencv-in-python/))\n","\n"],"metadata":{"id":"jqDB1l9I6Br-"}}]}