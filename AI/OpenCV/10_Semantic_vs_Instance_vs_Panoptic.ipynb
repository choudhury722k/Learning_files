{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"2_Semantic_vs_Instance_vs_Panoptic.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPTGQ5/SW5lvILRgNikmQ4l"},"kernelspec":{"name":"python3","display_name":"Python 3.8.8 64-bit ('base': conda)"},"language_info":{"name":"python","version":"3.8.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"interpreter":{"hash":"f60a20abaabf5a658075b37fac599269792a9493ddacd7c14d8505185d5625aa"}},"cells":[{"cell_type":"markdown","source":["# **Semantic vs Instance vs Panoptic**"],"metadata":{"id":"fxGPItxghvtg"}},{"cell_type":"markdown","source":["Image segmentation forms the basis of numerous Computer Vision projects. It segments the visual input in order to process it for tasks such as image classification and object detection. However, all the segmentation techniques may not delineate the objects in an image factory with equally satisfying accuracy. Some may be capable of merely identifying the presence of different kinds of objects in the image, some may separate out occurrences of each object type while some others may perform both these tasks. Accordingly, recent image segmentation methods can be classified into three categories viz. semantic segmentation, instance segmentation and panoptic segmentation. "],"metadata":{"id":"4ltinFQ2rD8M"}},{"cell_type":"markdown","source":["To read about it more, please refer [this](https://analyticsindiamag.com/semantic-vs-instance-vs-panoptic-which-image-segmentation-technique-to-choose/) article."],"metadata":{"id":"cNDx1iH5rSWd"}},{"cell_type":"markdown","source":["## **Practical Implementation**"],"metadata":{"id":"vUwEDVE-r_j7"}},{"cell_type":"markdown","source":["To compare all the three image segmentation techniques, we have applied each of them on a common image. Have a look at the input image as well as the code and output of each segmentation method."],"metadata":{"id":"JNsuQHwYr-UP"}},{"cell_type":"markdown","source":["## **Semantic segmentation**\n","\n","We have used the [PixelLib](https://pypi.org/project/pixellib/) Python library here which has been built for performing segmentation of images and videos with much ease.\n","\n","Install PixelLib and its dependencies as follows:"],"metadata":{"id":"HL-pWJQusCTo"}},{"cell_type":"code","execution_count":null,"source":["!python -m pip install pip --upgrade --user -q --no-warn-script-location\n","!python -m pip install numpy pandas seaborn matplotlib scipy statsmodels sklearn tensorflow keras opencv-python pillow scikit-image torch torchvision \\\n","     tqdm pixellib --user -q --no-warn-script-location\n","\n","import IPython\n","IPython.Application.instance().kernel.do_shutdown(True)\n"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["Import statements"],"metadata":{"id":"xhkvWPTasRUj"}},{"cell_type":"code","execution_count":null,"source":["import pixellib\n","from pixellib.semantic import semantic_segmentation"],"outputs":[],"metadata":{"id":"8vl3fdJHsTaQ","executionInfo":{"status":"ok","timestamp":1622789862119,"user_tz":-330,"elapsed":364,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"markdown","source":["Instantiate the semantic_segmentation class of pixellib"],"metadata":{"id":"xUHOyIL60Mql"}},{"cell_type":"code","execution_count":null,"source":["segment_image = semantic_segmentation()"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OXZCwPOr0N4y","executionInfo":{"status":"ok","timestamp":1622789934556,"user_tz":-330,"elapsed":20867,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"ff65215c-72f1-4933-f1c8-fee3498a01e2"}},{"cell_type":"markdown","source":["Load the exception model trained on pascal voc for segmenting objects. The model can be downloaded from [here](https://github.com/ayoolaolafenwa/PixelLib/releases/download/1.1/deeplabv3_xception_tf_dim_ordering_tf_kernels.h5)."],"metadata":{"id":"H78c5h2v0TEa"}},{"cell_type":"code","execution_count":null,"source":["# !wget https://github.com/ayoolaolafenwa/PixelLib/releases/download/1.1/deeplabv3_xception_tf_dim_ordering_tf_kernels.h5"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jlI_G9-W0ZHz","executionInfo":{"status":"ok","timestamp":1622789966270,"user_tz":-330,"elapsed":2305,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"18434dc5-18e5-456a-a869-ccd63f62aaac"}},{"cell_type":"code","execution_count":null,"source":["segment_image.load_pascalvoc_model(\"https://gitlab.com/AnalyticsIndiaMagazine/practicedatasets/-/raw/main/image_segmentation/deeplabv3_xception_tf_dim_ordering_tf_kernels.h5\")"],"outputs":[],"metadata":{"id":"5_sLImcY0Wjd","executionInfo":{"status":"ok","timestamp":1622789998220,"user_tz":-330,"elapsed":6113,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"markdown","source":["Perform instance segmentation on an image"],"metadata":{"id":"GnI1ZIsHuszb"}},{"cell_type":"code","execution_count":null,"source":["# !wget http://images.cocodataset.org/val2017/000000281759.jpg"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sLR-MNbLu7Ax","executionInfo":{"status":"ok","timestamp":1622789998852,"user_tz":-330,"elapsed":635,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"5ff54ae9-2b90-4bf6-a001-794c542cfffb"}},{"cell_type":"code","execution_count":null,"source":["segment_image.segmentAsPascalvoc(\"000000281759.jpg\", output_image_name = \"testoutput.jpg\")"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Be4CC2sVuvRj","executionInfo":{"status":"ok","timestamp":1622790216953,"user_tz":-330,"elapsed":9412,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"3d7484d6-ff7c-45b5-def5-f5348858b82d"}},{"cell_type":"code","execution_count":null,"source":["import matplotlib.pyplot as plt\n","import cv2\n","img = cv2.imread(\"testoutput.jpg\")\n","plt.imshow(img)\n","plt.show()"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":269},"id":"9GWQHBzQ1go-","executionInfo":{"status":"ok","timestamp":1622790279145,"user_tz":-330,"elapsed":1162,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"395f2898-6f84-42e9-98f2-7f605150fc18"}},{"cell_type":"markdown","source":["## **Instance Segmentation**"],"metadata":{"id":"GSshr6wMvcxP"}},{"cell_type":"code","execution_count":null,"source":["import pixellib\n","from pixellib.instance import instance_segmentation"],"outputs":[],"metadata":{"id":"xLzp79TaDH0k","executionInfo":{"status":"ok","timestamp":1622790216954,"user_tz":-330,"elapsed":12,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"markdown","source":["Load the mask r-cnn model to perform instance segmentation. The model can be downloaded from [here](https://github.com/ayoolaolafenwa/PixelLib/releases/download/1.2/mask_rcnn_coco.h5)."],"metadata":{"id":"Nz5W3TdnsVfZ"}},{"cell_type":"code","execution_count":null,"source":["# ! wget https://github.com/ayoolaolafenwa/PixelLib/releases/download/1.2/mask_rcnn_coco.h5"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ivWgQ4P_um3Y","executionInfo":{"status":"ok","timestamp":1622790220070,"user_tz":-330,"elapsed":3126,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"508e7fe0-94c5-46de-ee9e-18d6ddf9551c"}},{"cell_type":"code","execution_count":null,"source":["segment_image = instance_segmentation()\n","segment_image.load_model(\"https://gitlab.com/AnalyticsIndiaMagazine/practicedatasets/-/raw/main/image_segmentation/mask_rcnn_coco.h5\") \n","segment_image.segmentImage(\"000000281759.jpg\", output_image_name = \"testoutput2.jpg\")"],"outputs":[],"metadata":{"id":"L8M9I964DOE8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622790270087,"user_tz":-330,"elapsed":27882,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"e8d2c9a4-cf4e-48e0-aefd-e2e4039519e9"}},{"cell_type":"code","execution_count":null,"source":["import matplotlib.pyplot as plt\n","import cv2\n","img = cv2.imread(\"testoutput2.jpg\")\n","plt.imshow(img)\n","plt.show()"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":269},"id":"Cijvcrwo1qGZ","executionInfo":{"status":"ok","timestamp":1622790301276,"user_tz":-330,"elapsed":1482,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"b8831de6-3ae3-415f-9064-ee4af19070e7"}},{"cell_type":"markdown","source":["# **Panoptic Segmentation**"],"metadata":{"id":"dyla6G2NX-YI"}},{"cell_type":"markdown","source":["Panoptic segmentation is an image segmentation method used for Computer Vision tasks. It unifies two distinct concepts used to segment images namely, semantic segmentation and instance segmentation."],"metadata":{"id":"mkU0QXpwYCZV"}},{"cell_type":"markdown","source":["To read about it more, please refer [this](https://analyticsindiamag.com/guide-to-panoptic-segmentation-a-semantic-instance-segmentation-approach/) article."],"metadata":{"id":"LxKfGPcYYFX1"}},{"cell_type":"markdown","source":["## **Panoptic Segmentation**"],"metadata":{"id":"V-6iqYVdZ2tF"}},{"cell_type":"markdown","source":["Import the required libraries"],"metadata":{"id":"TZL5A11ccRcE"}},{"cell_type":"code","execution_count":null,"source":["from PIL import Image\n","import requests\n","import io\n","import math\n","import matplotlib.pyplot as plt\n","%config InlineBackend.figure_format = 'retina'\n","import torch\n","from torch import nn\n","from torchvision.models import resnet50\n","import torchvision.transforms as T\n","import numpy\n","torch.set_grad_enabled(False);\n","import itertools\n","import seaborn as sns "],"outputs":[],"metadata":{"id":"f1rZe7ANWZxh"}},{"cell_type":"markdown","source":["Install the Panoptic API from GitHub for panoptic inference"],"metadata":{"id":"c267PsSccXox"}},{"cell_type":"code","execution_count":null,"source":["!python -m pip install git+https://github.com/cocodataset/panopticapi.git --user -q"],"outputs":[],"metadata":{"id":"teerxTVNcZUy"}},{"cell_type":"markdown","source":["Import the installed API"],"metadata":{"id":"59HkYnMoca_j"}},{"cell_type":"code","execution_count":null,"source":["import panopticapi\n","from panopticapi.utils import id2rgb, rgb2id "],"outputs":[],"metadata":{"id":"dz2ENecRcdQf"}},{"cell_type":"markdown","source":["List of COCO semantic classes:"],"metadata":{"id":"niXfmsmLcfL6"}},{"cell_type":"code","execution_count":null,"source":["CLASSES = [\n","     'N/A', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n","     'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A',\n","     'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse',\n","     'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'N/A',   \n","     'Backpack', 'umbrella', 'N/A', 'N/A', 'handbag', 'tie', 'suitcase', \n","     'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', \n","     'baseball glove', 'skateboard', 'surfboard', 'tennis racket',    \n","     'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', \n","     'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', \n","     'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table', 'N/A', 'N/A', 'toilet', 'N/A', \n","     'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', \n","     'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book', \n","     'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'] "],"outputs":[],"metadata":{"id":"S8_wc0gpchEm"}},{"cell_type":"markdown","source":["Enumerate the above classes (Detectron2 model uses different numbering convention so we need to change it)"],"metadata":{"id":"HBqnRy78ctgn"}},{"cell_type":"code","execution_count":null,"source":["coco2d2 = {}\n","count = 0\n","for i, c in enumerate(CLASSES):\n","  if c != \"N/A\":\n","    coco2d2[i] = count\n","    count+=1 "],"outputs":[],"metadata":{"id":"u-ORGgYncvmW"}},{"cell_type":"markdown","source":["Perform standard PyTorch mean-std input image normalization"],"metadata":{"id":"OCcD0s7Gcxp6"}},{"cell_type":"code","execution_count":null,"source":["transform = T.Compose([\n","    T.Resize(800),\n","    T.ToTensor(),\n","    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","]) "],"outputs":[],"metadata":{"id":"d71nH9BIc1pB"}},{"cell_type":"markdown","source":["Load a pre-trained model from torch hub and request the post-processor"],"metadata":{"id":"JcTSS6nNc72D"}},{"cell_type":"code","execution_count":null,"source":["model, postprocessor = torch.hub.load('facebookresearch/detr', 'detr_resnet101_panoptic', pretrained=True, return_postprocessor=True, num_classes=250)\n","model.eval();"],"outputs":[],"metadata":{"id":"Qi1ORCcBc99s"}},{"cell_type":"markdown","source":["Retrieve an image from the validation set of COCO dataset for testing purpose"],"metadata":{"id":"T66vkfVjdB3l"}},{"cell_type":"code","execution_count":null,"source":["url = \"http://images.cocodataset.org/val2017/000000281759.jpg\"\n","im = Image.open(requests.get(url, stream=True).raw)"],"outputs":[],"metadata":{"id":"EzB1FH_YdEAS"}},{"cell_type":"markdown","source":["Mean-std normalize the input testing image (batch-size: 1)"],"metadata":{"id":"crXHcIKpdGJv"}},{"cell_type":"code","execution_count":null,"source":["img = transform(im).unsqueeze(0)\n","out = model(img) "],"outputs":[],"metadata":{"id":"iec-lZT2dHsw"}},{"cell_type":"markdown","source":["Compute the probability score for each possible class, excluding the “no-object” class (the last one)"],"metadata":{"id":"KrTTe1OpdKO8"}},{"cell_type":"code","execution_count":null,"source":["scores = out[\"pred_logits\"].softmax(-1)[..., :-1].max(-1)[0]"],"outputs":[],"metadata":{"id":"mmzhc_KVdL91"}},{"cell_type":"markdown","source":["Threshold the confidence to only masks with high confidence >0.85"],"metadata":{"id":"wBjFIiJadOB8"}},{"cell_type":"code","execution_count":null,"source":["keep = scores > 0.85"],"outputs":[],"metadata":{"id":"C3LIl0G_dQvk"}},{"cell_type":"markdown","source":["Plot the masks satisfying the confidence level condition"],"metadata":{"id":"XNpsQzzZdQkA"}},{"cell_type":"code","execution_count":null,"source":["ncols = 5\n","fig, axs = plt.subplots(ncols=ncols, nrows=math.ceil(keep.sum().item() / ncols), figsize=(18, 10))\n","for line in axs:\n","    for a in line:\n","        a.axis('off')\n","for i, mask in enumerate(out[\"pred_masks\"][keep]):\n","    ax = axs[i // ncols, i % ncols]\n","    ax.imshow(mask, cmap=\"cividis\")\n","    ax.axis('off')\n","fig.tight_layout() "],"outputs":[],"metadata":{"id":"vykgyROhdT9p"}},{"cell_type":"markdown","source":["Merge the individual predictions obtained by running the above lines of code into a unified panoptic segmentation. For that, we use DETR’s postprocessor.\n","\n","The post-processor requires as input the target size of predictions"],"metadata":{"id":"6r1X0H_sdXnb"}},{"cell_type":"code","execution_count":null,"source":["result = postprocessor(out, torch.as_tensor(img.shape[-2:]).unsqueeze(0))[0]"],"outputs":[],"metadata":{"id":"G9ueSI-8daMN"}},{"cell_type":"markdown","source":["The segmentation is stored in a special-format png"],"metadata":{"id":"WBD4C1A0eH9p"}},{"cell_type":"code","execution_count":null,"source":["panoptic_seg = Image.open(io.BytesIO(result['png_string']))\n","panoptic_seg = numpy.array(panoptic_seg, dtype=numpy.uint8).copy()"],"outputs":[],"metadata":{"id":"8Ns55VfdeLMD"}},{"cell_type":"markdown","source":["Retrieve the instance id corresponding to each mask"],"metadata":{"id":"Zd2TGa8UeNhn"}},{"cell_type":"code","execution_count":null,"source":["panoptic_seg_id = rgb2id(panoptic_seg)"],"outputs":[],"metadata":{"id":"aWdCLAu0ePHj"}},{"cell_type":"markdown","source":["Colour each mask individually and plot the visualization"],"metadata":{"id":"qXo9KL4QeQ3E"}},{"cell_type":"code","execution_count":null,"source":["import itertools\n","import seaborn as sns\n","palette = itertools.cycle(sns.color_palette())\n","panoptic_seg[:, :, :] = 0\n","for id in range(panoptic_seg_id.max() + 1):\n","  panoptic_seg[panoptic_seg_id == id] = numpy.asarray(next(palette)) * 255\n","plt.figure(figsize=(15,15))\n","plt.imshow(panoptic_seg)\n","plt.axis('off')\n","plt.show() "],"outputs":[],"metadata":{"id":"u1fK4NubeSoL"}},{"cell_type":"markdown","source":["Use Detectron2’s plotting utilities to better visualize the above panoptic segmentation results.\n","\n","Import the utilities"],"metadata":{"id":"vrmMhTZeejAW"}},{"cell_type":"code","execution_count":null,"source":["# install dependencies: \n","!python -m pip install pyyaml==5.1 --user -q\n","import torch, torchvision\n","print(torch.__version__, torch.cuda.is_available())\n","!gcc --version\n","# opencv is pre-installed on colab"],"outputs":[],"metadata":{"id":"9_FzH13EjseR"}},{"cell_type":"code","execution_count":null,"source":["# install detectron2:\n","# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n","import torch\n","assert torch.__version__.startswith(\"1.8\")   # need to manually install torch 1.8\n","!python -m pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.8/index.html --user -q\n","# exit(0)  # After installation, you need to \"restart runtime\" in Colab. This line can also restart runtime"],"outputs":[],"metadata":{"id":"b-i4hmGYk1dL"}},{"cell_type":"code","execution_count":null,"source":["# Some basic setup:\n","# Setup detectron2 logger\n","import detectron2\n","from detectron2.utils.logger import setup_logger\n","setup_logger()"],"outputs":[],"metadata":{"id":"ZyAvNCJMmvFF"}},{"cell_type":"code","execution_count":null,"source":["from detectron2.config import get_cfg\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.data import MetadataCatalog"],"outputs":[],"metadata":{"id":"BiW87dNfek49"}},{"cell_type":"markdown","source":["Extract the segments information and the panoptic result from DETR’s prediction"],"metadata":{"id":"SyIX1Aw-eqCg"}},{"cell_type":"code","execution_count":null,"source":["from copy import deepcopy\n","segments_info = deepcopy(result[\"segments_info\"])"],"outputs":[],"metadata":{"id":"lRv-9JoIer5h"}},{"cell_type":"markdown","source":["Store the panoptic predictions in a special format png"],"metadata":{"id":"dDbVOowPezGl"}},{"cell_type":"code","execution_count":null,"source":["panoptic_seg = Image.open(io.BytesIO(result['png_string']))\n","final_w, final_h = panoptic_seg.size "],"outputs":[],"metadata":{"id":"qflD4A_4e0rG"}},{"cell_type":"markdown","source":["Convert the png into segment id map"],"metadata":{"id":"luEd9A3We2sU"}},{"cell_type":"code","execution_count":null,"source":["panoptic_seg = numpy.array(panoptic_seg, dtype=numpy.uint8)\n","panoptic_seg = torch.from_numpy(rgb2id(panoptic_seg))"],"outputs":[],"metadata":{"id":"rc6oa7-he5K-"}},{"cell_type":"markdown","source":["Change Detectron2’s numbering to appropriate class id’s"],"metadata":{"id":"Cx-Flyk-e7jE"}},{"cell_type":"code","execution_count":null,"source":["meta = MetadataCatalog.get(\"coco_2017_val_panoptic_separated\")\n","for i in range(len(segments_info)):\n","    c = segments_info[i][\"category_id\"]\n","    segments_info[i][\"category_id\"] = meta.thing_dataset_id_to_contiguous_id[c] if segments_info[i][\"isthing\"] else meta.stuff_dataset_id_to_contiguous_id[c] "],"outputs":[],"metadata":{"id":"7upJ2fwre-qY"}},{"cell_type":"markdown","source":["Visualize the improved prediction results"],"metadata":{"id":"Wnl-xgGVfCWy"}},{"cell_type":"code","execution_count":null,"source":["v = Visualizer(numpy.array(im.copy().resize((final_w, final_h)))[:, :, ::-1], meta, scale=1.0)\n","v._default_font_size = 20\n","v = v.draw_panoptic_seg_predictions(panoptic_seg, segments_info, area_threshold=0)\n","plt.imshow(v.get_image()) \n","plt.show()"],"outputs":[],"metadata":{"id":"322yy0jKfEPz"}},{"cell_type":"markdown","source":["#**Related Articles:**\n","\n","> * [Comparison of Semantic, Instance and Panoptic Segmentation](https://analyticsindiamag.com/semantic-vs-instance-vs-panoptic-which-image-segmentation-technique-to-choose/)\n","\n","> * [Panoptic Segmentation](https://analyticsindiamag.com/guide-to-panoptic-segmentation-a-semantic-instance-segmentation-approach/)\n","\n","> * [PaddleSeg](https://analyticsindiamag.com/guide-to-asymmetric-non-local-neural-networks-using-paddleseg/)\n","\n","> * [MMDetection](https://analyticsindiamag.com/guide-to-mmdetection-an-object-detection-python-toolbox/)\n","\n","> * [Facebook D2Go to Mobile](https://analyticsindiamag.com/facebooks-d2go-brings-detectron2-to-mobile/)\n","\n","> * [Multi Class Image Classification with Tensorflow and Keras](https://analyticsindiamag.com/multi-label-image-classification-with-tensorflow-keras/)\n","\n","> * [Transfer Learning in Tensorflow Keras](https://analyticsindiamag.com/a-practical-guide-to-implement-transfer-learning-in-tensorflow/)"],"metadata":{"id":"1ZtPNx78qe5T"}}]}