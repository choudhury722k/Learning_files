{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1_Perpetual_View_Generation.ipynb","provenance":[],"authorship_tag":"ABX9TyNh13C/BdQdXBSf9eb0RqnX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"3ZTdXaR-Ye56"},"source":["# Perpetual View Generation"]},{"cell_type":"markdown","metadata":{"id":"7NoBQlJeYdzG"},"source":["Infinite Nature, aka perpetual view generation, allows you to take an image and fly into it as a bird would do, mapping and exploring all the landscape. We generate a long range of novel views (constructing new images relating to the original but progressive). This corresponds to an arbitrary or random long camera following a trajectory of a sky view, for example, a bird. All this from a single image!! \n","\n","This sounds like a challenging problem, considering how far the generation will go beyond the capabilities of current view synthesis models. These too work for a limited number of viewpoints (the image from where the synthesis will start or the base image). Another problem was that these viewpoints degenerate quickly and generate images/frames with minimal changes.\n","\n","The technique discussed in this article solves all the above problems by using a hybrid solution based on integrating both image synthesis and geometry in an interactive framework with iterative rendering, refining and repeating. This allows long-range generation that can cover large distances even after hundreds of frames. This approach is trained upon a set of monocular video sequences without any manual annotation, which saves a lot of time. "]},{"cell_type":"markdown","metadata":{"id":"wwp3EMJgYimG"},"source":["To read about it more, please refer [this](https://analyticsindiamag.com/guide-to-infinite-nature-for-perpetual-view-generation/) article."]},{"cell_type":"markdown","metadata":{"id":"5C-wo_CmYp8u"},"source":["# Code Implementation\n","\n","Below are the instructions for running the model locally.\n","\n","Install libraries with the given requirements file here"]},{"cell_type":"markdown","metadata":{"id":"EvBQf1UZNu0j"},"source":["## Download code, model weights, and example data and install dependencies."]},{"cell_type":"code","metadata":{"id":"hypYi7EJNxJ6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624527802197,"user_tz":-330,"elapsed":170752,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"3c3a0608-f7b2-42ac-da90-1cee065a6a3a"},"source":["%%shell\n","echo Fetching code from github...\n","\n","apt install subversion\n","svn export --force https://github.com/google-research/google-research/trunk/infinite_nature\n","\n","echo\n","echo Fetching trained model weights...\n","rm -f autocruise_input*.pkl\n","rm -f ckpt.tar.gz\n","rm -rf ckpt\n","wget https://storage.googleapis.com/gresearch/infinite_nature_public/autocruise_input1.pkl\n","wget https://storage.googleapis.com/gresearch/infinite_nature_public/autocruise_input2.pkl\n","wget https://storage.googleapis.com/gresearch/infinite_nature_public/autocruise_input3.pkl\n","wget https://storage.googleapis.com/gresearch/infinite_nature_public/ckpt.tar.gz\n","tar -xf ckpt.tar.gz\n","\n","echo\n","echo Installing required dependencies...\n","pip install -r infinite_nature/requirements.txt\n","\n","echo\n","echo Fetching tf_mesh_renderer and compiling kernels...\n","cd infinite_nature\n","rm -rf tf_mesh_renderer\n","source download_tf_mesh_renderer.sh\n","\n","echo Done.\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Fetching code from github...\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following additional packages will be installed:\n","  libapr1 libaprutil1 libserf-1-1 libsvn1\n","Suggested packages:\n","  db5.3-util libapache2-mod-svn subversion-tools\n","The following NEW packages will be installed:\n","  libapr1 libaprutil1 libserf-1-1 libsvn1 subversion\n","0 upgraded, 5 newly installed, 0 to remove and 39 not upgraded.\n","Need to get 2,237 kB of archives.\n","After this operation, 9,910 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libapr1 amd64 1.6.3-2 [90.9 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libaprutil1 amd64 1.6.1-2 [84.4 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libserf-1-1 amd64 1.3.9-6 [44.4 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libsvn1 amd64 1.9.7-4ubuntu1 [1,183 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 subversion amd64 1.9.7-4ubuntu1 [834 kB]\n","Fetched 2,237 kB in 1s (2,486 kB/s)\n","Selecting previously unselected package libapr1:amd64.\n","(Reading database ... 160772 files and directories currently installed.)\n","Preparing to unpack .../libapr1_1.6.3-2_amd64.deb ...\n","Unpacking libapr1:amd64 (1.6.3-2) ...\n","Selecting previously unselected package libaprutil1:amd64.\n","Preparing to unpack .../libaprutil1_1.6.1-2_amd64.deb ...\n","Unpacking libaprutil1:amd64 (1.6.1-2) ...\n","Selecting previously unselected package libserf-1-1:amd64.\n","Preparing to unpack .../libserf-1-1_1.3.9-6_amd64.deb ...\n","Unpacking libserf-1-1:amd64 (1.3.9-6) ...\n","Selecting previously unselected package libsvn1:amd64.\n","Preparing to unpack .../libsvn1_1.9.7-4ubuntu1_amd64.deb ...\n","Unpacking libsvn1:amd64 (1.9.7-4ubuntu1) ...\n","Selecting previously unselected package subversion.\n","Preparing to unpack .../subversion_1.9.7-4ubuntu1_amd64.deb ...\n","Unpacking subversion (1.9.7-4ubuntu1) ...\n","Setting up libapr1:amd64 (1.6.3-2) ...\n","Setting up libaprutil1:amd64 (1.6.1-2) ...\n","Setting up libserf-1-1:amd64 (1.3.9-6) ...\n","Setting up libsvn1:amd64 (1.9.7-4ubuntu1) ...\n","Setting up subversion (1.9.7-4ubuntu1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n","/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n","\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","A    infinite_nature\n","A    infinite_nature/README.md\n","A    infinite_nature/autocruise.py\n","A    infinite_nature/config.py\n","A    infinite_nature/download_tf_mesh_renderer.sh\n","A    infinite_nature/fly_camera.py\n","A    infinite_nature/geometry.py\n","A    infinite_nature/infinite_nature_demo.ipynb\n","A    infinite_nature/infinite_nature_lib.py\n","A    infinite_nature/mesh_renderer_tf2_upgrade.patch\n","A    infinite_nature/networks.py\n","A    infinite_nature/ops.py\n","A    infinite_nature/render.py\n","A    infinite_nature/render_utils.py\n","A    infinite_nature/requirements.txt\n","A    infinite_nature/spade.py\n","Exported revision 6819.\n","\n","Fetching trained model weights...\n","--2021-06-24 09:40:44--  https://storage.googleapis.com/gresearch/infinite_nature_public/autocruise_input1.pkl\n","Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.12.240, 172.217.164.176, 142.250.81.208, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.12.240|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 655723 (640K) [application/octet-stream]\n","Saving to: ‘autocruise_input1.pkl’\n","\n","autocruise_input1.p 100%[===================>] 640.35K  --.-KB/s    in 0.005s  \n","\n","2021-06-24 09:40:44 (123 MB/s) - ‘autocruise_input1.pkl’ saved [655723/655723]\n","\n","--2021-06-24 09:40:44--  https://storage.googleapis.com/gresearch/infinite_nature_public/autocruise_input2.pkl\n","Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.13.240, 172.217.15.80, 142.251.33.208, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.13.240|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 655608 (640K) [application/octet-stream]\n","Saving to: ‘autocruise_input2.pkl’\n","\n","autocruise_input2.p 100%[===================>] 640.24K  --.-KB/s    in 0.005s  \n","\n","2021-06-24 09:40:44 (123 MB/s) - ‘autocruise_input2.pkl’ saved [655608/655608]\n","\n","--2021-06-24 09:40:44--  https://storage.googleapis.com/gresearch/infinite_nature_public/autocruise_input3.pkl\n","Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.2.112, 172.217.164.144, 172.253.62.128, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.2.112|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 655608 (640K) [application/octet-stream]\n","Saving to: ‘autocruise_input3.pkl’\n","\n","autocruise_input3.p 100%[===================>] 640.24K  --.-KB/s    in 0.005s  \n","\n","2021-06-24 09:40:45 (119 MB/s) - ‘autocruise_input3.pkl’ saved [655608/655608]\n","\n","--2021-06-24 09:40:45--  https://storage.googleapis.com/gresearch/infinite_nature_public/ckpt.tar.gz\n","Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.12.240, 172.217.164.176, 142.250.81.208, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.12.240|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 554884799 (529M) [application/x-tar]\n","Saving to: ‘ckpt.tar.gz’\n","\n","ckpt.tar.gz         100%[===================>] 529.18M   131MB/s    in 4.2s    \n","\n","2021-06-24 09:40:49 (127 MB/s) - ‘ckpt.tar.gz’ saved [554884799/554884799]\n","\n","\n","Installing required dependencies...\n","Collecting tensorflow==2.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/1a/0d79814736cfecc825ab8094b39648cc9c46af7af1bae839928acb73b4dd/tensorflow-2.2.0-cp37-cp37m-manylinux2010_x86_64.whl (516.2MB)\n","\u001b[K     |████████████████████████████████| 516.2MB 34kB/s \n","\u001b[?25hCollecting tensorflow-addons==0.10.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/56/5d2d632b0c55beb2d64977909a53337aadab693deba428aa71c4021c6c3d/tensorflow_addons-0.10.0-cp37-cp37m-manylinux2010_x86_64.whl (1.0MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 56kB/s \n","\u001b[?25hCollecting imageio==2.9.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/57/5d899fae74c1752f52869b613a8210a2480e1a69688e65df6cb26117d45d/imageio-2.9.0-py3-none-any.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 33.0MB/s \n","\u001b[?25hRequirement already satisfied: numpy==1.19.5 in /usr/local/lib/python3.7/dist-packages (from -r infinite_nature/requirements.txt (line 4)) (1.19.5)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r infinite_nature/requirements.txt (line 1)) (3.3.0)\n","Collecting tensorboard<2.3.0,>=2.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/74/0a6fcb206dcc72a6da9a62dd81784bfdbff5fedb099982861dc2219014fb/tensorboard-2.2.2-py3-none-any.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 21.2MB/s \n","\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r infinite_nature/requirements.txt (line 1)) (0.36.2)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r infinite_nature/requirements.txt (line 1)) (1.34.1)\n","Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r infinite_nature/requirements.txt (line 1)) (1.4.1)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r infinite_nature/requirements.txt (line 1)) (1.12.1)\n","Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r infinite_nature/requirements.txt (line 1)) (1.6.3)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r infinite_nature/requirements.txt (line 1)) (1.1.0)\n","Collecting h5py<2.11.0,>=2.10.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/c0/abde58b837e066bca19a3f7332d9d0493521d7dd6b48248451a9e3fe2214/h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 32.7MB/s \n","\u001b[?25hRequirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r infinite_nature/requirements.txt (line 1)) (0.2.0)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r infinite_nature/requirements.txt (line 1)) (3.12.4)\n","Collecting tensorflow-estimator<2.3.0,>=2.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/f5/926ae53d6a226ec0fda5208e0e581cffed895ccc89e36ba76a8e60895b78/tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454kB)\n","\u001b[K     |████████████████████████████████| 460kB 41.3MB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r infinite_nature/requirements.txt (line 1)) (0.12.0)\n","Collecting gast==0.3.3\n","  Downloading https://files.pythonhosted.org/packages/d6/84/759f5dd23fec8ba71952d97bcc7e2c9d7d63bdc582421f3cd4be845f0c98/gast-0.3.3-py2.py3-none-any.whl\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r infinite_nature/requirements.txt (line 1)) (1.15.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r infinite_nature/requirements.txt (line 1)) (1.1.2)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons==0.10.0->-r infinite_nature/requirements.txt (line 2)) (2.7.1)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio==2.9.0->-r infinite_nature/requirements.txt (line 3)) (7.1.2)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r infinite_nature/requirements.txt (line 1)) (0.4.4)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r infinite_nature/requirements.txt (line 1)) (3.3.4)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r infinite_nature/requirements.txt (line 1)) (1.0.1)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r infinite_nature/requirements.txt (line 1)) (1.31.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r infinite_nature/requirements.txt (line 1)) (1.8.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r infinite_nature/requirements.txt (line 1)) (2.23.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r infinite_nature/requirements.txt (line 1)) (57.0.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r infinite_nature/requirements.txt (line 1)) (1.3.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r infinite_nature/requirements.txt (line 1)) (4.5.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r infinite_nature/requirements.txt (line 1)) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r infinite_nature/requirements.txt (line 1)) (4.7.2)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r infinite_nature/requirements.txt (line 1)) (4.2.2)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r infinite_nature/requirements.txt (line 1)) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r infinite_nature/requirements.txt (line 1)) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r infinite_nature/requirements.txt (line 1)) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r infinite_nature/requirements.txt (line 1)) (2.10)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r infinite_nature/requirements.txt (line 1)) (3.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r infinite_nature/requirements.txt (line 1)) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r infinite_nature/requirements.txt (line 1)) (3.7.4.3)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r infinite_nature/requirements.txt (line 1)) (0.4.8)\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: tensorboard, h5py, tensorflow-estimator, gast, tensorflow, tensorflow-addons, imageio\n","  Found existing installation: tensorboard 2.5.0\n","    Uninstalling tensorboard-2.5.0:\n","      Successfully uninstalled tensorboard-2.5.0\n","  Found existing installation: h5py 3.1.0\n","    Uninstalling h5py-3.1.0:\n","      Successfully uninstalled h5py-3.1.0\n","  Found existing installation: tensorflow-estimator 2.5.0\n","    Uninstalling tensorflow-estimator-2.5.0:\n","      Successfully uninstalled tensorflow-estimator-2.5.0\n","  Found existing installation: gast 0.4.0\n","    Uninstalling gast-0.4.0:\n","      Successfully uninstalled gast-0.4.0\n","  Found existing installation: tensorflow 2.5.0\n","    Uninstalling tensorflow-2.5.0:\n","      Successfully uninstalled tensorflow-2.5.0\n","  Found existing installation: imageio 2.4.1\n","    Uninstalling imageio-2.4.1:\n","      Successfully uninstalled imageio-2.4.1\n","Successfully installed gast-0.3.3 h5py-2.10.0 imageio-2.9.0 tensorboard-2.2.2 tensorflow-2.2.0 tensorflow-addons-0.10.0 tensorflow-estimator-2.2.0\n","\n","Fetching tf_mesh_renderer and compiling kernels...\n","Cloning into 'tf_mesh_renderer'...\n","remote: Enumerating objects: 180, done.\u001b[K\n","remote: Total 180 (delta 0), reused 0 (delta 0), pack-reused 180\u001b[K\n","Receiving objects: 100% (180/180), 1.25 MiB | 31.32 MiB/s, done.\n","Resolving deltas: 100% (96/96), done.\n","HEAD is now at 8f85195 Merge pull request #2 from tomguluson92/patch-1\n","Done.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":[""]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"bamRrihcZIjK"},"source":["Import Dependencies"]},{"cell_type":"code","metadata":{"id":"08MXs7cBPDwO","executionInfo":{"status":"ok","timestamp":1624527803204,"user_tz":-330,"elapsed":1013,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}},"source":["import tensorflow as tf\n","import os\n","import sys\n","\n","# Make sure dynamic linking can find tensorflow libraries.\n","os.system('ldconfig ' + tf.sysconfig.get_lib())\n","\n","# Make sure python can find our libraries.\n","sys.path.append('infinite_nature')\n","sys.path.append('infinite_nature/tf_mesh_renderer/mesh_renderer')\n","\n","# Make sure the mesh renderer library knows where to load its .so file from.\n","os.environ['TEST_SRCDIR'] = 'infinite_nature'"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"nvJVkxMbGy6D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624527831655,"user_tz":-330,"elapsed":28456,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"d5c2c857-5896-457b-d0c4-8a4b7c6f7cb6"},"source":["import imageio\n","import IPython\n","import numpy as np\n","import pickle\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","\n","import config\n","import fly_camera\n","import infinite_nature_lib\n","\n","# Build model and restore checkpoint.\n","config.set_training(False)\n","model_path = \"ckpt/model.ckpt-6935893\"\n","render_refine, style_encoding = infinite_nature_lib.load_model(model_path)\n","initial_rgbds = [\n","    pickle.load(open(\"autocruise_input1.pkl\", \"rb\"))['input_rgbd'],\n","    pickle.load(open(\"autocruise_input2.pkl\", \"rb\"))['input_rgbd'],\n","    pickle.load(open(\"autocruise_input3.pkl\", \"rb\"))['input_rgbd']]\n","\n","# Code for an autopilot demo. We expose two functions that will be invoked\n","# from an HTML/JS frontend: reset and step.\n","\n","# The state that we need to remember while flying:\n","state = {\n","  'intrinsics': None,\n","  'pose': None,\n","  'rgbd': None,\n","  'start_rgbd': None,\n","  'style_noise': None,\n","  'next_pose_function': None,\n","  'direction_offset': None,  # Direction controlled by user's mouse clicks.\n","}\n","\n","def current_image_as_png():\n","  imgdata = tf.image.encode_png(\n","      tf.image.convert_image_dtype(state['rgbd'][..., :3], dtype=tf.uint8))\n","  return IPython.display.Image(data=imgdata.numpy())\n","\n","def reset(rgbd=None):\n","  if rgbd is None:\n","    rgbd = state['start_rgbd']\n","\n","  height, width, _ = rgbd.shape\n","  aspect_ratio = width / float(height)\n","\n","  rgbd = tf.image.resize(rgbd, [160, 256])\n","  state['rgbd'] = rgbd\n","  state['start_rgbd'] = rgbd\n","  state['pose'] = np.array(\n","      [[1.0, 0.0, 0.0, 0.0],\n","       [0.0, 1.0, 0.0, 0.0],\n","       [0.0, 0.0, 1.0, 0.0]],\n","      dtype=np.float32)\n","  # 0.8 focal_x corresponds to a FOV of ~64 degrees.\n","  state['intrinsics'] = np.array(\n","      [0.8, 0.8 * aspect_ratio, .5, .5],\n","      dtype=np.float32)\n","  state['direction_offset'] = (0.0, 0.0)\n","  state['style_noise'] = style_encoding(rgbd)\n","  state['next_pose_function'] = fly_camera.fly_dynamic(\n","    state['intrinsics'],\n","    state['pose'],\n","    turn_function=(lambda _: state['direction_offset']))\n","  return current_image_as_png()\n","\n","\n","def step(offsetx, offsety):\n","  state['direction_offset'] = (offsetx, offsety)\n","  next_pose = state['next_pose_function'](state['rgbd'])\n","  next_rgbd = render_refine(\n","       state['rgbd'], state['style_noise'],\n","       state['pose'], state['intrinsics'],\n","       next_pose, state['intrinsics'])\n","  state['pose'] = next_pose\n","  state['rgbd'] = next_rgbd\n","  return current_image_as_png()\n","\n","\n","# To run on user-supplied images, we use MiDaS V2 to obtain initial disparity.\n","midas_model = hub.load('https://tfhub.dev/intel/midas/v2/2', tags=['serve'])\n","\n","def midas_disparity(rgb):\n","  \"\"\"Computes MiDaS v2 disparity on an RGB input image.\n","\n","  Args:\n","    rgb: [H, W, 3] Range [0.0, 1.0].\n","  Returns:\n","    [H, W, 1] MiDaS disparity resized to the input size and in the range\n","    [0.0, 1.0]\n","  \"\"\"\n","  size = rgb.shape[:2]\n","  resized = tf.image.resize(rgb, [384, 384], tf.image.ResizeMethod.BICUBIC)\n","  # MiDaS networks wants [1, C, H, W]\n","  midas_input = tf.transpose(resized, [2, 0, 1])[tf.newaxis]\n","  prediction = midas_model.signatures['serving_default'](midas_input)['default'][0]\n","  disp_min = tf.reduce_min(prediction)\n","  disp_max = tf.reduce_max(prediction)\n","  prediction = (prediction - disp_min) / (disp_max - disp_min)\n","  return tf.image.resize(\n","      prediction[..., tf.newaxis], size,  method=tf.image.ResizeMethod.AREA)\n","\n","\n","def load_initial(i):\n","  return reset(rgbd=initial_rgbds[i])\n","\n","\n","def load_image(data):\n","  # Data converted from JS ends up as a string, needs to be converted to\n","  # bytes using Latin-1 encoding (which just maps 0-255 to 0-255).\n","  data = data.encode('Latin-1')\n","  rgb = tf.image.decode_image(data, channels=3, dtype=tf.float32)\n","  resized = tf.image.resize(rgb, [160, 256], tf.image.ResizeMethod.AREA)\n","  rgbd = tf.concat([resized, midas_disparity(resized)], axis=-1)\n","  return reset(rgbd=rgbd)\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From infinite_nature/ops.py:48: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.Flatten instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","WARNING:tensorflow:From infinite_nature/ops.py:52: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.Dense instead.\n","WARNING:tensorflow:From infinite_nature/ops.py:193: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.keras.layers.Conv2D` instead.\n","Restoring from ckpt/model.ckpt-6935893\n","INFO:tensorflow:Restoring parameters from ckpt/model.ckpt-6935893\n","Model restored.\n","INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"sCuRX1liUEVM","colab":{"base_uri":"https://localhost:8080/","height":644},"executionInfo":{"status":"ok","timestamp":1624528408415,"user_tz":-330,"elapsed":728,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"95aa6e44-e465-4dc9-a733-2a3ddb027420"},"source":["import IPython\n","from google.colab import output\n","\n","# The front-end for our interactive demo.\n","\n","html='''\n","<style>\n","#view {\n","  width: 512px;\n","  height: 320px;\n","  background-color: #aaa;\n","  background-size: 100% 100%;\n","  border: 1px solid #000;\n","  margin: 20px;\n","  position: relative;\n","}\n","#rgb {\n","  height: 100%;\n","}\n","#cursor {\n","  position: absolute;\n","  height: 0; width: 0;\n","  left: 50%; top: 50%;\n","  opacity: .5;\n","}\n","#cursor::before, #cursor::after {\n","  content: '';\n","  position: absolute;\n","  background: #f04;\n","  pointer-events: none;\n","}\n","#cursor::before {\n","  left: -10px; top: -1px; width: 20px; height: 2px;\n","}\n","#cursor::after {\n","  left: -1px; top: -10px; width: 2px; height: 20px;\n","}\n",".buttons {\n","  margin: 20px;\n","}\n",".buttons div {\n","  display: inline-block;\n","  cursor: pointer;\n","  padding: 20px;\n","  background: #eee;\n","  border: 2px solid #aaa;\n","  border-radius: 3px;\n","  margin-right: 10px;\n","  font-weight: bold;\n","  text-transform: uppercase;\n","  letter-spacing: 1px;\n","  color: #444;\n","}\n",".buttons div:active {\n","  background: #444;\n","  color: #fff;\n","}\n","h3 {\n","  margin-left: 20px;\n","}\n","</style>\n","<h3>Infinite Nature interactive demo</h3>\n","<div id=view><img id=rgb><div id=cursor></div></div>\n","<div class=buttons>\n","Click <b>Play</b> to run or <b>Step</b> to advance frame by frame.\n","Click mouse over image to steer.<br><br>\n","<div id=restart>Restart</div><div id=play>Play</div><div id=pause>Pause</div><div id=step>Step</div>\n","<br><br>\n","Select starting image (be patient…):<br><br>\n","<div id=image1>Image 1</div><div id=image2>Image 2</div><div id=image3>Image 3</div><div id=upload>Upload…</div><br>\n","<input style=\"display:none\" type=file id=chooser accept=\".png,.jpg\">\n","</div>\n","<script>\n","let playing = true;\n","let pending = false;\n","let x = 0.5;\n","let y = 0.5;\n","let cursor_count = 0;\n","\n","async function call(name, ...parms) {\n","  pending = true;\n","  const result = await google.colab.kernel.invokeFunction(name, parms, {});\n","  pending = false;\n","  const url = `data:image/png;base64,${result.data['image/png']}`;\n","  document.querySelector('#rgb').src = url;\n","  if (!playing) { return; }\n","  step();\n","}\n","\n","async function reset() {\n","  playing = false;\n","  await call('reset');\n","}\n","\n","async function selectImage(i) {\n","  playing = false;\n","  await call('load_initial', i);\n","}\n","\n","function upload() {\n","  playing = false;\n","  document.querySelector('#chooser').click();\n","}\n","\n","function uploadFile(file) {\n","  if (file.type != 'image/png' && file.type != 'image/jpeg') {\n","    error('Only PNG or JPEG files accepted.');\n","    return;\n","  }\n","  console.log(file);\n","  const reader = new FileReader();\n","  reader.onload = (e) => {\n","    const imagebytes = e.target.result;\n","    call('load_image', imagebytes);\n","  }\n","  document.querySelector('#rgb').src = '';\n","  reader.readAsBinaryString(file);\n","}\n","\n","async function step() {\n","  if (pending) { return; }\n","  await call('step', 2*x - 1, 2*y - 1);\n","  // Cursor moves back towards center.\n","  if (cursor_count) {\n","    cursor_count--;\n","  } else {\n","    x = 0.5 + (x - 0.5) * .9;\n","    y = 0.5 + (y - 0.5) * .9;\n","    update_cursor();\n","  }\n","}\n","\n","async function play() {\n","  playing = true;\n","  await step();\n","}\n","\n","async function pause() {\n","  playing = false;\n","}\n","\n","function update_cursor() {\n","  let cursor = document.querySelector('#cursor');\n","  cursor.style.left = `${(100 * x).toFixed(2)}%`;\n","  cursor.style.top = `${(100 * y).toFixed(2)}%`;\n","}\n","\n","function cursor(e) {\n","  console.log(e);\n","  x = e.offsetX / e.target.clientWidth;\n","  y = e.offsetY / e.target.clientHeight;\n","  cursor_count = 1;\n","  update_cursor();\n","}\n","\n","document.querySelector('#restart').addEventListener('click', reset);\n","document.querySelector('#image1').addEventListener('click', () => selectImage(0));\n","document.querySelector('#image2').addEventListener('click', () => selectImage(1));\n","document.querySelector('#image3').addEventListener('click', () => selectImage(2));\n","document.querySelector('#upload').addEventListener('click', upload);\n","document.querySelector('#play').addEventListener('click', play);\n","document.querySelector('#pause').addEventListener('click', pause);\n","document.querySelector('#step').addEventListener('click', () => { playing = false; step(); });\n","document.querySelector('#view').addEventListener('click', cursor);\n","document.querySelector('#chooser').addEventListener('change', (e) => {\n","  if (e.target.files.length > 0) {\n","    uploadFile(e.target.files[0]);\n","  }\n","});\n","selectImage(0);\n","</script>\n","'''\n","\n","display(IPython.display.HTML(html))\n","\n","output.register_callback('load_initial', load_initial)\n","output.register_callback('load_image', load_image)\n","output.register_callback('reset', reset)\n","output.register_callback('step', step)\n"],"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","<style>\n","#view {\n","  width: 512px;\n","  height: 320px;\n","  background-color: #aaa;\n","  background-size: 100% 100%;\n","  border: 1px solid #000;\n","  margin: 20px;\n","  position: relative;\n","}\n","#rgb {\n","  height: 100%;\n","}\n","#cursor {\n","  position: absolute;\n","  height: 0; width: 0;\n","  left: 50%; top: 50%;\n","  opacity: .5;\n","}\n","#cursor::before, #cursor::after {\n","  content: '';\n","  position: absolute;\n","  background: #f04;\n","  pointer-events: none;\n","}\n","#cursor::before {\n","  left: -10px; top: -1px; width: 20px; height: 2px;\n","}\n","#cursor::after {\n","  left: -1px; top: -10px; width: 2px; height: 20px;\n","}\n",".buttons {\n","  margin: 20px;\n","}\n",".buttons div {\n","  display: inline-block;\n","  cursor: pointer;\n","  padding: 20px;\n","  background: #eee;\n","  border: 2px solid #aaa;\n","  border-radius: 3px;\n","  margin-right: 10px;\n","  font-weight: bold;\n","  text-transform: uppercase;\n","  letter-spacing: 1px;\n","  color: #444;\n","}\n",".buttons div:active {\n","  background: #444;\n","  color: #fff;\n","}\n","h3 {\n","  margin-left: 20px;\n","}\n","</style>\n","<h3>Infinite Nature interactive demo</h3>\n","<div id=view><img id=rgb><div id=cursor></div></div>\n","<div class=buttons>\n","Click <b>Play</b> to run or <b>Step</b> to advance frame by frame.\n","Click mouse over image to steer.<br><br>\n","<div id=restart>Restart</div><div id=play>Play</div><div id=pause>Pause</div><div id=step>Step</div>\n","<br><br>\n","Select starting image (be patient…):<br><br>\n","<div id=image1>Image 1</div><div id=image2>Image 2</div><div id=image3>Image 3</div><div id=upload>Upload…</div><br>\n","<input style=\"display:none\" type=file id=chooser accept=\".png,.jpg\">\n","</div>\n","<script>\n","let playing = true;\n","let pending = false;\n","let x = 0.5;\n","let y = 0.5;\n","let cursor_count = 0;\n","\n","async function call(name, ...parms) {\n","  pending = true;\n","  const result = await google.colab.kernel.invokeFunction(name, parms, {});\n","  pending = false;\n","  const url = `data:image/png;base64,${result.data['image/png']}`;\n","  document.querySelector('#rgb').src = url;\n","  if (!playing) { return; }\n","  step();\n","}\n","\n","async function reset() {\n","  playing = false;\n","  await call('reset');\n","}\n","\n","async function selectImage(i) {\n","  playing = false;\n","  await call('load_initial', i);\n","}\n","\n","function upload() {\n","  playing = false;\n","  document.querySelector('#chooser').click();\n","}\n","\n","function uploadFile(file) {\n","  if (file.type != 'image/png' && file.type != 'image/jpeg') {\n","    error('Only PNG or JPEG files accepted.');\n","    return;\n","  }\n","  console.log(file);\n","  const reader = new FileReader();\n","  reader.onload = (e) => {\n","    const imagebytes = e.target.result;\n","    call('load_image', imagebytes);\n","  }\n","  document.querySelector('#rgb').src = '';\n","  reader.readAsBinaryString(file);\n","}\n","\n","async function step() {\n","  if (pending) { return; }\n","  await call('step', 2*x - 1, 2*y - 1);\n","  // Cursor moves back towards center.\n","  if (cursor_count) {\n","    cursor_count--;\n","  } else {\n","    x = 0.5 + (x - 0.5) * .9;\n","    y = 0.5 + (y - 0.5) * .9;\n","    update_cursor();\n","  }\n","}\n","\n","async function play() {\n","  playing = true;\n","  await step();\n","}\n","\n","async function pause() {\n","  playing = false;\n","}\n","\n","function update_cursor() {\n","  let cursor = document.querySelector('#cursor');\n","  cursor.style.left = `${(100 * x).toFixed(2)}%`;\n","  cursor.style.top = `${(100 * y).toFixed(2)}%`;\n","}\n","\n","function cursor(e) {\n","  console.log(e);\n","  x = e.offsetX / e.target.clientWidth;\n","  y = e.offsetY / e.target.clientHeight;\n","  cursor_count = 1;\n","  update_cursor();\n","}\n","\n","document.querySelector('#restart').addEventListener('click', reset);\n","document.querySelector('#image1').addEventListener('click', () => selectImage(0));\n","document.querySelector('#image2').addEventListener('click', () => selectImage(1));\n","document.querySelector('#image3').addEventListener('click', () => selectImage(2));\n","document.querySelector('#upload').addEventListener('click', upload);\n","document.querySelector('#play').addEventListener('click', play);\n","document.querySelector('#pause').addEventListener('click', pause);\n","document.querySelector('#step').addEventListener('click', () => { playing = false; step(); });\n","document.querySelector('#view').addEventListener('click', cursor);\n","document.querySelector('#chooser').addEventListener('change', (e) => {\n","  if (e.target.files.length > 0) {\n","    uploadFile(e.target.files[0]);\n","  }\n","});\n","selectImage(0);\n","</script>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"q1wtfRdNcEnE"},"source":[""],"execution_count":null,"outputs":[]}]}