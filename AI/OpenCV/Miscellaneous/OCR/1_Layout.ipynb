{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"1_Layout.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyPkm0FxHvxGMdunzlgN4hvw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# LayoutParser\n","\n","LayoutParser, a Python library for Document Image Analysis. This library has a Model Zoo with a great collection of pre-trained deep learning models with an off-the-shelf implementation strategy. This library has a unified architecture to adapt any DIA model. Apart from the usage of pre-trained models, LayoutParser provides tools for customization and fine-tuning as per need. Further, data preparation tools- for tasks such as document image annotation and data preprocessing tools are readily available in this library. The library aims at quality models and pipelines distribution with reproducibility, reusability and extensibility through a continuously improving community platform.\n","\n","\n","References:\n","\n","Official Notebook\n","https://github.com/Layout-Parser/layout-parser/blob/master/examples/Deep%20Layout%20Parsing.ipynb\n","\n","\n","Github repo\n","https://github.com/Layout-Parser/layout-parser\n","\n","Research paper\n","https://arxiv.org/abs/2103.15348\n","https://arxiv.org/pdf/2103.15348.pdf\n","\n","\n","Dataset\n","https://arxiv.org/abs/2004.08686\n","\n"],"metadata":{"id":"-wqX0KMy-qPk"}},{"cell_type":"markdown","source":["You can read about it more in [this](https://analyticsindiamag.com/guide-to-layoutparser-a-document-image-analysis-python-library/) article."],"metadata":{"id":"ukTgEt0G_X8O"}},{"cell_type":"markdown","source":["# Layout Detection in a Document Image"],"metadata":{"id":"mSACiHy2_LFw"}},{"cell_type":"markdown","source":["install LayoutParser library from PyPi package. Install other dependencies."],"metadata":{"id":"QZIqGqWCAnSH"}},{"cell_type":"code","execution_count":null,"source":["!python -m pip install pip --upgrade --user -q --no-warn-script-location\n","!python -m pip install numpy pandas seaborn matplotlib scipy statsmodels sklearn nltk gensim tensorflow keras torch torchvision \\\n","    tqdm scikit-image pillow --user -q --no-warn-script-location"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["!python -m pip install -U layoutparser --user -q\n","!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git@v0.4#egg=detectron2' --user -q\n","!python -m pip install layoutparser[ocr] --user -q\n"],"outputs":[],"metadata":{"id":"jDyjgUdu-lbU"}},{"cell_type":"code","execution_count":null,"source":["import IPython\n","IPython.Application.instance().kernel.do_shutdown(True)\n"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["Import the libraries"],"metadata":{"id":"0HcBlUGp-pDN"}},{"cell_type":"code","execution_count":null,"source":["import layoutparser as lp\n","import matplotlib.pyplot as plt\n","import matplotlib\n","%matplotlib inline\n","import cv2"],"outputs":[],"metadata":{"id":"iRsYGv6cAetA"}},{"cell_type":"markdown","source":["Read an image from the source files to infer on it"],"metadata":{"id":"dfeBPsEeYwy3"}},{"cell_type":"code","execution_count":null,"source":["img = cv2.imread(\"https://raw.githubusercontent.com/Layout-Parser/layout-parser/master/examples/data/paper-image.jpg\")\n","# convert BGR image into RGB format\n","image = img[..., ::-1]\n","# display image\n","plt.figure(figsize=(12,16))\n","plt.imshow(image)\n","plt.xticks([])\n","plt.yticks([])\n","plt.show()"],"outputs":[],"metadata":{"id":"ZsxUTTNpBCQ5"}},{"cell_type":"markdown","source":["Load a pre-trained Detectron2 model configured for Layout Parsing"],"metadata":{"id":"N7FXayWaZFst"}},{"cell_type":"code","execution_count":null,"source":["model = lp.Detectron2LayoutModel('lp://PubLayNet/faster_rcnn_R_50_FPN_3x/config', \n","                                 extra_config=[\"MODEL.ROI_HEADS.SCORE_THRESH_TEST\", 0.8],\n","                                 label_map={0: \"Text\", 1: \"Title\", 2: \"List\", 3:\"Table\", 4:\"Figure\"})"],"outputs":[],"metadata":{"id":"-yKx8tlbCjzv"}},{"cell_type":"markdown","source":["Infer the layouts for the sample image using the pre-trained model"],"metadata":{"id":"vO8kYed_ZS8m"}},{"cell_type":"code","execution_count":null,"source":["layout = model.detect(image)"],"outputs":[],"metadata":{"id":"4yAiTjceCo-x"}},{"cell_type":"markdown","source":["Display the image with infered layouts on it"],"metadata":{"id":"ei0jGv9EZcfM"}},{"cell_type":"code","execution_count":null,"source":["lp.draw_box(image, layout, box_width=3)"],"outputs":[],"metadata":{"id":"26ME4lQ2CsDu"}}]}