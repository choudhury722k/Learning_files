{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **Kornia**"
   ],
   "metadata": {
    "id": "KfULWgHtq-UY"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Kornia is an open-source Python library inspired by OpenCV designed to handle generic Computer Vision tasks.Kornia bridges the gap between two simple yet powerful libraries namely, OpenCV and PyTorch. Though solely based on traditional CV solutions like torchvision, tf.image, PIL and skimage, it enables differentiable programming for CV applications by utilizing the crucial properties of PyTorch like GPU hardware acceleration, differentiability and distributed data-flows."
   ],
   "metadata": {
    "id": "9XotZ08yrB2b"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To know about it more, please refer [this](https://analyticsindiamag.com/guide-to-kornia-an-opencv-inspired-pytorch-framework/) article."
   ],
   "metadata": {
    "id": "F43OBZFtrGna"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Practical implementation**"
   ],
   "metadata": {
    "id": "hQCsGoNgr9Sp"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here, we demonstrate three use cases of Kornia â€“ blurring a custom image, changing its color space, and adjusting its colors"
   ],
   "metadata": {
    "id": "OeeMR7-ksByO"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have used [this](https://st.depositphotos.com/2977105/3691/i/950/depositphotos_36916547-stock-photo-tiger-portrait-horizontal.jpg) following image for demonstration:\n",
    "Kornia input image"
   ],
   "metadata": {
    "id": "YRj9Zg5isEsL"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!python -m pip install pip --upgrade --user -q --no-warn-script-location\n",
    "!python -m pip install numpy pandas seaborn matplotlib scipy statsmodels sklearn nltk gensim tensorflow keras torch torchvision \\\n",
    "    tqdm scikit-image kornia --user -q --no-warn-script-location\n",
    "\n",
    "\n",
    "import IPython\n",
    "IPython.Application.instance().kernel.do_shutdown(True)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# !wget https://st.depositphotos.com/2977105/3691/i/950/depositphotos_36916547-stock-photo-tiger-portrait-horizontal.jpg"
   ],
   "outputs": [],
   "metadata": {
    "id": "sv0lcXwdq5Ck"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step-wise explanation of the code is as follows:"
   ],
   "metadata": {
    "id": "ETslKBwSsQ69"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, install the library using pip command."
   ],
   "metadata": {
    "id": "haAhJwyUsSi7"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Blur image**"
   ],
   "metadata": {
    "id": "Lfa6Mz79u9Lc"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\n",
    "import kornia\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {
    "id": "bowiAF4_Q1dH"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# read the image with OpenCV\n",
    "input_image: np.ndarray = cv2.imread('depositphotos_36916547-stock-photo-tiger-portrait-horizontal.jpg')\n",
    " #Convert the image color space from BGR to RGB\n",
    "input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)"
   ],
   "outputs": [],
   "metadata": {
    "id": "lcc86eo0Twn5"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convert the image to a torch 4D tensor "
   ],
   "metadata": {
    "id": "JY8I8O9ataeM"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# convert to torch tensor\n",
    "tensor_image: torch.tensor = kornia.image_to_tensor(input_image, keepdim=False)"
   ],
   "outputs": [],
   "metadata": {
    "id": "MQE6fGDeWQNz"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create an operator that blurs the tensor image using Gaussian filter "
   ],
   "metadata": {
    "id": "rGtFTGKGtdtS"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# create the operator\n",
    "gaussian = kornia.filters.GaussianBlur2d((11, 11), (10.5, 10.5))"
   ],
   "outputs": [],
   "metadata": {
    "id": "6h_2EH6nWVM-"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Where, (11,11) is the size of the kernel and (1.05,10.5) is the standard deviation of the kernel"
   ],
   "metadata": {
    "id": "9IyuvLwMtgOR"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convert the tensor image to float type and apply the gaussian operator defined in previous step to blur the image"
   ],
   "metadata": {
    "id": "MSqrjYrttj50"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# blur the image\n",
    "blur_image: torch.tensor = gaussian(tensor_image.float())"
   ],
   "outputs": [],
   "metadata": {
    "id": "oZh7kgALWYcm"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convert the blurred tensor image back to a numpy array"
   ],
   "metadata": {
    "id": "ZCcajPw7tmol"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# convert back to numpy\n",
    "final_blur_image: np.ndarray = kornia.tensor_to_image(blur_image.byte())"
   ],
   "outputs": [],
   "metadata": {
    "id": "849Id2P5Wb9V"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot the input and output images"
   ],
   "metadata": {
    "id": "w0EPmh7XtpUA"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create the plot\n",
    "fig, axs = plt.subplots(1, 2, figsize=(16, 10))\n",
    "axs = axs.ravel()\n",
    "\n",
    "axs[0].axis('off')\n",
    "axs[0].set_title('Original image')\n",
    "axs[0].imshow(input_image)\n",
    "\n",
    "axs[1].axis('off')\n",
    "axs[1].set_title('Blurred image')\n",
    "axs[1].imshow(final_blur_image)"
   ],
   "outputs": [],
   "metadata": {
    "id": "GVpCpS_8We0Z"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Color space conversions**"
   ],
   "metadata": {
    "id": "7R7djMEwYxV-"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Read the input colored image and convert it to a numpy array"
   ],
   "metadata": {
    "id": "HtPD43Mbtu74"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "bgr_image: np.ndarray = cv2.imread('depositphotos_36916547-stock-photo-tiger-portrait-horizontal.jpg', cv2.IMREAD_COLOR)"
   ],
   "outputs": [],
   "metadata": {
    "id": "HYXd5qoUWiOC"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convert the image to a torch tensor"
   ],
   "metadata": {
    "id": "fs9W9Vrkt3Xj"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tensor_bgr: torch.Tensor = kornia.image_to_tensor(bgr_image, keepdim=False)"
   ],
   "outputs": [],
   "metadata": {
    "id": "6q0lHrCnZIMx"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define functions to flip the image horizontally and vertically and rotate it by 180 degrees."
   ],
   "metadata": {
    "id": "-cj-TctGt58M"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def horizontal_flip(input: torch.Tensor) -> torch.Tensor:\n",
    "    return torch.flip(input, [-1])\n",
    "\n",
    "\n",
    "def vertical_flip(input: torch.Tensor) -> torch.Tensor:\n",
    "    return torch.flip(input, [-2])\n",
    "\n",
    "\n",
    "def rotate_180(input: torch.Tensor) -> torch.Tensor:\n",
    "    return torch.flip(input, [-2, -1])\n",
    "#    Define a function to plot a batch of images\n",
    "\n",
    "def imshow(input: torch.Tensor):\n",
    "    output: torch.Tensor = torchvision.utils.make_grid(input, nrow=2, padding=5)\n",
    "    output_np: np.ndarray = kornia.tensor_to_image(output)\n",
    "    plt.imshow(output_np)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {
    "id": "8ircttk1ZLzJ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create batch of images"
   ],
   "metadata": {
    "id": "J_P1IEKN1Ugv"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "batch_bgr = torch.cat([tensor_bgr, horizontal_flip(tensor_bgr), vertical_flip(tensor_bgr), rotate_180(tensor_bgr)])\n",
    "imshow(batch_bgr)"
   ],
   "outputs": [],
   "metadata": {
    "id": "Y3QySx8eZmjN"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **BGR to RGB conversion**"
   ],
   "metadata": {
    "id": "ouFf4lRA1asC"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "BGR to RGB color space conversion"
   ],
   "metadata": {
    "id": "fQhClVcXuGPR"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "batch_rgb = kornia.bgr_to_rgb(batch_bgr)\n",
    "imshow(batch_rgb)"
   ],
   "outputs": [],
   "metadata": {
    "id": "HB-fSb9-ZpuY"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "RGB to grayscale conversion"
   ],
   "metadata": {
    "id": "MoYMZAit1hkF"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "batch_gray = kornia.rgb_to_grayscale(batch_rgb.float() / 255.)\n",
    "imshow(batch_gray)"
   ],
   "outputs": [],
   "metadata": {
    "id": "q8h6QipUZxuf"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "RGB to HSV conversion"
   ],
   "metadata": {
    "id": "_IgSZ7Tn1u2B"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "batch_hsv = kornia.rgb_to_hsv(batch_rgb.float() / 255.)\n",
    "imshow(batch_hsv[:, 2:3])"
   ],
   "outputs": [],
   "metadata": {
    "id": "t_CI1mrEZ1kM"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Color adjustment"
   ],
   "metadata": {
    "id": "inBbwNOBoTOz"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Read the input image in BGR format"
   ],
   "metadata": {
    "id": "G6rWZcBquMJ_"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "bgr_image: np.ndarray = cv2.imread('depositphotos_36916547-stock-photo-tiger-portrait-horizontal.jpg', cv2.IMREAD_COLOR)"
   ],
   "outputs": [],
   "metadata": {
    "id": "cmkneBI5omD6"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convert input image to torch tensor"
   ],
   "metadata": {
    "id": "PAOASHGiuSxO"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tensor_bgr: torch.Tensor = kornia.image_to_tensor(bgr_image)\n",
    "tensor_rgb: torch.Tensor = kornia.bgr_to_rgb(tensor_bgr)\n"
   ],
   "outputs": [],
   "metadata": {
    "id": "jpPfnOGFpeMP"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Expand the image "
   ],
   "metadata": {
    "id": "u9oG8Ea1uVmQ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tensor_rgb = tensor_rgb.expand(4, -1, -1, -1)  # 4xCxHxW\n",
    "tensor_rgb = tensor_rgb.float() / 255.\n",
    "\n",
    "#Define a function to create a batch of images\n",
    "def imshow(input: torch.Tensor):\n",
    "    output: torch.Tensor = torchvision.utils.make_grid(input, nrow=2, padding=5)\n",
    "    output_np: np.ndarray = kornia.tensor_to_image(output)\n",
    "    plt.imshow(output_np)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {
    "id": "jlsL5FrApiRi"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "imshow(tensor_rgb)"
   ],
   "outputs": [],
   "metadata": {
    "id": "KkYH4YbhpmW2"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Adjust brightness"
   ],
   "metadata": {
    "id": "P8GPTHkWFDsJ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tensor_brightness: torch.Tensor = kornia.adjust_brightness(tensor_rgb, 0.6)\n",
    "imshow(tensor_brightness)"
   ],
   "outputs": [],
   "metadata": {
    "id": "vLnvFvjdpplK"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tensor contrast"
   ],
   "metadata": {
    "id": "7bL1wMOzFO1-"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tensor_contrast: torch.Tensor = kornia.adjust_contrast(tensor_rgb, 0.2)\n",
    "imshow(tensor_contrast)"
   ],
   "outputs": [],
   "metadata": {
    "id": "w3iuzE8Xp3jp"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Adjust gamma"
   ],
   "metadata": {
    "id": "-w6j-f5sFYY9"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tensor_gamma: torch.Tensor = kornia.adjust_gamma(tensor_rgb, gamma=3., gain=1.5)\n",
    "imshow(tensor_gamma)"
   ],
   "outputs": [],
   "metadata": {
    "id": "3mM2pSkpp7V_"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Adjust saturation"
   ],
   "metadata": {
    "id": "56ZS4PSjFhKn"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tensor_saturated: torch.Tensor = kornia.adjust_saturation(tensor_rgb, 0.2)\n",
    "imshow(tensor_saturated)"
   ],
   "outputs": [],
   "metadata": {
    "id": "Qqz4TzMPp-94"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Adjust Hue"
   ],
   "metadata": {
    "id": "VJChOrcHuge1"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tensor_hue: torch.Tensor = kornia.adjust_hue(tensor_rgb, 0.5)\n",
    "imshow(tensor_hue)"
   ],
   "outputs": [],
   "metadata": {
    "id": "V6aSlNJYqCfP"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#**Related Articles:**\n",
    "\n",
    "> * [Guide to Kornia](https://analyticsindiamag.com/guide-to-kornia-an-opencv-inspired-pytorch-framework/)\n",
    "\n",
    "> * [Extract Foreground Images with GrabCut Algorithm](https://analyticsindiamag.com/how-to-extract-foreground-from-images-interactively-using-grabcut/)\n",
    "\n",
    "> * [GAN in simple 8 Steps](https://analyticsindiamag.com/how-to-build-a-generative-adversarial-network-in-8-simple-steps/)\n",
    "\n",
    "> * [PyTorch vs Keras vs Caffe](https://analyticsindiamag.com/keras-vs-pytorch-vs-caffe-comparing-the-implementation-of-cnn/)\n",
    "\n",
    "> * [Face Emotion Recognizer](https://analyticsindiamag.com/face-emotion-recognizer-in-6-lines-of-code/)\n",
    "\n",
    "> * [Sign Language Classification using CNN](https://analyticsindiamag.com/hands-on-guide-to-sign-language-classification-using-cnn/)\n",
    "\n",
    "> * [Transfer Learning for multi class classification](https://analyticsindiamag.com/transfer-learning-for-multi-class-image-classification-using-deep-convolutional-neural-network/)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "1ZtPNx78qe5T"
   }
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNgeOReY788Xtkp37lslplF",
   "collapsed_sections": [],
   "name": "1_Kornia.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "f60a20abaabf5a658075b37fac599269792a9493ddacd7c14d8505185d5625aa"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}