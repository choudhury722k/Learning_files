{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1_3D_dense_face_alignment.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNsogXCpSXAbvstjr1akplR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"7y-HM5-Uq8as"},"source":["# 3D Dense Face Alignment "]},{"cell_type":"markdown","metadata":{"id":"gDtIq0Sbqy1l"},"source":["3D dense face alignment(3DDFA) is a trending technique for many face tasks, For example, object recognition, animation, tracking, image restoration, and many more. For now, most of the studies in 3DDFA are divided into two categories:\n","\n","> * 3D Morphable Model(3DMM) parameter regression,\n","> * and Dense vertices regression.\n","\n","Now Existing method of 3D dense face alignment only focuses on accuracy, which tends to limit the scope of their practical applications. In previous implementations of 3DDFA, there was a major problem with accuracy and output inference but the new 3DdFA_V2(version 2nd) came up with a new regression framework that makes a reliable balance between accuracy, speed, and stability. 3DDFA_V2 is published by Jianzhu Guo, Xiangyu Zhu, Yang Yang, Fan Yang, Zhen Lei, and Stan Z. Li in the research paper called Towards Fast, Accurate and Stable"]},{"cell_type":"markdown","metadata":{"id":"CSWDYgTDrBG0"},"source":["To read about it more, please refer [this](https://analyticsindiamag.com/guide-towards-fast-accurate-and-stable-3d-dense-face-alignment3ddfa-v2-framework/) article."]},{"cell_type":"markdown","metadata":{"id":"Qk5AOOUQdyH-"},"source":["## A simple demostration of how to run"]},{"cell_type":"markdown","metadata":{"id":"QB_9Un5zrI8g"},"source":["Cloning and setup up the environment"]},{"cell_type":"code","metadata":{"id":"QVhLz5czcT5T"},"source":["# if not clone, clone it\n","%cd /content\n","!git clone https://github.com/cleardusk/3DDFA_V2.git\n","%cd 3DDFA_V2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vQ6OBy22crZM"},"source":["!sh ./build.sh"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GGi1za39rNOw"},"source":["Importing modules"]},{"cell_type":"code","metadata":{"id":"JKwrGXxXdJiw"},"source":["# before import, make sure FaceBoxes and Sim3DR are built successfully, e.g.,\n","\n","import cv2\n","import yaml\n","\n","from FaceBoxes import FaceBoxes\n","from TDDFA import TDDFA\n","from utils.render import render\n","from utils.depth import depth\n","from utils.pncc import pncc\n","from utils.uv import uv_tex\n","from utils.pose import viz_pose\n","from utils.serialization import ser_to_ply, ser_to_obj\n","from utils.functions import draw_landmarks, get_suffix\n","\n","import matplotlib.pyplot as plt\n","from skimage import io"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZEGbq0PKeMYV"},"source":["### Load configs"]},{"cell_type":"markdown","metadata":{"id":"GCGETEnCrPxD"},"source":["\n","It will enable the ONNX environment to speed up the process, default backbone of the architecture is MobileNet_V1 with input size 120Ã—120, and the default pretrained weight/mb1_120x120.pth, there is also another wider factor is available as this project provide two mobilenet models to choose from."]},{"cell_type":"code","metadata":{"id":"pEpptH1Kc1pq"},"source":["# load config\n","cfg = yaml.load(open('configs/mb1_120x120.yml'), Loader=yaml.SafeLoader)\n","\n","# Init FaceBoxes and TDDFA, recommend using onnx flag\n","onnx_flag = True  # or True to use ONNX to speed up\n","if onnx_flag:\n","    !pip install onnxruntime\n","    \n","    import os\n","    os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n","    os.environ['OMP_NUM_THREADS'] = '4'\n","    from FaceBoxes.FaceBoxes_ONNX import FaceBoxes_ONNX\n","    from TDDFA_ONNX import TDDFA_ONNX\n","\n","    face_boxes = FaceBoxes_ONNX()\n","    tddfa = TDDFA_ONNX(**cfg)\n","else:\n","    face_boxes = FaceBoxes()\n","    tddfa = TDDFA(gpu_mode=False, **cfg)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rF7GVPuvrTMk"},"source":["Testing\n","\n","Let;s first take any image you want "]},{"cell_type":"code","metadata":{"id":"u10oyDvxdTSE"},"source":["# given an image path or the image url\n","\n","# img_fp = 'examples/inputs/emma.jpg'\n","# img = cv2.imread(img_fp)\n","# plt.imshow(img[..., ::-1])\n","\n","img_url = 'https://c8.alamy.com/comp/KY3E6K/mosaic-of-different-portraits-of-the-same-cute-girl-mixed-emotions-KY3E6K.jpg'\n","img = io.imread(img_url)\n","plt.imshow(img)\n","\n","img = img[..., ::-1]  # RGB -> BGR"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nMH7-FbaeTLj"},"source":["### Detect faces using FaceBoxes"]},{"cell_type":"code","metadata":{"id":"h6heXlK6dVim"},"source":["# face detection\n","boxes = face_boxes(img)\n","print(f'Detect {len(boxes)} faces')\n","print(boxes)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9h6uZu6BeW50"},"source":["### Regressing 3DMM parameters, reconstruction and visualization"]},{"cell_type":"code","metadata":{"id":"1uk2NixGdYSq"},"source":["# regress 3DMM params\n","param_lst, roi_box_lst = tddfa(img, boxes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AQkzXnvZdazr"},"source":["# reconstruct vertices and visualizing sparse landmarks\n","dense_flag = False\n","ver_lst = tddfa.recon_vers(param_lst, roi_box_lst, dense_flag=dense_flag)\n","draw_landmarks(img, ver_lst, dense_flag=dense_flag)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c-J_WPIQddrv"},"source":["# reconstruct vertices and visualizing dense landmarks\n","dense_flag = True\n","ver_lst = tddfa.recon_vers(param_lst, roi_box_lst, dense_flag=dense_flag)\n","draw_landmarks(img, ver_lst, dense_flag=dense_flag)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s3mVNyQ0dgo9"},"source":["# reconstruct vertices and render\n","ver_lst = tddfa.recon_vers(param_lst, roi_box_lst, dense_flag=dense_flag)\n","render(img, ver_lst, tddfa.tri, alpha=0.6, show_flag=True);"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ImpM_8tpdit-"},"source":["# reconstruct vertices and render depth\n","ver_lst = tddfa.recon_vers(param_lst, roi_box_lst, dense_flag=dense_flag)\n","depth(img, ver_lst, tddfa.tri, show_flag=True);"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dyu1DeKi4mr3"},"source":["# reconstruct vertices and render pncc\n","ver_lst = tddfa.recon_vers(param_lst, roi_box_lst, dense_flag=dense_flag)\n","pncc(img, ver_lst, tddfa.tri, show_flag=True);"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zFDTMs1OYTkw"},"source":["# running offline\n","%%bash\n","for OPT in 2d_sparse 2d_dense 3d depth pncc pose uv_tex ply obj; do\n","  python demo.py -f examples/inputs/trump_hillary.jpg -o $OPT --show_flag=false --onnx;\n","done;"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gVWVkirSg_i7"},"source":["!python3 demo_video.py -f examples/inputs/videos/214.avi --onnx"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aj7NM9N2kLB3"},"source":[""],"execution_count":null,"outputs":[]}]}