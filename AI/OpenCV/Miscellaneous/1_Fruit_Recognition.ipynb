{"cells":[{"cell_type":"markdown","source":["# **Fruit Recognition using the Convolutional Neural Network**"],"metadata":{"id":"5KGPDgP2cL4T"}},{"cell_type":"markdown","source":["Object detection and recognition is a demanding work belonging to the field of computer vision. Objects in the images are detected and recognized using machine learning models when trained on a sufficient number of available images. When applying deep learning models in this task when we have a large number of training images, the accuracy of object recognition is improved. This concept motivates us in developing such a model which can recognize a fruit and predicts its name. There may be a variety of applications of fruit recognition in agricultural work when we are to recognize thousands of fruit images in a less amount of time. It can also be applied in automating the billing process at a fruit shop where the model can recognize the fruit and calculate its price by multiplying with weight."],"metadata":{"id":"s8yJIFGqcILU"}},{"cell_type":"markdown","source":["In this practice session, we will recognize the fruit where the Convolutional Neural Network will predict the name of the fruit given its image. We will train the network in a supervised manner where images of the fruits will be the input to the network and labels of the fruits will be the output of the network. After successful training, the CNN model will be able to correctly predict the label of the fruit."],"metadata":{"id":"foRnMXv4cqBZ"}},{"cell_type":"markdown","source":["## **The Data Set**"],"metadata":{"id":"XPXK6kBmcw1g"}},{"cell_type":"markdown","source":["The data set used in this article is taken from ‘Fruit Images for Object Detection’ dataset that is publicly available on [Kaggle](https://www.kaggle.com/mbkinaci/fruit-images-for-object-detection?select=train_zip). This is a small data set consisting of 240 training images and 60 test images. All the images belong to the three types of fruits – Apple, Banana and Orange. "],"metadata":{"id":"dODNQS0Cc1Gy"}},{"cell_type":"markdown","source":["## **Implementation**"],"metadata":{"id":"bZd8uiCViPET"}},{"cell_type":"markdown","source":["Importing some required libraries"],"metadata":{"id":"x536z_nTiTky"}},{"cell_type":"code","execution_count":null,"source":["!python -m pip install pip --upgrade --user -q --no-warn-script-location\n","!python -m pip install numpy pandas seaborn matplotlib scipy statsmodels sklearn nltk gensim tensorflow keras \\\n","    tqdm scikit-image pillow --user -q --no-warn-script-location\n","\n","\n","import IPython\n","IPython.Application.instance().kernel.do_shutdown(True)\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":2,"source":["#Importing Library\n","import numpy as np\n","import pandas as pd\n","import cv2\n","import os \n","from PIL import Image"],"outputs":[],"metadata":{"id":"fJxAIS9dhOK3"}},{"cell_type":"markdown","source":["Here, we will check the files in the directory"],"metadata":{"id":"ZRX8PxhhiZEf"}},{"cell_type":"code","execution_count":3,"source":["dir_path = \"https://gitlab.com/AnalyticsIndiaMagazine/practicedatasets/-/archive/main/practicedatasets-main.zip?path=fruit_recognition/train\""],"outputs":[],"metadata":{"id":"s-BKmedewn7v"}},{"cell_type":"code","execution_count":4,"source":["#Checking the directory\n","import os\n","for dirname, _, filenames in os.walk(dir_path):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))"],"outputs":[],"metadata":{"id":"1CbG-TdUZ8hi"}},{"cell_type":"markdown","source":["We can verify the contents of the directory in this way. Using the below code snippet, we will get all the images and their labels. These labels will be obtained from the names of the image files."],"metadata":{"id":"QYAMMxb4itoY"}},{"cell_type":"code","execution_count":6,"source":["images  =  []       \n","labels  =  [] \n","train_path  =  'https://gitlab.com/AnalyticsIndiaMagazine/practicedatasets/-/tree/main/fruit_recognition/train'\n","for filename in os.listdir('https://gitlab.com/AnalyticsIndiaMagazine/practicedatasets/-/tree/main/fruit_recognition/train'):\n","    if filename.split('.')[1]=='jpg':\n","        img  =  cv2.imread(os.path.join(train_path,filename))\n","        arr = Image.fromarray(img,'RGB')\n","        img_arr = arr.resize((50,50))\n","        labels.append(filename.split('_')[0])\n","        images.append(np.array(img_arr))"],"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'https://gitlab.com/AnalyticsIndiaMagazine/practicedatasets/-/tree/main/fruit_recognition/train'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-3b0781fde2db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlabels\u001b[0m  \u001b[0;34m=\u001b[0m  \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_path\u001b[0m  \u001b[0;34m=\u001b[0m  \u001b[0;34m'https://gitlab.com/AnalyticsIndiaMagazine/practicedatasets/-/tree/main/fruit_recognition/train'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://gitlab.com/AnalyticsIndiaMagazine/practicedatasets/-/tree/main/fruit_recognition/train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'jpg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mimg\u001b[0m  \u001b[0;34m=\u001b[0m  \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'https://gitlab.com/AnalyticsIndiaMagazine/practicedatasets/-/tree/main/fruit_recognition/train'"]}],"metadata":{"id":"m28p_Kacivtv"}},{"cell_type":"markdown","source":["After obtaining all the labels, we will print them."],"metadata":{"id":"lt_K-gAaixTg"}},{"cell_type":"code","execution_count":null,"source":["#Image Labels\n","np.unique(labels)"],"outputs":[],"metadata":{"id":"C_YKgekAizUS"}},{"cell_type":"markdown","source":["All the labels in the text form stored in the labels array will be encoded by label encoding to transform them as the output labels."],"metadata":{"id":"0oF2h5iBi1bT"}},{"cell_type":"code","execution_count":null,"source":["from sklearn.preprocessing import LabelEncoder\n","lb_encod  =  LabelEncoder()\n","labels = pd.DataFrame(labels)\n","labels = lb_encod.fit_transform(labels[0])\n","labels"],"outputs":[],"metadata":{"id":"oYwXTfvgi3oS"}},{"cell_type":"code","execution_count":null,"source":["#Visualizing image\n","import matplotlib.pyplot as plt\n","figure = plt.figure(figsize = (8,8))\n","ax = figure.add_subplot(121)\n","ax.imshow(images[0])\n","bx = figure.add_subplot(122)\n","bx.imshow(images[60])\n","plt.show()"],"outputs":[],"metadata":{"id":"aoFa5ZnZi5r4"}},{"cell_type":"code","execution_count":null,"source":["#In the next step, we will preprocess the image data\n","\n","#Saving the image array and corresponding labels\n","images = np.array(images)\n","np.save(\"image\",images)\n","np.save(\"labels\",labels)\n","\n","#Loading the images and labels that we have saved above\n","image = np.load(\"image.npy\",allow_pickle = True)\n","labels = np.load(\"labels.npy\",allow_pickle = True)\n","\n","img_shape  = np.arange(image.shape[0])\n","np.random.shuffle(img_shape)\n","image = image[img_shape]\n","labels = labels[img_shape]"],"outputs":[],"metadata":{"id":"b59x7Y5qi8sC"}},{"cell_type":"markdown","source":["Now, we will define the train and the test data set."],"metadata":{"id":"A4ElFeGUi-Nc"}},{"cell_type":"code","execution_count":null,"source":["num_classes = len(np.unique(labels))\n","len_data = len(image)"],"outputs":[],"metadata":{"id":"yccFLUHrjAis"}},{"cell_type":"code","execution_count":null,"source":["x_train, x_test = image[(int)(0.1*len_data):],image[:(int)(0.1*len_data)]\n","y_train,y_test = labels[(int)(0.1*len_data):],labels[:(int)(0.1*len_data)]\n","\n","import keras\n","from keras.utils import np_utils\n","y_train = np_utils.to_categorical(y_train,num_classes)\n","y_test = np_utils.to_categorical(y_test,num_classes)"],"outputs":[],"metadata":{"id":"-L7hGI_9jCdL"}},{"cell_type":"markdown","source":["## **Convolutional Neural Network**"],"metadata":{"id":"JXQgFbP0jENc"}},{"cell_type":"markdown","source":["After defining the training and test sets, we will define and train the convolutional neural network model. As a kernel regularization, we will use the L2 regularization method."],"metadata":{"id":"gD6PxrRejHnQ"}},{"cell_type":"code","execution_count":null,"source":["from keras.models import Sequential\n","from keras.layers import Dense,Conv2D,MaxPooling2D,Dropout,Flatten,MaxPool2D\n","from keras.optimizers import RMSprop,Adam\n","from keras.layers import Activation, Convolution2D, Dropout, Conv2D,AveragePooling2D, BatchNormalization,Flatten,GlobalAveragePooling2D\n","from keras import layers\n","from keras.regularizers import l2\n","from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau\n","\n","l2_reg = 0.001\n","opt = Adam(lr = 0.001)\n","\n","#Defining the CNN Model\n","cnn_model  =  Sequential()\n","cnn_model.add(Conv2D(filters = 32, kernel_size = (2,2), input_shape = (50,50, 3), activation = 'relu',kernel_regularizer = l2(l2_reg)))\n","cnn_model.add(MaxPool2D(pool_size = (2,2)))\n","cnn_model.add(Conv2D(filters = 64, kernel_size = (2,2), activation = 'relu',kernel_regularizer = l2(l2_reg)))\n","cnn_model.add(MaxPool2D(pool_size = (2,2)))\n","cnn_model.add(Conv2D(filters = 128, kernel_size = (2,2), activation = 'relu',kernel_regularizer = l2(l2_reg)))\n","cnn_model.add(MaxPool2D(pool_size = (2,2)))\n","cnn_model.add(Dropout(0.1))\n","\n","cnn_model.add(Flatten())\n","\n","cnn_model.add(Dense(64, activation = 'relu'))\n","cnn_model.add(Dense(16, activation = 'relu'))\n","cnn_model.add(Dense(4, activation = 'softmax'))\n","\n","#CNN Model Summary\n","cnn_model.summary()"],"outputs":[],"metadata":{"id":"QcwBMIFkjKwk"}},{"cell_type":"code","execution_count":null,"source":["#Compiling the model\n","cnn_model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])\n","\n","#Training the CNN Model"],"outputs":[],"metadata":{"id":"YlGViIxZjNVw"}},{"cell_type":"code","execution_count":null,"source":["file1 = 'weights.hdf5'\n","filepath = \"./\"\n","checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n","history = cnn_model.fit(x_train,y_train,batch_size = 128,epochs = 110,verbose = 1,validation_split = 0.33)"],"outputs":[],"metadata":{"id":"dk8bf5DzjPnG"}},{"cell_type":"code","execution_count":null,"source":["#Check the performance\n","scores  =  cnn_model.evaluate(x_test, y_test, verbose = 1)\n","print('Test loss:', scores[0])\n","print('Test accuracy:', scores[1])"],"outputs":[],"metadata":{"id":"9I_7mQGqjT08"}},{"cell_type":"code","execution_count":null,"source":["#Visualize the performance\n","figure = plt.figure(figsize = (10,5))\n","ax = figure.add_subplot(121)\n","ax.plot(history.history['accuracy'])\n","ax.plot(history.history['val_accuracy'])\n","ax.legend(['Training Accuracy','Val Accuracy'])\n","bx = figure.add_subplot(122)\n","bx.plot(history.history['loss'])\n","bx.plot(history.history['val_loss'])\n","bx.legend(['Training Loss','Val Loss'])"],"outputs":[],"metadata":{"id":"dSnTMUWcjVZO"}},{"cell_type":"markdown","source":["After the successful training, we will test the model in predicting the class labels for the fruit images."],"metadata":{"id":"EhmuUWQWjXdx"}},{"cell_type":"code","execution_count":null,"source":["#Test\n","test_path  =  'test_zip/test'\n","t_labels = []\n","t_images = []\n","for filename in os.listdir('test_zip/test'):\n","    if filename.split('.')[1]=='jpg':\n","        img  =  cv2.imread(os.path.join(test_path,filename))\n","        arr = Image.fromarray(img,'RGB')\n","        img_arr = arr.resize((50,50))\n","        t_labels.append(filename.split('_')[0])\n","        t_images.append(np.array(img_arr))\n","\n","test_images = np.array(test_images)\n","np.save(\"test_image\",test_images)\n","test_image = np.load(\"image.npy\",allow_pickle = True)\n","\n","pred = np.argmax(cnn_model.predict(test_image),axis = 1)\n","prediction  =  lb_encod.inverse_transform(pred)\n","\n","test_image = np.expand_dims(test_image[25],axis = 0)\n","pred_test = np.argmax(cnn_model.predict(test_image),axis = 1)\n","prediction_test  =  lb_encod.inverse_transform(pred_test)\n","\n","print(prediction_test[0])\n","plt.imshow(test_images[25])"],"outputs":[],"metadata":{"id":"DtirE28ujZxe"}},{"cell_type":"markdown","source":["#**Related Articles:**\n","\n","> * [Fruit Recognition with CNN](https://analyticsindiamag.com/fruit-recognition-using-the-convolutional-neural-network/)\n","\n","> * [Semantic Segmentation Using TensorFlow Keras](https://analyticsindiamag.com/semantic-segmentation-using-tensorflow-keras/)\n","\n","> * [Convert Image to Pencil Sketch](https://analyticsindiamag.com/converting-image-into-a-pencil-sketch-in-python/)\n","\n","> * [Image Classification Task with and without Data Augmentation](https://analyticsindiamag.com/image-data-augmentation-impacts-performance-of-image-classification-with-codes/)\n","\n","> * [Image Data Augmentation Work As A Regularizer](https://analyticsindiamag.com/why-does-image-data-augmentation-work-as-a-regularizer-in-deep-learning/)\n","\n","> * [Guide to Pillow](https://analyticsindiamag.com/hands-on-guide-to-pillow-python-library-for-image-processing/)\n"],"metadata":{"id":"1ZtPNx78qe5T"}}],"metadata":{"colab":{"collapsed_sections":[],"name":"1_Fruit_Recognition.ipynb","provenance":[],"toc_visible":true},"interpreter":{"hash":"f60a20abaabf5a658075b37fac599269792a9493ddacd7c14d8505185d5625aa"},"kernelspec":{"name":"python3","display_name":"Python 3.8.8 64-bit ('base': conda)"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":2}