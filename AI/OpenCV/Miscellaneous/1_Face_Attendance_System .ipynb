{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"1_Face_Attendance_System .ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOI4LVFErWfKOIZYyYS6t5g"},"kernelspec":{"name":"python3","display_name":"Python 3.8.8 64-bit ('base': conda)"},"language_info":{"name":"python","version":"3.8.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","interpreter":{"hash":"f60a20abaabf5a658075b37fac599269792a9493ddacd7c14d8505185d5625aa"}},"cells":[{"cell_type":"markdown","source":["# **Face Attendance System**"],"metadata":{"id":"I-Iix3nOkJiz"}},{"cell_type":"markdown","source":["Recognizing people by their faces in pictures and video feeds is seen everywhere starting from social media to phone cameras. A face recognition system is built for matching human faces with a digital image. Ultimately what a computer recognizes is pixel values ranging from 0-255. In Computer Vision face recognition has been in since ages and has evolved over the years. Many researchers have come up with many new techniques to efficiently identify and tell apart faces. There are many use cases such as authentication and verification of users."],"metadata":{"id":"4SMYD0bWkSiQ"}},{"cell_type":"markdown","source":["This practice session covers all the aspects of face recognition based attendance systems. It discusses the challenges faced in face recognition, the face recognition library and building the attendance marking system based on these techniques."],"metadata":{"id":"27SPOBGqkUcI"}},{"cell_type":"markdown","source":["# **Code Implementation**"],"metadata":{"id":"X5gBEOdYkayf"}},{"cell_type":"markdown","source":["## **Basic Face Matching** "],"metadata":{"id":"81PZKd77kee5"}},{"cell_type":"markdown","source":["First, we get the location of where exactly the face is in the image using face_location() method(which gets the outline of the face) on the RGB image. Then face encodings(markings of eyes, nose, mouth, jaws which remain the same for different images of the same person) are taken using face_encodings() function which returns a list containing 128 measurements. Both these two steps are followed for the original and test image. Then a comparison between these two returned lists is done by the function compare_faces() which returns a list of boolean values(True or False). The face distance function gets the value of that by how much the two images differ. The lower the distance the better the matching and vice versa."],"metadata":{"id":"LkjYbB_goQCD"}},{"cell_type":"code","execution_count":null,"source":["!python -m pip install pip --upgrade --user -q --no-warn-script-location\n","!python -m pip install numpy pandas seaborn matplotlib scipy statsmodels sklearn nltk gensim tensorflow keras torch torchvision \\\n","    tqdm scikit-image pillow face_recognition --user -q --no-warn-script-location\n","\n","\n","import IPython\n","IPython.Application.instance().kernel.do_shutdown(True)\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# !wget -O andrew_ng.jpg https://wp.technologyreview.com/wp-content/uploads/2017/08/andrew-ng-7.jpg"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oIxxrR6wodrB","executionInfo":{"status":"ok","timestamp":1623061513483,"user_tz":-330,"elapsed":695,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"91afab9d-ce7a-47ec-f5e7-13ba28bc381e"}},{"cell_type":"code","execution_count":null,"source":["# !wget -O ian_godfellow.jpg https://upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Ian_Goodfellow.jpg/330px-Ian_Goodfellow.jpg"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"39qwwz70opQF","executionInfo":{"status":"ok","timestamp":1623061514129,"user_tz":-330,"elapsed":655,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"c493468a-fd17-4c3a-add1-589599be513c"}},{"cell_type":"code","execution_count":null,"source":["import cv2\n","import face_recognition as fr\n","imgAng = fr.load_image_file('andrew_ng.jpg')\n","Test = fr.load_image_file('ian_godfellow.jpg')\n","fLoc = fr.face_locations(imgAng)[0]\n","encodeAng = fr.face_encodings(imgAng)[0]\n","fLocTest = fr.face_locations(Test)[0]\n","encTest = fr.face_encodings(Test)[0]\n","result = fr.compare_faces([encodeAng],encTest)\n","faceDist = fr.face_distance([encodeAng],encTest)\n","print(result,faceDist)"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Jqv9EBPoTQP","executionInfo":{"status":"ok","timestamp":1623061557896,"user_tz":-330,"elapsed":14656,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"031d787f-00b5-4907-fb39-ba712083cd23"}},{"cell_type":"markdown","source":["## **Building Face Attendance System**"],"metadata":{"id":"_yKzCmx1o0W_"}},{"cell_type":"markdown","source":["Now we are ready to build a realtime face attendance system wherein webcam captured frames will be matched against the existing database images and if the match is found then it’ll store it in a CSV file called ‘Attendance Register’ along with name and time of capture. Only once the file will store the matched image’s details, if the same image is received again then it’ll not update.\n","\n","Path setting to the directory containing the image database. Read each image and the images array. Append the filenames into a list called Names and remove the extensio"],"metadata":{"id":"Zw6YPB7do4TL"}},{"cell_type":"code","execution_count":null,"source":["# !mkdir ImagesAttendance"],"outputs":[],"metadata":{"id":"5F1PWemuwGU9","executionInfo":{"status":"ok","timestamp":1623061557898,"user_tz":-330,"elapsed":21,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"code","execution_count":null,"source":["# !wget -O ImagesAttendance/andrew.jpg https://i2.wp.com/syncedreview.com/wp-content/uploads/2018/11/6a7be29fafa971a5952b2e031f63c536463861a6.jpg"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1-xr2KdLwKEA","executionInfo":{"status":"ok","timestamp":1623061557899,"user_tz":-330,"elapsed":16,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"9f459534-e515-4743-e44c-41f9aa821e4b"}},{"cell_type":"code","execution_count":null,"source":["# !wget -O ImagesAttendance/ian.jpg https://i2.wp.com/syncedreview.com/wp-content/uploads/2018/11/6a7be29fafa971a5952b2e031f63c536463861a6.jpg"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AcnxXYGswbms","executionInfo":{"status":"ok","timestamp":1623061558578,"user_tz":-330,"elapsed":690,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"77511e0d-d4f2-43b3-eea7-0fbbd3f58e3f"}},{"cell_type":"code","execution_count":null,"source":["# !wget  -O ImagesAttendance/nicole.jpg https://pyxis.nymag.com/v1/imgs/8a4/e6b/b6237f56f0428eedf85e117ef0c669de58-nicole-kidman.rvertical.w330.jpg"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8dax6HSmw8gk","executionInfo":{"status":"ok","timestamp":1623061558579,"user_tz":-330,"elapsed":15,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"4ac57f14-44e8-401f-b734-ac84445bf19b"}},{"cell_type":"code","execution_count":null,"source":["import os\n","pathlib = 'ImagesAttendance'\n","images = []\n","Names = []\n","myList = os.listdir(pathlib)\n","print(myList)\n","for cl in myList:\n","    currImg = cv2.imread(f'{pathlib}/{cl}')\n","    images.append(currImg)\n","    Names.append(os.path.splitext(cl)[0])\n","print(Names)"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uckdXM_dkIYO","executionInfo":{"status":"ok","timestamp":1623061558580,"user_tz":-330,"elapsed":11,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"0e28de08-5315-45a3-b61a-0842c45d602d"}},{"cell_type":"markdown","source":["Finding face encodings of images in the database and keeping them in a list to use later with incoming frames. "],"metadata":{"id":"jU1rP_PTxM54"}},{"cell_type":"code","execution_count":null,"source":["def DbEncodings(images):\n","    encList = []\n","    for image in images:\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        enc = fr.face_encodings(image)[0]\n","        encList.append(enc)\n","    return encList"],"outputs":[],"metadata":{"id":"vlyCdElPxPgG","executionInfo":{"status":"ok","timestamp":1623061696499,"user_tz":-330,"elapsed":398,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"markdown","source":["The same process is followed by the first detection face location then getting the face encoding values."],"metadata":{"id":"Y0xmUsv1Aot-"}},{"cell_type":"code","execution_count":null,"source":["encodeKnown = DbEncodings(images)\n","print('Encoding Complete')\n"," \n","cap = cv2.VideoCapture(0)\n","\n","#Iterating through frames \n","while True:\n","    _, img = cap.read()\n","    image = cv2.resize(img,(0,0),None,0.25,0.25)\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    facesInFrame = face_recognition.face_locations(image)\n","    encodesInFrame = face_recognition.face_encodings(image,facesInFrame)\n","    #Now the incoming images are tested against the previously-stored encodings. \n","    #Then the face distance is also computed. \n","    #Lastly, we call the Attendance function along with the person name who is identifie\n","\n","    for encFace,faceLoc in zip(encodesInFrame,facesInFrame):\n","        matchList = face_recognition.compare_faces(encodeKnown,encFace)\n","        faceDis = face_recognition.face_distance(encodeKnown,encFace)\n","        #print(faceDis)\n","        match = np.argmin(faceDis)\n","\n","        if matchList[match]:\n","            name = Names[match].upper()\n","            #print(name)\n","            y,w,z,x = faceLoc\n","            y, w, z, x1 = y*4,w*4,z*4,x*4\n","            cv2.rectangle(img,(x,y),(w,z),(0,255,0),2)\n","            cv2.rectangle(img,(x,z-35),(w,z),(0,255,0),cv2.FILLED)\n","            cv2.putText(img,name,(x+6,z-6),cv2.FONT_HERSHEY_COMPLEX,1,(255,255,255),2)\n","            Attendance(name)\n","\n","    cv2.imshow('Webcam',img)\n","    k = cv2.waitKey(0)\n","    if k == 27:         # wait for ESC key to exit\n","        break\n","        cv2.destroyAllWindows()"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":284},"id":"GyREd7_nAckZ","executionInfo":{"status":"error","timestamp":1623061698493,"user_tz":-330,"elapsed":1337,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"2eb415c0-3c1d-420f-ffe5-573ce75c9b84"}},{"cell_type":"markdown","source":["Reading from attendance file, Storing data(Name and Time of entry) if previously not stored."],"metadata":{"id":"bZD_rSxmAYkz"}},{"cell_type":"code","execution_count":null,"source":["def Attendance(name):\n","    with open('Attendance_Register.csv','r+') as f:\n","        DataList = f.readlines()\n","        names = []\n","        for data in DataList:\n","            ent = data.split(',')\n","            names.append(ent[0])\n","        if name not in names:\n","            curr = datetime.now()\n","            dt = curr.strftime('%H:%M:%S')\n","            f.writelines(f'\\n{name},{dt}')"],"outputs":[],"metadata":{"id":"E5UpaPqlxa-G"}},{"cell_type":"markdown","source":["Capturing video frames"],"metadata":{"id":"F8Rj-xgCxRgW"}},{"cell_type":"markdown","source":[],"metadata":{"id":"EOf4amCTxOou"}},{"cell_type":"markdown","source":["#**Related Articles:**\n","\n","> * [Face Attendance System](https://analyticsindiamag.com/a-complete-guide-on-building-a-face-attendance-system/)\n","\n","> * [6 MNIST Image Dataset](https://analyticsindiamag.com/mnist/)\n","\n","> * [Vision Transformers](https://analyticsindiamag.com/hands-on-vision-transformers-with-pytorch/)\n","\n","> * [MONAI](https://analyticsindiamag.com/monai-datatsets-managers/)\n","\n","> * [Guide to Pystiche](https://analyticsindiamag.com/pystiche/)\n","\n","> * [MODNet](https://analyticsindiamag.com/modnet-a-trimap-free-realtime-portrait-matting/)\n","\n","> * [Monk's AI](https://analyticsindiamag.com/build-computer-vision-applications-with-few-lines-of-code-using-monk-ai/)"],"metadata":{"id":"1ZtPNx78qe5T"}}]}