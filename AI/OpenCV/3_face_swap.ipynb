{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Single image face swap using dlib and OpenCV\n",
    "### Writen by:\n",
    "- Eli Ghosn\n",
    "- Guilherme Leite\n",
    "- Rafael Rosenzvaig\n",
    "### Professor Luciano Silva\n",
    "### Insper - Computer Vision - 2020.2"
   ],
   "metadata": {
    "id": "_UNP3IsErC2P"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This document will present an implementation for face swapping, between two different images, using two well-known computer vision python libraries: __dlib__ and __OpenCV__.\n",
    "\n",
    "#### Implementation summary:\n",
    "1. Load 2 images that contain a human face on it\n",
    "2. Load pre-trained feature detection model\n",
    "3. Apply model on images to retrieve features coordinates\n",
    "4. Define facial area of interest using previously retrieved coordinates\n",
    "5. Split facial area of interest into tringles\n",
    "6. Cut facial region from both images and apply mask to remove the body from one image and the face from the other\n",
    "7. Warp masked face image to allign with masked body image\n",
    "8. Smooth edges to blend face into new body\n",
    "9. Retrieve final image"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To start our program, we need to import the libraries and images that are going to be used throughout our code."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!python -m pip install pip --upgrade --user -q --no-warn-script-location\n",
    "!python -m pip install numpy pandas seaborn matplotlib scipy statsmodels sklearn nltk gensim scikit-image opencv-python pillow dlib --user -q --no-warn-script-location\n",
    "\n",
    "import IPython\n",
    "IPython.Application.instance().kernel.do_shutdown(True)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Loading base images and coverting them to grayscale\n",
    "face = cv2.imread(\"obama.jpg\")\n",
    "body = cv2.imread(\"trump.jpeg\")"
   ],
   "outputs": [],
   "metadata": {
    "id": "u7Ys_RYvgUZa"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After importing, we convert the images to grayscale. This is done to enable feature identification that requires only 1 layer of color, instead of the usual 3 layered RGB format."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "face_gray = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "body_gray = cv2.cvtColor(body, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Create empty matrices in the images' shapes\n",
    "height, width = face_gray.shape\n",
    "mask = np.zeros((height, width), np.uint8)\n",
    "\n",
    "height, width, channels = body.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To correctly swap the faces between the two pictures, we need a program that can identify the facial features on each picture. Luckly, there is a library called [dlib](http://dlib.net/) that can identify especific geometrical shapes in images. Those shapes can then be used to predict how the face is positioned in a given image. And for that to work properly, a predictor needs to be trained to find only the features (or **landmarks** as they are called in dlib) that are useful for detecting human faces, such as eyes, mouth, nose, etc. \n",
    "\n",
    "Below, you will find a link to a tutorial on how to find especific features on a person's face, using dlib's shape predictor.\n",
    "\n",
    "You can download the pre-trained model [here](https://sourceforge.net/projects/dclib/files/dlib/v18.10/shape_predictor_68_face_landmarks.dat.bz2/download) then just extract it to the same folder as this notebook.\n",
    "\n",
    "This will be the model we will be using to find the specific features on our input images.\n",
    "\n",
    "[Full tutorial link](https://www.pyimagesearch.com/2019/12/16/training-a-custom-dlib-shape-predictor/)"
   ],
   "metadata": {
    "id": "92TR7xpiqDW4"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Loading models and predictors of the dlib library to detect landmarks in both faces\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"https://gitlab.com/AnalyticsIndiaMagazine/practicedatasets/-/raw/main/face_swapping/shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# Getting landmarks for the face that will be swapped into to the body\n",
    "rect = detector(face_gray)[0]\n",
    "\n",
    "# This creates a with 68 pairs of integer values — these values are the (x, y)-coordinates of the facial structures \n",
    "landmarks = predictor(face_gray, rect)\n",
    "landmarks_points = [] \n",
    "\n",
    "def get_landmarks(landmarks, landmarks_points):\n",
    "  for n in range(68):\n",
    "      x = landmarks.part(n).x\n",
    "      y = landmarks.part(n).y\n",
    "      landmarks_points.append((x, y))\n",
    "\n",
    "get_landmarks(landmarks, landmarks_points)\n",
    "\n",
    "points = np.array(landmarks_points, np.int32)"
   ],
   "outputs": [],
   "metadata": {
    "id": "AOxrJm5kg2nz"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The Convex Hull of a shape or a group of points is a tight fitting convex boundary around the points or the shape, we are using this to generate a mask around the landmark point over the subject's face.\n",
    "\n",
    "https://www.learnopencv.com/convex-hull-using-opencv-in-python-and-c/"
   ],
   "metadata": {
    "id": "1gg9UtaLJoEc"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "convexhull = cv2.convexHull(points) \n",
    "\n",
    "face_cp = face.copy()\n",
    "plt.imshow(cv2.cvtColor((cv2.polylines(face_cp, [convexhull], True, (255,255,255), 3)), cv2.COLOR_BGR2RGB))\n",
    "\n",
    "face_image_1 = cv2.bitwise_and(face, face, mask=mask)"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "PMlOUbrHJoal",
    "outputId": "fba5bba3-c838-4e9c-9ab6-81663afbbf4d"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can divide the faces into triangles using the landmarks. The triangles will be used to fit the facial features of the first person in the second one's face, this is important because each person's face is shaped diferently and the photos can be taken from different perspectives.\n",
    "https://www.learnopencv.com/delaunay-triangulation-and-voronoi-diagram-using-opencv-c-python/"
   ],
   "metadata": {
    "id": "QYkvSF0FLGNX"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rect = cv2.boundingRect(convexhull)\n",
    "\n",
    "subdiv = cv2.Subdiv2D(rect) # Creates an instance of Subdiv2D\n",
    "subdiv.insert(landmarks_points) # Insert points into subdiv\n",
    "triangles = subdiv.getTriangleList()\n",
    "triangles = np.array(triangles, dtype=np.int32)\n",
    "\n",
    "indexes_triangles = []\n",
    "face_cp = face.copy()\n",
    "\n",
    "def get_index(arr):\n",
    "    index = 0\n",
    "    if arr[0]:\n",
    "        index = arr[0][0]\n",
    "    return index\n",
    "\n",
    "for triangle in triangles :\n",
    "\n",
    "    # Gets the vertex of the triangle\n",
    "    pt1 = (triangle[0], triangle[1])\n",
    "    pt2 = (triangle[2], triangle[3])\n",
    "    pt3 = (triangle[4], triangle[5])\n",
    "    \n",
    "    # Draws a line for each side of the triangle\n",
    "    cv2.line(face_cp, pt1, pt2, (255, 255, 255), 3,  0)\n",
    "    cv2.line(face_cp, pt2, pt3, (255, 255, 255), 3,  0)\n",
    "    cv2.line(face_cp, pt3, pt1, (255, 255, 255), 3,  0)\n",
    "\n",
    "    index_pt1 = np.where((points == pt1).all(axis=1))\n",
    "    index_pt1 = get_index(index_pt1)\n",
    "    index_pt2 = np.where((points == pt2).all(axis=1))\n",
    "    index_pt2 = get_index(index_pt2)\n",
    "    index_pt3 = np.where((points == pt3).all(axis=1))\n",
    "    index_pt3 = get_index(index_pt3)\n",
    "\n",
    "    # Saves coordinates if the triangle exists and has 3 vertices\n",
    "    if index_pt1 is not None and index_pt2 is not None and index_pt3 is not None:\n",
    "        vertices = [index_pt1, index_pt2, index_pt3]\n",
    "        indexes_triangles.append(vertices)\n",
    "\n",
    "# Draw delaunay triangles\n",
    "plt.imshow(cv2.cvtColor(face_cp, cv2.COLOR_BGR2RGB))   "
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "0r5BChx3E9qQ",
    "outputId": "4f37a99f-594f-42cd-a85e-21e534ed7e08"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can now get the landmarks and generate the convex hull for the second person."
   ],
   "metadata": {
    "id": "-vO3pZqyLEyB"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Getting landmarks for the face that will have the first one swapped into\n",
    "rect2 = detector(body_gray)[0]\n",
    "\n",
    "# This creates a with 68 pairs of integer values — these values are the (x, y)-coordinates of the facial structures \n",
    "landmarks_2 = predictor(body_gray, rect2)\n",
    "landmarks_points2 = []\n",
    "\n",
    "# Uses the function declared previously to get a list of the landmark coordinates\n",
    "get_landmarks(landmarks_2, landmarks_points2)\n",
    "\n",
    "# Generates a convex hull for the second person\n",
    "points2 = np.array(landmarks_points2, np.int32)\n",
    "convexhull2 = cv2.convexHull(points2)\n",
    "\n",
    "body_cp = body.copy()\n",
    "plt.imshow(cv2.cvtColor((cv2.polylines(body_cp, [convexhull2], True, (255,255,255), 3)), cv2.COLOR_BGR2RGB))"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "kZJY92dfFB6P",
    "outputId": "85e756de-af4b-4afd-af81-0140816f73a9"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To fit the first person's face into the second one's body, we  will distort the triangles generated to so that they have the same dimentions of the ones created with the landmarks of the second person, this will warp the face of the first person to fit the facial features of the second one."
   ],
   "metadata": {
    "id": "ztRqEmLcjpDM"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lines_space_new_face = np.zeros((height, width, channels), np.uint8)\n",
    "body_new_face = np.zeros((height, width, channels), np.uint8)\n",
    "\n",
    "height, width = face_gray.shape\n",
    "lines_space_mask = np.zeros((height, width), np.uint8)\n",
    "\n",
    "\n",
    "for triangle in indexes_triangles:\n",
    "\n",
    "    # Coordinates of the first person's delaunay triangles\n",
    "    pt1 = landmarks_points[triangle[0]]\n",
    "    pt2 = landmarks_points[triangle[1]]\n",
    "    pt3 = landmarks_points[triangle[2]]\n",
    "\n",
    "    # Gets the delaunay triangles\n",
    "    (x, y, widht, height) = cv2.boundingRect(np.array([pt1, pt2, pt3], np.int32))\n",
    "    cropped_triangle = face[y: y+height, x: x+widht]\n",
    "    cropped_mask = np.zeros((height, widht), np.uint8)\n",
    "\n",
    "    # Fills triangle to generate the mask\n",
    "    points = np.array([[pt1[0]-x, pt1[1]-y], [pt2[0]-x, pt2[1]-y], [pt3[0]-x, pt3[1]-y]], np.int32)\n",
    "    cv2.fillConvexPoly(cropped_mask, points, 255)\n",
    "\n",
    "    # Draws lines for the triangles\n",
    "    cv2.line(lines_space_mask, pt1, pt2, 255)\n",
    "    cv2.line(lines_space_mask, pt2, pt3, 255)\n",
    "    cv2.line(lines_space_mask, pt1, pt3, 255)\n",
    "\n",
    "    lines_space = cv2.bitwise_and(face, face, mask=lines_space_mask)\n",
    "\n",
    "    # Calculates the delaunay triangles of the second person's face\n",
    "\n",
    "    # Coordinates of the first person's delaunay triangles\n",
    "    pt1 = landmarks_points2[triangle[0]]\n",
    "    pt2 = landmarks_points2[triangle[1]]\n",
    "    pt3 = landmarks_points2[triangle[2]]\n",
    "\n",
    "    # Gets the delaunay triangles\n",
    "    (x, y, widht, height) = cv2.boundingRect(np.array([pt1, pt2, pt3], np.int32))\n",
    "    cropped_mask2 = np.zeros((height,widht), np.uint8)\n",
    "\n",
    "    # Fills triangle to generate the mask\n",
    "    points2 = np.array([[pt1[0]-x, pt1[1]-y], [pt2[0]-x, pt2[1]-y], [pt3[0]-x, pt3[1]-y]], np.int32)\n",
    "    cv2.fillConvexPoly(cropped_mask2, points2, 255)\n",
    "\n",
    "    # Deforms the triangles to fit the subject's face : https://docs.opencv.org/3.4/d4/d61/tutorial_warp_affine.html\n",
    "    points =  np.float32(points)\n",
    "    points2 = np.float32(points2)\n",
    "    M = cv2.getAffineTransform(points, points2)  # Warps the content of the first triangle to fit in the second one\n",
    "    dist_triangle = cv2.warpAffine(cropped_triangle, M, (widht, height))\n",
    "    dist_triangle = cv2.bitwise_and(dist_triangle, dist_triangle, mask=cropped_mask2)\n",
    "\n",
    "    # Joins all the distorted triangles to make the face mask to fit in the second person's features\n",
    "    body_new_face_rect_area = body_new_face[y: y+height, x: x+widht]\n",
    "    body_new_face_rect_area_gray = cv2.cvtColor(body_new_face_rect_area, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Creates a mask\n",
    "    masked_triangle = cv2.threshold(body_new_face_rect_area_gray, 1, 255, cv2.THRESH_BINARY_INV)\n",
    "    dist_triangle = cv2.bitwise_and(dist_triangle, dist_triangle, mask=masked_triangle[1])\n",
    "\n",
    "    # Adds the piece to the face mask\n",
    "    body_new_face_rect_area = cv2.add(body_new_face_rect_area, dist_triangle)\n",
    "    body_new_face[y: y+height, x: x+widht] = body_new_face_rect_area\n",
    "  \n",
    "plt.imshow(cv2.cvtColor(body_new_face, cv2.COLOR_BGR2RGB))"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "RwDmYJgXFKVZ",
    "outputId": "8cad70a7-9f34-4f58-bb95-a66027e671b1"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, we can swap the face masks:"
   ],
   "metadata": {
    "id": "-zgQFjlXrF7j"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "body_face_mask = np.zeros_like(body_gray)\n",
    "body_head_mask = cv2.fillConvexPoly(body_face_mask, convexhull2, 255)\n",
    "body_face_mask = cv2.bitwise_not(body_head_mask)\n",
    "\n",
    "body_maskless = cv2.bitwise_and(body, body, mask=body_face_mask)\n",
    "result = cv2.add(body_maskless, body_new_face)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "d9xEOryhrHZO",
    "outputId": "a0ba84cc-1ca8-4cb2-b9a5-2e637c3d0cfd"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the image above we can see that the proportions of the mask of the first person are the same as the second one, however the swap doesn't look very good because the colours of the edge of the mask are very different from the rest of the subject's face. To smooth the edges and make the mask and the face more alike, we can use the SeamlessClone function from OpenCV \n",
    "https://www.learnopencv.com/seamless-cloning-using-opencv-python-cpp/\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "0eDiRLVonEsp"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Gets the center of the face for the body\n",
    "(x, y, widht, height) = cv2.boundingRect(convexhull2)\n",
    "center_face2 = (int((x+x+widht)/2), int((y+y+height)/2))\n",
    "\n",
    "seamlessclone = cv2.seamlessClone(result, body, body_head_mask, center_face2, cv2.NORMAL_CLONE)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(seamlessclone, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "cv2.imwrite(\"./result.png\", seamlessclone)"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "Y5B-hymvg6Ux",
    "outputId": "2b888869-e2e9-45b0-c606-c3c5d6e8b86f"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Final thoughts and conclusion\n",
    "\n",
    "The final result is reasonably good since the seamlessClone function helps the mask to blend into the face very nicely, the results are not as good when we use images of people with glasses or beards because the facial features can be harder to find due to them being covered. This also makes the cloning process look less real since it won't be just the color of the skin that has to be changed, leading to mixed results in those cases.\n",
    "Further improvements of this application could be:\n",
    "- Enable video real-time face swap\n",
    "- Allow glasses and beards\n",
    "- Enable 3D character face swap\n"
   ],
   "metadata": {
    "id": "X1EQmiHmqAIG"
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}