{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"1_Convolutional_Autoencoder.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOg4Jl1xorJdK8V9olFXmZw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Convolutional Autoencoder**"],"metadata":{"id":"yfe2A_qoiyW7"}},{"cell_type":"markdown","source":["Convolutional Autoencoder is a variant of Convolutional Neural Networks that are used as the tools for unsupervised learning of convolution filters. They are generally applied in the task of image reconstruction to minimize reconstruction errors by learning the optimal filters. Once they are trained in this task, they can be applied to any input in order to extract features. Convolutional Autoencoders are general-purpose feature extractors differently from general autoencoders that completely ignore the 2D image structure. In autoencoders, the image must be unrolled into a single vector and the network must be built following the constraint on the number of inputs."],"metadata":{"id":"Lth0W06qi4sH"}},{"cell_type":"markdown","source":["To read about it more, please refer [this](https://analyticsindiamag.com/how-to-implement-convolutional-autoencoder-in-pytorch-with-cuda/) article."],"metadata":{"id":"_c6ygmywi9nU"}},{"cell_type":"markdown","source":["# **Implementing in PyTorch**"],"metadata":{"id":"D_FGpnBhjFeS"}},{"cell_type":"markdown","source":["First of all, we will import the required libraries."],"metadata":{"id":"nNsZDsdgjI41"}},{"cell_type":"code","execution_count":null,"source":["!python -m pip install pip --upgrade --user -q --no-warn-script-location\n","!python -m pip install numpy pandas seaborn matplotlib scipy statsmodels sklearn tensorflow keras opencv-python pillow scikit-image torch torchvision --user -q --no-warn-script-location\n","\n","import IPython\n","IPython.Application.instance().kernel.do_shutdown(True)\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","from torch.utils.data.sampler import SubsetRandomSampler\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import torch.nn as nn\n","import torch.nn.functional as F"],"outputs":[],"metadata":{"id":"jyWZQhLOiv6O"}},{"cell_type":"markdown","source":["After importing the libraries, we will download the CIFAR-10 dataset."],"metadata":{"id":"w64-kowVjRkD"}},{"cell_type":"code","execution_count":null,"source":["#Converting data to torch.FloatTensor\n","transform = transforms.ToTensor()\n","\n","# Download the training and test datasets\n","train_data = datasets.CIFAR10(root='data', train=True, download=True, transform=transform)\n","\n","test_data = datasets.CIFAR10(root='data', train=False, download=True, transform=transform)"],"outputs":[],"metadata":{"id":"82Kcr_uCjT1z"}},{"cell_type":"markdown","source":["Now, we will prepare the data loaders that will be used for training and testing."],"metadata":{"id":"YKAuXb3gjTLj"}},{"cell_type":"code","execution_count":null,"source":["#Prepare data loaders\n","train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, num_workers=0)\n","test_loader = torch.utils.data.DataLoader(test_data, batch_size=32, num_workers=0)"],"outputs":[],"metadata":{"id":"obIgmkhCjXbQ"}},{"cell_type":"markdown","source":["We will print some random images from the training data set."],"metadata":{"id":"mxkR-idQjZI-"}},{"cell_type":"code","execution_count":null,"source":["#Utility functions to un-normalize and display an image\n","def imshow(img):\n","    img = img / 2 + 0.5  \n","    plt.imshow(np.transpose(img, (1, 2, 0))) \n","\n"," \n","#Define the image classes\n","classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n","\n","#Obtain one batch of training images\n","dataiter = iter(train_loader)\n","images, labels = dataiter.next()\n","images = images.numpy() # convert images to numpy for display\n","\n","#Plot the images\n","fig = plt.figure(figsize=(8, 8))\n","# display 20 images\n","for idx in np.arange(9):\n","    ax = fig.add_subplot(3, 3, idx+1, xticks=[], yticks=[])\n","    imshow(images[idx])\n","    ax.set_title(classes[labels[idx]])"],"outputs":[],"metadata":{"id":"19QaB4eOjbTS"}},{"cell_type":"markdown","source":["In the next step, we will define the Convolutional Autoencoder as a class that will be used to define the final Convolutional Autoencoder model."],"metadata":{"id":"yfxrowsmjeWa"}},{"cell_type":"code","execution_count":null,"source":["#Define the Convolutional Autoencoder\n","class ConvAutoencoder(nn.Module):\n","    def __init__(self):\n","        super(ConvAutoencoder, self).__init__()\n","       \n","        #Encoder\n","        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)  \n","        self.conv2 = nn.Conv2d(16, 4, 3, padding=1)\n","        self.pool = nn.MaxPool2d(2, 2)\n","       \n","        #Decoder\n","        self.t_conv1 = nn.ConvTranspose2d(4, 16, 2, stride=2)\n","        self.t_conv2 = nn.ConvTranspose2d(16, 3, 2, stride=2)\n","\n","\n","    def forward(self, x):\n","        x = F.relu(self.conv1(x))\n","        x = self.pool(x)\n","        x = F.relu(self.conv2(x))\n","        x = self.pool(x)\n","        x = F.relu(self.t_conv1(x))\n","        x = F.sigmoid(self.t_conv2(x))\n","              \n","        return x\n","\n","\n","#Instantiate the model\n","model = ConvAutoencoder()\n","print(model)\n"],"outputs":[],"metadata":{"id":"AxQ1Nmz_jgaH"}},{"cell_type":"markdown","source":["After that, we will define the loss criterion and optimizer."],"metadata":{"id":"BErM5d5Sjh52"}},{"cell_type":"code","execution_count":null,"source":["#Loss function\n","criterion = nn.BCELoss()\n","\n","#Optimizer\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"],"outputs":[],"metadata":{"id":"VGyVbOzMjjZ-"}},{"cell_type":"markdown","source":["Now, we will pass our model to the CUDA environment, if available else CPU."],"metadata":{"id":"jCNJp-okjlM5"}},{"cell_type":"code","execution_count":null,"source":["def get_device():\n","    if torch.cuda.is_available():\n","        device = 'cuda:0'\n","    else:\n","        device = 'cpu'\n","    return device\n","\n","device = get_device()\n","print(device)\n","model.to(device)"],"outputs":[],"metadata":{"id":"oY8kiSUVjquq"}},{"cell_type":"markdown","source":["In the next step, we will train the model on CIFAR10 dataset."],"metadata":{"id":"TNyAiXdujs5U"}},{"cell_type":"code","execution_count":null,"source":["#Epochs\n","n_epochs = 100\n","\n","for epoch in range(1, n_epochs+1):\n","    # monitor training loss\n","    train_loss = 0.0\n","\n","    #Training\n","    for data in train_loader:\n","        images, _ = data\n","        images = images.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, images)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item()*images.size(0)\n","          \n","    train_loss = train_loss/len(train_loader)\n","    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))"],"outputs":[],"metadata":{"id":"5fDYXkekjwN6"}},{"cell_type":"markdown","source":["Finally, we will train the convolutional autoencoder model on generating the reconstructed images."],"metadata":{"id":"zRC6CUXJjzz6"}},{"cell_type":"code","execution_count":null,"source":["#Batch of test images\n","dataiter = iter(test_loader)\n","images, labels = dataiter.next()\n","\n","#Sample outputs\n","output = model(images)\n","images = images.numpy()\n","batch_size = 32\n","output = output.view(batch_size, 3, 32, 32)\n","output = output.detach().numpy()\n","\n","#Original Images\n","print(\"Original Images\")\n","fig, axes = plt.subplots(nrows=1, ncols=5, sharex=True, sharey=True, figsize=(12,4))\n","for idx in np.arange(5):\n","    ax = fig.add_subplot(1, 5, idx+1, xticks=[], yticks=[])\n","    imshow(images[idx])\n","    ax.set_title(classes[labels[idx]])\n","plt.show()\n","\n","#Reconstructed Images\n","print('Reconstructed Images')\n","fig, axes = plt.subplots(nrows=1, ncols=5, sharex=True, sharey=True, figsize=(12,4))\n","for idx in np.arange(5):\n","    ax = fig.add_subplot(1, 5, idx+1, xticks=[], yticks=[])\n","    imshow(output[idx])\n","    ax.set_title(classes[labels[idx]])\n","plt.show() "],"outputs":[],"metadata":{"id":"YUIvA6Iij2Hf"}},{"cell_type":"markdown","source":["#**Related Articles:**\n","\n","> * [Convolutional Autoencoder with PyTorch](https://analyticsindiamag.com/how-to-implement-convolutional-autoencoder-in-pytorch-with-cuda/)\n","\n","> * [Object Detection in HardNet](https://analyticsindiamag.com/building-your-own-object-recognition-in-pytorch-a-guide-to-implement-hardnet-in-pytorch/)\n","\n","> * [CNN Model â€“ To Count Fingers](https://analyticsindiamag.com/how-to-implement-cnn-model-to-count-fingers-and-distinguish-between-left-and-right-hand/)\n","\n","> * [Emotion Detection](https://analyticsindiamag.com/my-first-cnn-project-emotion-detection-using-convolutional-neural-network-with-tpu/)\n","\n","> * [Roboflow](https://analyticsindiamag.com/step-by-step-guide-to-object-detection-using-roboflow/)\n","\n","> * [Capsule Network](https://analyticsindiamag.com/understanding-capsule-net-with-its-implementation-in-computer-vision/)\n","\n","> * [Face Attendance System](https://analyticsindiamag.com/a-complete-guide-on-building-a-face-attendance-system/)"],"metadata":{"id":"1ZtPNx78qe5T"}}]}