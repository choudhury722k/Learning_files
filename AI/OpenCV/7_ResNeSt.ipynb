{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"1_ResNeSt.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMgsLx+dxfRYhHhX9Uf/49+"},"kernelspec":{"name":"python3","display_name":"Python 3.8.8 64-bit ('base': conda)"},"language_info":{"name":"python","version":"3.8.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"interpreter":{"hash":"f60a20abaabf5a658075b37fac599269792a9493ddacd7c14d8505185d5625aa"}},"cells":[{"cell_type":"markdown","source":["# ResNeSt\n","\n","\n","<img src=\"https://pytorch.org/assets/images/resnest.jpg\" alt=\"alt\" width=\"50%\"/>"],"metadata":{"id":"jGe0lP1qA8P-"}},{"cell_type":"markdown","source":["Convolution neural networks have largely dominated the computer vision domain, but in the last few years, feature-map attention architectures like SE-Net and SK-Net have started to assert dominance. In their paper “ResNeSt: Split-Attention Networks”,  Hang Zhang,  Chongruo Wu, et al. proposed a new ResNet variant that combines the best of both worlds. The ResNeSt architecture leverages the channel-wise attention with multi-path representation into a single unified Split-Attention block. It learns cross-channel feature correlations while preserving independent representation in the meta structure."],"metadata":{"id":"aot-LO6C5aVh"}},{"cell_type":"markdown","source":["To read more about its architecture, please refer [this](https://analyticsindiamag.com/guide-to-resnest-a-better-resnet-with-the-same-costs/) article."],"metadata":{"id":"vkjE5_jU5baU"}},{"cell_type":"markdown","source":["# Image Classification with ResNeSt"],"metadata":{"id":"uZ2_wlpL5iJU"}},{"cell_type":"markdown","source":["  Install PyTorch and fvcore."],"metadata":{"id":"E4jDurdA5ol1"}},{"cell_type":"code","execution_count":null,"source":["!python -m pip install pip --upgrade --user -q --no-warn-script-location\n","!python -m pip install numpy pandas seaborn matplotlib scipy statsmodels sklearn tensorflow keras opencv-python pillow scikit-image fvcore torch torchvision --user -q --no-warn-script-location\n","\n","import IPython\n","IPython.Application.instance().kernel.do_shutdown(True)\n"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["Download the pre-trained ResNeSt model from Torch hub and set it eval mode for making inferences."],"metadata":{"id":"gIYxXVs65wVf"}},{"cell_type":"code","execution_count":null,"source":["import torch\n","# get list of models\n","torch.hub.list('zhanghang1989/ResNeSt', force_reload=True)"],"outputs":[],"metadata":{"id":"M0RhhJGNA8QG"}},{"cell_type":"markdown","source":["All pre-trained models expect input images normalized in the same way,\n","i.e. mini-batches of 3-channel RGB images of shape `(3 x H x W)`, where `H` and `W` are expected to be at least `224`.\n","The images have to be loaded in to a range of `[0, 1]` and then normalized using `mean = [0.485, 0.456, 0.406]`\n","and `std = [0.229, 0.224, 0.225]`."],"metadata":{"id":"wziNctwiA8QH"}},{"cell_type":"code","execution_count":null,"source":["# load pretrained models, using ResNeSt-50 as an example\n","model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest50', pretrained=True)\n","model.eval()"],"outputs":[],"metadata":{"id":"OREUEyfcA-aT"}},{"cell_type":"markdown","source":["Get the image(s) for making inferences."],"metadata":{"id":"i7_1lX7M5zrv"}},{"cell_type":"code","execution_count":null,"source":["# !wget https://raw.githubusercontent.com/EliSchwartz/imagenet-sample-images/master/n01491361_tiger_shark.JPEG"],"outputs":[],"metadata":{"id":"67K57qnv6Aci"}},{"cell_type":"code","execution_count":null,"source":["# Download an example image\n","filename = \"n01491361_tiger_shark.JPEG\""],"outputs":[],"metadata":{"id":"HuMy7UNzA8QI"}},{"cell_type":"code","execution_count":null,"source":["from PIL import Image\n","from torchvision import transforms\n","input_image = Image.open(filename)\n","preprocess = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","input_tensor = preprocess(input_image)\n","input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n","\n","# move the input and model to GPU for speed if available\n","if torch.cuda.is_available():\n","    input_batch = input_batch.to('cuda')\n","    model.to('cuda')\n","\n","with torch.no_grad():\n","    output = model(input_batch)\n","    \n","# Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes\n","print(output)"],"outputs":[],"metadata":{"id":"tdgGXA-0A8QI"}},{"cell_type":"code","execution_count":null,"source":["# The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n","probabilities = torch.nn.functional.softmax(output[0], dim=0)\n","print(probabilities)"],"outputs":[],"metadata":{"id":"XFdJ8CBcBWiq"}},{"cell_type":"code","execution_count":null,"source":["# Download ImageNet labels\n","# !wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt"],"outputs":[],"metadata":{"id":"23u4cCMDA8QJ"}},{"cell_type":"markdown","source":["Apply softmax on the confidence scores of the 1000 ImageNet classes to get the probabilities. Print the top 3(k) categories. "],"metadata":{"id":"AwFNsC096isK"}},{"cell_type":"code","execution_count":null,"source":["# Read the categories\n","with open(\"imagenet_classes.txt\", \"r\") as f:\n","    categories = [s.strip() for s in f.readlines()]\n","# Show top categories per image\n","top3_prob, top3_catid = torch.topk(probabilities, 3)\n","for i in range(top3_prob.size(0)):\n","    print(categories[top3_catid[i]], top3_prob[i].item())"],"outputs":[],"metadata":{"id":"AcTNzLq5A8QK"}}]}