{"cells":[{"cell_type":"markdown","source":["# **Multi-Label Image Classification With Tensorflow & Keras**"],"metadata":{"id":"2YYNBtHZd8Ls"}},{"cell_type":"markdown","source":["Image classification is one of the trending applications in machine learning. It has a wide range of applications — from facial recognition algorithms to identifying complex patterns in images like crime detections, and many other social, medical and technical applications."],"metadata":{"id":"o6WKXdwOeAwh"}},{"cell_type":"markdown","source":["In this practice session, we will play around with a simple Multi-label classification problem. We will use the power of Tensorflow and the simplicity of Keras to build a classifier that is able to categorize the images of cats and dogs and also to identify their respective breeds."],"metadata":{"id":"nZM3PzJceab9"}},{"cell_type":"markdown","source":["## **Getting the dataset**"],"metadata":{"id":"G9QmBnckavRR"}},{"cell_type":"markdown","source":["Head to MachineHack, sign up and start the [Who Let The Dogs Out: Pets Breed Classification Hackathon](https://machinehack.com/hackathons/who_let_the_dogs_out_pets_breed_classification_hackathon/overview). The datasets can be downloaded on the assignment page. The training set consists of 6206 images of both cats and dogs of different breeds. We will use these images and their respective classes provided in the train.csv file to train our classifier to categorize a given image as either the image of a cat or a dog."],"metadata":{"id":"Isxj3e5Ea7Bm"}},{"cell_type":"markdown","source":["Multi-Label Image Classification With Tensorflow And Keras\n","\n","Note:\n","\n","> * Multi-label classification is a type of classification in which an object can be categorized into more than one class. For example, In the above dataset, we will classify a picture as the image of a dog or cat and also classify the same image based on the breed of the dog or cat.\n","> * Multi-class classification is simply classifying objects into any one of multiple categories. Such as classifying just into either a dog or cat from the dataset above.\n"],"metadata":{"id":"Uvv4wfwfh0y6"}},{"cell_type":"markdown","source":["Importing Tensorflow and Keras"],"metadata":{"id":"i_NW2SrHh3-e"}},{"cell_type":"code","execution_count":null,"source":["!python -m pip install pip --upgrade --user -q --no-warn-script-location\n","!python -m pip install numpy pandas seaborn matplotlib scipy statsmodels sklearn tensorflow keras opencv-python pillow scikit-image --user -q --no-warn-script-location\n","\n","import IPython\n","IPython.Application.instance().kernel.do_shutdown(True)\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","print(tf.__version__)"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":394,"status":"ok","timestamp":1622724481224,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"},"user_tz":-330},"id":"_M1KxlKBh6db","outputId":"839bf63c-3cd5-45d0-9593-9fc456444dca"}},{"cell_type":"markdown","source":["Preparing the training data\n","\n","To feed the images into the Neural Network we would require the images to be loaded. We are provided with a train.csv file consisting of the image names and the respective categories. We can use the sheet to load the images using the flow_from_dataframe method from Keras, but the method requires the complete filename with the extension of the image. Since we have jpg images we will format all the id’s in train.csv by adding ‘.jpg’ to all rows. We will then create a new training set with 3 columns namely Images, Animal and Breed. Since the Animal and Breed columns are categories we will convert the type to string."],"metadata":{"id":"okEHouMyh-1a"}},{"cell_type":"code","execution_count":null,"source":["training_set = pd.read_csv(\"train.csv\")\n","\n","training_imgs = [\"{}.jpg\".format(x) for x in list(training_set.id)]\n","\n","training_labels_1 = list(training_set['class_name'])\n","training_labels_2 = list(training_set['breed'])\n","training_set = pd.DataFrame( {'Images': training_imgs,'Animal': training_labels_1, 'Breed' : training_labels_2})\n","\n","#Changing the type  to str\n","training_set.Animal = training_set.Animal.astype(str)\n","training_set.Breed = training_set.Breed.astype(str)"],"outputs":[],"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1622724481225,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"},"user_tz":-330},"id":"3AQylyl2jbtG"}},{"cell_type":"markdown","source":["Creating a new category\n","\n","One of the simplest ways to solve a Multi-label Classification problem is by converting it into  Multi-class Classification problem. Here we will combine the Animal and Breed categories to form a new set of unique categories and we will call this new feature ‘New_class’."],"metadata":{"id":"j_rtZs5ajlkP"}},{"cell_type":"code","execution_count":null,"source":["training_set['New_class'] = training_set['Animal'] + training_set['Breed']"],"outputs":[],"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1622724481226,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"},"user_tz":-330},"id":"h0HPAQNnjnr6"}},{"cell_type":"markdown","source":["Let’s have a look at our new dataset."],"metadata":{"id":"08ykN3ftjro8"}},{"cell_type":"code","execution_count":null,"source":["print(training_set.head())"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1622724481227,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"},"user_tz":-330},"id":"XhDk_bsfjtLa","outputId":"46c2658e-b883-477c-b096-82d215a6b391"}},{"cell_type":"markdown","source":["Preprocessing Images"],"metadata":{"id":"jBmvTd63ju7-"}},{"cell_type":"code","execution_count":null,"source":["!gdown https://drive.google.com/uc?id=1W-9crZ3f30ZDdXPZ8-wADQo33CkG8TgH"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["!unzip image_data.zip"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1622724481228,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"},"user_tz":-330},"id":"Fw3ijP7nj0K0","outputId":"39bd8c08-20f3-409c-b993-1bfa337045f3"}},{"cell_type":"code","execution_count":null,"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","train_dataGen = ImageDataGenerator(rescale = 1./255,\n","                                  shear_range = 0.2,\n","                                  zoom_range = 0.2,\n","                                  horizontal_flip = True)\n","\n","train_generator = train_dataGen.flow_from_dataframe(\n","                                        dataframe = training_set,\n","                                        directory=\"image_data/images_train/\",x_col=\"Images\",\n","                                        y_col=\"New_class\",\n","                                        class_mode=\"categorical\",\n","                                        target_size=(128,128),\n","                                        batch_size=32)"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1622724481229,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"},"user_tz":-330},"id":"_SIAQCOyjzpo","outputId":"6378ad8c-e03b-4e2c-8872-f6e6a9a76715"}},{"cell_type":"markdown","source":["We will now preprocess the images using Keras’ ImageDataGenerator class which will convert the images into an array of vectors that can be fed to the neural network. A set of features or parameters can be initialized to the ImageDataGenerator such as rescale, shear_range, zoom_range etc. These parameters help in extracting maximum features from an image.\n","\n","The flow_from_dataframe method allows us to import images from a data frame provided the path of the images using the parameter ‘directory’. The x_col specifies the independent factor which is an image and y_col represents the dependent factor which is the category of the image that we need to predict. The target size will be the size of the resulting images from the ImageDataGenerator object, batch_size is the number of sample images used to train at once."],"metadata":{"id":"pwnCzT3FkAcy"}},{"cell_type":"markdown","source":["Building Convolutional Neural Network"],"metadata":{"id":"TdaIuEIQkCj5"}},{"cell_type":"markdown","source":["We are done processing the image data. Now we can proceed to build a simple convolutional neural network. Keras allows us to build neural networks effortlessly with a couple of classes and methods."],"metadata":{"id":"kULj7HaFkERA"}},{"cell_type":"code","execution_count":null,"source":["classifier = Sequential()"],"outputs":[],"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1622724481230,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"},"user_tz":-330},"id":"LEGAk2vukF52"}},{"cell_type":"markdown","source":["The Sequential class initializes a network to which we can add layers and nodes."],"metadata":{"id":"AGo9aq7IkIef"}},{"cell_type":"code","execution_count":null,"source":["#First Convolutional layer\n","classifier.add(Conv2D(filters = 56,kernel_size = (3,3), activation = 'relu', input_shape = (128,128,3)))"],"outputs":[],"metadata":{"executionInfo":{"elapsed":664,"status":"ok","timestamp":1622724481882,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"},"user_tz":-330},"id":"qy5VtQKZkMXr"}},{"cell_type":"markdown","source":["The add method allows us to add layers of nodes to the initialized network. In the above code, we added a Convolutional layer to the network. The convolution will be performed using a 3×3 matrix as specified with the kernel _size parameter. The activation parameter sets the activation function for the nodes. The input size should be same as the size of the outputs from the ImageDataGenerator (3 is the channel width)."],"metadata":{"id":"m2NkJzo5kKUr"}},{"cell_type":"code","execution_count":null,"source":["classifier.add(MaxPooling2D(pool_size = (2,2)))"],"outputs":[],"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1622724481883,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"},"user_tz":-330},"id":"qrV5_mUplFp6"}},{"cell_type":"markdown","source":["The above code adds a pooling layer to the network.\n","\n","We can add as many layers as we want as shown below, however, this puts a lot of pressure on the system resources. Choose the layers and nodes based on the capability of the machines."],"metadata":{"id":"K2RVtiaHlI77"}},{"cell_type":"code","execution_count":null,"source":["#second Convolutional layer\n","classifier.add(Conv2D(32,(3,3),activation = 'relu'))\n","classifier.add(MaxPooling2D(pool_size = (2,2)))"],"outputs":[],"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1622724481883,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"},"user_tz":-330},"id":"zzdvcnvWlLJK"}},{"cell_type":"markdown","source":["The line below adds a Flattening layer to the network."],"metadata":{"id":"Up_2i_M2lLcL"}},{"cell_type":"code","execution_count":null,"source":["#Flattening\n","classifier.add(Flatten())"],"outputs":[],"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1622724481883,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"},"user_tz":-330},"id":"Pf5LkhUmlOYu"}},{"cell_type":"markdown","source":["Next, we will add a hidden layer and an output layer to complete the network as done with the following code blocks."],"metadata":{"id":"ovsDQk2PlQe8"}},{"cell_type":"code","execution_count":null,"source":["#Hidden Layer\n","classifier.add(Dense(units = 64, activation = 'relu'))\n","\n","#Output Layer\n","classifier.add(Dense(units = 10 , activation = 'softmax'))"],"outputs":[],"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1622724481884,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"},"user_tz":-330},"id":"P9tE8k4wlSzJ"}},{"cell_type":"markdown","source":["We will now compile the network to initialize the metrics, loss and weights for the network"],"metadata":{"id":"zN9xBt5tlUba"}},{"cell_type":"code","execution_count":null,"source":["classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['categorical_accuracy','accuracy'])"],"outputs":[],"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1622724481885,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"},"user_tz":-330},"id":"_-7il6t0lXKY"}},{"cell_type":"markdown","source":["Let’s have a look at the description of our CNN :"],"metadata":{"id":"_l9aw0iblYye"}},{"cell_type":"code","execution_count":null,"source":["classifier.summary()"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1622724481885,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"},"user_tz":-330},"id":"piVgRrtRlaJq","outputId":"bc132a39-cc45-459c-9898-f36e54a41cf5"}},{"cell_type":"markdown","source":["Training the CNN"],"metadata":{"id":"f4Ooo_Pnlbua"}},{"cell_type":"code","execution_count":null,"source":["classifier.fit_generator(train_generator, epochs =50, steps_per_epoch = 60 )"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":82524,"status":"ok","timestamp":1622724575495,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"},"user_tz":-330},"id":"8wCwZHwKldUq","outputId":"5c564486-7b8f-4bdf-ebba-7b077114d918"}},{"cell_type":"markdown","source":["The fit_generator method will train the classifier with the data we gathered by processing the images using ImageDataGenerator class. The epochs are the number of times the cycle of training repeats. Steps-per-epoch determines the number of times the weights of each node should be updated for decreasing the loss."],"metadata":{"id":"53zNtJmble8o"}},{"cell_type":"markdown","source":["Predicting For Test Set"],"metadata":{"id":"NTg667rdlgyO"}},{"cell_type":"markdown","source":["Preparing Test Data\n","\n","We will prepare the test data by adding the path and file extension to the original test_set. This will help us load the images directly from the csv file using the load_img() method that you will see in the following code blocks."],"metadata":{"id":"Nj1Cb4k-lint"}},{"cell_type":"code","execution_count":null,"source":["test_set = pd.read_csv(\"test.csv\")\n","test_imgs = [\"image_data/images_test/{}.jpg\".format(x) for x in list(test_set.id)]\n","test_set = pd.DataFrame( {'Images': test_imgs })"],"outputs":[],"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1622724575497,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"},"user_tz":-330},"id":"ECXi9fR2lksv"}},{"cell_type":"markdown","source":["Identifying the trained classes"],"metadata":{"id":"Kouc6zW5lmRZ"}},{"cell_type":"markdown","source":["The train_generator consists of the complete trained image data. Let’s have a look at the unique categories in the training data using the class_indices attribute of the train_generator. "],"metadata":{"id":"flIYOnWLlwWI"}},{"cell_type":"code","execution_count":null,"source":["classes = train_generator.class_indices\n","print(classes)"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1622724575499,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"},"user_tz":-330},"id":"5gbrC73DlyAe","outputId":"96f3e976-acc7-49ce-9ab6-1007c8086941"}},{"cell_type":"markdown","source":["Our model will be predicting the labels in the range 0 to 9 based on the above dictionary for each category. We will need to reverse these to the original classes. We will use a reverse of the above dictionary to later convert the predictions to actual classes. The dictionary can be inverted with the following line of code:"],"metadata":{"id":"Qx2pQc5Yl07B"}},{"cell_type":"code","execution_count":null,"source":["inverted_classes = dict(map(reversed, classes.items()))\n","print(inverted_classes)"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1622724575500,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"},"user_tz":-330},"id":"PWGKG65Nqs2t","outputId":"41a07762-8acc-40c1-861e-3fcdc0da3240"}},{"cell_type":"markdown","source":["Predicting classes"],"metadata":{"id":"1_6P_DULquUf"}},{"cell_type":"markdown","source":["Now it’s time to load the images one by one and predict and store the category of each image from the test_set. "],"metadata":{"id":"Vuw_c7m2qr-r"}},{"cell_type":"code","execution_count":null,"source":["from keras.preprocessing import image\n","\n","Y_pred = []\n","\n","for i in range(len(test_set)):\n","  img = image.load_img(path= test_set.Images[i],target_size=(128,128,3))\n","  img = image.img_to_array(img)\n","  test_img = img.reshape((1,128,128,3))\n","  img_class = classifier.predict_classes(test_img)\n","  prediction = img_class[0]\n","  Y_pred.append(prediction)"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":51748,"status":"ok","timestamp":1622724627235,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"},"user_tz":-330},"id":"D-QBB-oqqyqe","outputId":"7f53abfd-3b51-45f1-964e-d072d5c0f304"}},{"cell_type":"markdown","source":["The above code block loads each image from the test set preprocess it and feeds it to the classifier to predict. The predictions are stored in a list called y_pred. Notice that all the image sizes (128,128) are the same as we did for the training set, this is important and otherwise would result in an error.\n","\n","Let’s take a look at the predictions:"],"metadata":{"id":"cW6Qrs6Wq1i6"}},{"cell_type":"code","execution_count":null,"source":["print(Y_pred)"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43,"status":"ok","timestamp":1622724627248,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"},"user_tz":-330},"id":"XMPKxsHOq3GP","outputId":"465b0cb1-5a9b-44c1-edfd-4d9ba7f2d50d"}},{"cell_type":"markdown","source":["We can see that the predictions are in the range of 0 to 9. We can now use the inverted_classes dictionary to convert the predicted labels into actual categories."],"metadata":{"id":"xDxe3pBXq42E"}},{"cell_type":"code","execution_count":null,"source":["prediction_classes = [ inverted_classes.get(item,item) for item in Y_pred ]"],"outputs":[],"metadata":{"executionInfo":{"elapsed":35,"status":"ok","timestamp":1622724627250,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"},"user_tz":-330},"id":"S3dh7GHnq7F7"}},{"cell_type":"markdown","source":["Now if we look at the prediction_classes, we will be able to see the actual categories we used to train our classifier with."],"metadata":{"id":"k7IEGdLaq9SV"}},{"cell_type":"code","execution_count":null,"source":["print(prediction_classes)"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34,"status":"ok","timestamp":1622724627252,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"},"user_tz":-330},"id":"Wzx8LbA7q8pL","outputId":"c7970c70-fc57-448b-b73b-be51b039f94c"}},{"cell_type":"markdown","source":["There is one more thing to do. Remember, the original training set provided had 2 categories, class_name and breed which we later renamed as Animal and Breed. So we will now need to split the predicted categories into class_name and breed (Animal and Breed)."],"metadata":{"id":"VunFEVyNrBl8"}},{"cell_type":"code","execution_count":null,"source":["animal = []\n","breed = []\n","for i in prediction_classes:\n","  animal.append(i[0]) # First character = class_name/Animal\n","  breed.append(i[1:]) # Last 2 characters = breed/Breed"],"outputs":[],"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1622724627252,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"},"user_tz":-330},"id":"4HRwXJcvrDR-"}},{"cell_type":"markdown","source":["Creating a dataframe for the predictions and writing it to an excel"],"metadata":{"id":"4JxBtoBnrFJu"}},{"cell_type":"code","execution_count":null,"source":["predictions = {}\n","predictions['class_name'] = animal\n","predictions['breed'] = breed"],"outputs":[],"metadata":{"executionInfo":{"elapsed":24,"status":"ok","timestamp":1622724627253,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"},"user_tz":-330},"id":"WQJtskVlrHLj"}},{"cell_type":"markdown","source":["Let’s have a look at the predicted classes:"],"metadata":{"id":"DWusuZJArJ99"}},{"cell_type":"code","execution_count":null,"source":["#Writing to excel\n","pd.DataFrame(predictions).to_excel(\"predictionss.xlsx\", index = False)"],"outputs":[],"metadata":{"executionInfo":{"elapsed":609,"status":"ok","timestamp":1622724639495,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"},"user_tz":-330},"id":"72qpYZ25rMdB"}},{"cell_type":"markdown","source":["#**Related Articles:**\n","\n","> * [Multi Class Image Classification with Tensorflow and Keras](https://analyticsindiamag.com/multi-label-image-classification-with-tensorflow-keras/)\n","\n","> * [Transfer Learning in Tensorflow Keras](https://analyticsindiamag.com/a-practical-guide-to-implement-transfer-learning-in-tensorflow/)\n","\n","> * [Differentiable Augmentation for Data-Efficient GAN Training](https://analyticsindiamag.com/guide-to-differentiable-augmentation-for-data-efficient-gan-training/)\n","\n","> * [Guide to Albumentation](https://analyticsindiamag.com/hands-on-guide-to-albumentation/)\n","\n","> * [Google STAC](https://analyticsindiamag.com/googles-stac-ssl-framework-for-object-detection/)\n","\n","> * [Comparison of Transfer Learning with Multi Class Classification](https://analyticsindiamag.com/practical-comparison-of-transfer-learning-models-in-multi-class-image-classification/)\n"],"metadata":{"id":"1ZtPNx78qe5T"}}],"metadata":{"colab":{"authorship_tag":"ABX9TyNWLpsHPOJDh1a7guTHbmiC","collapsed_sections":[],"mount_file_id":"1OdT9XX0CriDWBPhzPBuRfeaPTXWDR2lM","name":"3_Multi_image_classification_With_TensorflowKeras.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":2}