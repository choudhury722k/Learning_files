{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"1_Practical_Comparison_of_Transfer_Learning_Models.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP3JZ4rpOkCiVGg5hYAUDQe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **Practical Comparison of Transfer Learning Models**"],"metadata":{"id":"cjJFJUP6xl31"}},{"cell_type":"markdown","source":["Computer vision is a trend nowadays due to the latest developments in the field of deep learning. Researchers and developers are continuously proposing interesting applications of computer vision using deep learning frameworks. In the last article ‘Transfer Learning for Multi-Class Image Classification Using Deep Convolutional Network’, we used the VGG19 model as a transfer learning framework to classify CIFAR-10 images into 10 classes. Now we will explore the other popular transfer learning architectures in the same task and compare their classification performance."],"metadata":{"id":"ynaxVZtHxuvJ"}},{"cell_type":"markdown","source":["In this practice session, we will compare the multi-class classification performance of three popular transfer learning architectures – VGG16, VGG19 and ResNet50. These all three models that we will use are pre-trained on ImageNet dataset. For the experiment, we have taken the CIFAR-10 image dataset that is a popular benchmark in image classification. The performances of all the three models will be compared using the confusion matrices and their average accuracies."],"metadata":{"id":"1IUFC_SVxxr1"}},{"cell_type":"markdown","source":["## **Implementation of Transfer Learning Models in Python**"],"metadata":{"id":"HES8EtFVyU2I"}},{"cell_type":"markdown","source":["Here, we are going to import all the required libraries. Make sure that you have installed the TensorFlow if you are working on your local system. For the implementation of transfer learning, three models VGG19, VGG16 and ResNet50 are also imported here."],"metadata":{"id":"UCRTUixiyYnV"}},{"cell_type":"code","execution_count":null,"source":["!python -m pip install pip --upgrade --user -q --no-warn-script-location\n","!python -m pip install numpy pandas seaborn matplotlib scipy statsmodels sklearn nltk gensim tensorflow keras torch torchvision \\\n","    tqdm scikit-image --user -q --no-warn-script-location\n","\n","\n","import IPython\n","IPython.Application.instance().kernel.do_shutdown(True)\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["#importing other required libraries\n","import numpy as np\n","import pandas as pd\n","from sklearn.utils.multiclass import unique_labels\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import seaborn as sns\n","import itertools\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","from keras import Sequential\n","from tensorflow.keras.applications import vgg19, vgg16, ResNet50\n","from keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.optimizers import SGD,Adam\n","from keras.callbacks import ReduceLROnPlateau\n","from keras.layers import Flatten, Dense, BatchNormalization, Activation,Dropout\n","from keras.utils.np_utils import to_categorical\n","import tensorflow as tf\n","import random"],"outputs":[],"metadata":{"id":"A3_rAJAisR2Y","executionInfo":{"status":"ok","timestamp":1622714855396,"user_tz":-330,"elapsed":632,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"markdown","source":["\n","\n","Once the libraries are imported successfully, we will download the CIFAR-10 dataset that is a publicly available dataset with Keras. "],"metadata":{"id":"0szxOPqcydAy"}},{"cell_type":"code","execution_count":null,"source":["#Keras library for CIFAR dataset\n","from keras.datasets import cifar10\n","(x_train, y_train),(x_test, y_test)=cifar10.load_data()"],"outputs":[],"metadata":{"id":"6nJH2kWZzkID","executionInfo":{"status":"ok","timestamp":1622714856390,"user_tz":-330,"elapsed":379,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"markdown","source":["After downloading the dataset, we will plot some random images from the dataset CIFAR-10 dataset to verify whether it has been downloaded correctly or not."],"metadata":{"id":"0LJfcjduzmsx"}},{"cell_type":"code","execution_count":null,"source":["W_grid=5\n","L_grid=5\n","fig,axes = plt.subplots(L_grid,W_grid,figsize=(10,10))\n","axes=axes.ravel()\n","n_training=len(x_train)\n","for i in np.arange(0,L_grid * W_grid):\n","    index=np.random.randint(0,n_training) \n","    axes[i].imshow(x_train[index])\n","    axes[i].set_title(y_train[index]) \n","    axes[i].axis('off')\n","plt.subplots_adjust(hspace=0.4)"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":628},"id":"yb86_kxXzpEU","executionInfo":{"status":"ok","timestamp":1622714858539,"user_tz":-330,"elapsed":2151,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"865c3dd2-51d0-4b44-a262-92b04c5dc5dc"}},{"cell_type":"markdown","source":["We will split our dataset into training and validation sets. Training and validation sets will be used during the training and the test set will be used in final prediction on the new image dataset."],"metadata":{"id":"b736E4_CzuLo"}},{"cell_type":"code","execution_count":null,"source":["#Train-validation-test split\n","x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=.3)"],"outputs":[],"metadata":{"id":"qfjMtMMLzwHY","executionInfo":{"status":"ok","timestamp":1622714858540,"user_tz":-330,"elapsed":14,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"markdown","source":["After the split, we will perform one-hot encoding on the dataset because our output has 10 classes. First, we will print the shape and after one-hot encoding, we will verify the final shape of the dataset."],"metadata":{"id":"SMy3dp9hzyE7"}},{"cell_type":"code","execution_count":null,"source":["#Dimension of the CIFAR10 dataset\n","print((x_train.shape,y_train.shape))\n","print((x_val.shape,y_val.shape))\n","print((x_test.shape,y_test.shape))"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Ev2-F7g0DCx","executionInfo":{"status":"ok","timestamp":1622714858541,"user_tz":-330,"elapsed":14,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"625111ac-55e5-490d-81d0-a6a991a5afb6"}},{"cell_type":"code","execution_count":null,"source":["#Onehot Encoding the labels.\n","#Since we have 10 classes we should expect the shape[1] of y_train,y_val and y_test to change from 1 to 10\n","y_train=to_categorical(y_train)\n","y_val=to_categorical(y_val)\n","y_test=to_categorical(y_test)\n","\n","#Verifying the dimension after one hot encoding\n","print((x_train.shape,y_train.shape))\n","print((x_val.shape,y_val.shape))\n","print((x_test.shape,y_test.shape))"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TI3zUIji0FoF","executionInfo":{"status":"ok","timestamp":1622714858542,"user_tz":-330,"elapsed":12,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"68990f4c-0a40-44cd-d03b-bbfef26f9a5e"}},{"cell_type":"markdown","source":["In order to preprocess the image dataset to make it available for training the deep learning model, the below image data augmentation steps will be performed. "],"metadata":{"id":"rLxVrXfe0Irk"}},{"cell_type":"code","execution_count":null,"source":["#Image Data Augmentation\n","train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True, zoom_range=.1 )\n","\n","val_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True,zoom_range=.1)\n","\n","test_generator = ImageDataGenerator(rotation_range=2,  horizontal_flip= True, zoom_range=.1)\n","\n","#Fitting the augmentation defined above to the data\n","\n","train_generator.fit(x_train)\n","val_generator.fit(x_val)\n","test_generator.fit(x_test)"],"outputs":[],"metadata":{"id":"iUsXeEys0Qjh","executionInfo":{"status":"ok","timestamp":1622714859024,"user_tz":-330,"elapsed":491,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"markdown","source":["Now, we will define the learning rate annealer. As we have discussed in the previous article, the learning rate annealer decreases the learning rate after a certain number of epochs if the error rate does not change."],"metadata":{"id":"4N-iQGRV0exs"}},{"cell_type":"code","execution_count":null,"source":["#Learning Rate Annealer\n","lrr= ReduceLROnPlateau(monitor='val_acc', factor=.01,  patience=3, min_lr=1e-5)"],"outputs":[],"metadata":{"id":"NFO8tktv0nlg","executionInfo":{"status":"ok","timestamp":1622714859025,"user_tz":-330,"elapsed":22,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"markdown","source":["## **VGG19 Transfer Learning Model**"],"metadata":{"id":"fE_S70Mg0pT5"}},{"cell_type":"markdown","source":["In the next step, we will initialize our VGG19 model. As we are going to use the VGG10 as a transfer learning framework, we will use the pre-trained ImageNet weights with this model."],"metadata":{"id":"D5U_gJTG1D89"}},{"cell_type":"code","execution_count":null,"source":["base_model_VGG19 = vgg19.VGG19(include_top=False, weights='imagenet', input_shape=(32,32,3), classes=y_train.shape[1])"],"outputs":[],"metadata":{"id":"D_HXHlBT1Ff-","executionInfo":{"status":"ok","timestamp":1622714859025,"user_tz":-330,"elapsed":20,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"markdown","source":["Now we will add the layers to the VGG19 network that we have initialized above."],"metadata":{"id":"wz1xvwPX1Kc9"}},{"cell_type":"code","execution_count":null,"source":["#Adding the final layers to the above base models where the actual classification is done in the dense layers\n","model_vgg19 = Sequential()\n","model_vgg19.add(base_model_VGG19) \n","model_vgg19.add(Flatten()) \n","model_vgg19.add(Dense(1024,activation=('relu'),input_dim=512))\n","model_vgg19.add(Dense(512,activation=('relu'))) \n","model_vgg19.add(Dense(256,activation=('relu'))) \n","#model_vgg19.add(Dropout(.3))\n","model_vgg19.add(Dense(128,activation=('relu')))\n","#model_vgg19.add(Dropout(.2))\n","model_vgg19.add(Dense(10,activation=('softmax')))"],"outputs":[],"metadata":{"id":"bzN_1uPH1MOE","executionInfo":{"status":"ok","timestamp":1622714859026,"user_tz":-330,"elapsed":19,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"markdown","source":["After adding all the layers, we will check the model’s summary."],"metadata":{"id":"pzQnazEE1OMM"}},{"cell_type":"code","execution_count":null,"source":["#VGG19 Model Summary\n","model_vgg19.summary()"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7B60HlN11PtE","executionInfo":{"status":"ok","timestamp":1622714859027,"user_tz":-330,"elapsed":19,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"9a2832b3-42b8-4ff3-a93c-f82378589044"}},{"cell_type":"markdown","source":["Next, we will define the training hyperparameters and compile our model. For error optimization, we will be using stochastic gradient descent. "],"metadata":{"id":"dU-cslqE1n89"}},{"cell_type":"code","execution_count":null,"source":["#Defining the hyperparameters\n","batch_size= 100\n","epochs=50\n","learn_rate=.001\n","sgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)\n","\n","#Compiling the VGG19 model\n","model_vgg19.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lC6QJjMj1rlb","executionInfo":{"status":"ok","timestamp":1622714859028,"user_tz":-330,"elapsed":14,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"67fcf334-50d9-4b55-c4f0-87f93bd0922a"}},{"cell_type":"markdown","source":["After defining all the hyperparameters, we will train our model in 20 epochs."],"metadata":{"id":"PqWs7yd01uag"}},{"cell_type":"code","execution_count":null,"source":["model_vgg19.fit_generator(train_generator.flow(x_train, y_train, batch_size = batch_size), epochs=epochs, steps_per_epoch = x_train.shape[0]//batch_size, validation_data = val_generator.flow(x_val, y_val, batch_size = batch_size), validation_steps = 250, callbacks = [lrr], verbose = 1)"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iOB3gSvy1wCb","executionInfo":{"status":"ok","timestamp":1622715967101,"user_tz":-330,"elapsed":1108085,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"697a94b2-16fd-4ba0-a963-c5234de4cdc4"}},{"cell_type":"markdown","source":["The training performance will be visualized now in terms of loss and accuracy during the training and the validation."],"metadata":{"id":"4dq2g6Kb16Uu"}},{"cell_type":"code","execution_count":null,"source":["#Plotting the training and validation loss\n","f,ax=plt.subplots(2,1) #Creates 2 subplots under 1 column\n","#Training loss and validation loss\n","ax[0].plot(model_vgg19.history.history['loss'],color='b',label='Training Loss')\n","ax[0].plot(model_vgg19.history.history['val_loss'],color='r',label='Validation Loss')\n","#Training accuracy and validation accuracy\n","ax[1].plot(model_vgg19.history.history['accuracy'],color='b',label='Training  Accuracy')\n","ax[1].plot(model_vgg19.history.history['val_accuracy'],color='r',label='Validation Accuracy')"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":283},"id":"3jF4vQQG2E-H","executionInfo":{"status":"ok","timestamp":1622715967105,"user_tz":-330,"elapsed":30,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"00484036-d682-41d7-e9b6-62d6401a940f"}},{"cell_type":"markdown","source":["To plot the confusion matrix, we will define a function here."],"metadata":{"id":"35I1LcDz2H-z"}},{"cell_type":"code","execution_count":null,"source":["#Defining function for confusion matrix plot\n","def plot_confusion_matrix(y_true, y_pred, classes,\n","                          normalize=False,\n","                          title=None,\n","                          cmap=plt.cm.Blues):\n","    if not title:\n","        if normalize:\n","            title = 'Normalized confusion matrix'\n","        else:\n","            title = 'Confusion matrix, without normalization'\n","\n","    # Computing confusion matrix\n","    cm = confusion_matrix(y_true, y_pred)\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        print(\"Normalized confusion matrix\")\n","    else:\n","        print('Confusion matrix, without normalization')\n","\n","# Visualizing\n","    fig, ax = plt.subplots(figsize=(7,7))\n","    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n","    ax.figure.colorbar(im, ax=ax)\n","    # We want to show all ticks...\n","    ax.set(xticks=np.arange(cm.shape[1]),\n","           yticks=np.arange(cm.shape[0]),\n","           xticklabels=classes, yticklabels=classes,\n","           title=title,\n","           ylabel='True label',\n","           xlabel='Predicted label')\n","\n","   # Rotating the tick labels and setting their alignment.\n","    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n","             rotation_mode=\"anchor\")\n","    # Looping over data dimensions and create text annotations.\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","    for i in range(cm.shape[0]):\n","        for j in range(cm.shape[1]):\n","            ax.text(j, i, format(cm[i, j], fmt),\n","                    ha=\"center\", va=\"center\",\n","                    color=\"white\" if cm[i, j] > thresh else \"black\")\n","    fig.tight_layout()\n","    return ax\n","np.set_printoptions(precision=2)"],"outputs":[],"metadata":{"id":"Z59Zb9Ai2Ltx","executionInfo":{"status":"ok","timestamp":1622715967107,"user_tz":-330,"elapsed":18,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"markdown","source":["We will make the predictions through the trained VGG19 model using the test image dataset."],"metadata":{"id":"aKBUpE262Qqu"}},{"cell_type":"code","execution_count":null,"source":["#Making prediction\n","y_pred1 = model_vgg19.predict_classes(x_test)\n","y_true = np.argmax(y_test,axis=1)"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fp0rh-cQ2UwX","executionInfo":{"status":"ok","timestamp":1622715970568,"user_tz":-330,"elapsed":3477,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"8a1262cd-f5ae-494f-a42a-ec9f15808f56"}},{"cell_type":"markdown","source":["Now, we will plot the non-normalized confusion matrix to visualize the exact number of classifications and normalized confusion matrix to visualize the percentage of classifications. "],"metadata":{"id":"dE_ub6yF2W8z"}},{"cell_type":"code","execution_count":null,"source":["#Plotting the confusion matrix\n","confusion_mtx=confusion_matrix(y_true,y_pred1)\n","\n","class_names=['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n","\n","#Plotting non-normalized confusion matrix\n","plot_confusion_matrix(y_true, y_pred1, classes = class_names,  title = 'Non-Normalized VGG19 Confusion Matrix')"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":523},"id":"2mANYaDV2ZKn","executionInfo":{"status":"ok","timestamp":1622715971603,"user_tz":-330,"elapsed":1041,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"09124095-a3df-4adf-a073-b73d2b135467"}},{"cell_type":"code","execution_count":null,"source":["#Plotting normalized confusion matrix\n","plot_confusion_matrix(y_true, y_pred1, classes = class_names, normalize = True, title = 'Normalized VGG19 Confusion matrix')"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":523},"id":"zb0x1OB92cdS","executionInfo":{"status":"ok","timestamp":1622715972594,"user_tz":-330,"elapsed":1003,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"4b58d826-41c4-4115-e253-b5aab5b58082"}},{"cell_type":"markdown","source":["Finally, we will see the average classification accuracy of VGG19."],"metadata":{"id":"uV7ux1hk2ofD"}},{"cell_type":"code","execution_count":null,"source":["#Accuracy of VGG19\n","from sklearn.metrics import accuracy_score\n","accuracy_score(y_true, y_pred1)"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WkLEw8Ko2qik","executionInfo":{"status":"ok","timestamp":1622715972596,"user_tz":-330,"elapsed":18,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"2cc35de1-a09c-450d-a5b5-b78a2e58a409"}},{"cell_type":"markdown","source":["## VGG16 Transfer Learning Model"],"metadata":{"id":"3mOFdmRk2woI"}},{"cell_type":"markdown","source":["As the next model, we will repeat the above steps for the VGG16 model."],"metadata":{"id":"PZv6Exij206-"}},{"cell_type":"code","execution_count":null,"source":["#VGG16 Model\n","base_model_vgg16 = vgg16.VGG16(include_top = False, weights= 'imagenet', input_shape = (32,32,3), classes = y_train.shape[1])\n","\n","#Adding the final layers to the above base models where the actual classification is done in the dense layers\n","model_vgg16= Sequential()\n","model_vgg16.add(base_model_vgg16) \n","model_vgg16.add(Flatten())\n","#Adding the Dense layers along with activation and batch normalization\n","model_vgg16.add(Dense(1024,activation=('relu'),input_dim=512))\n","model_vgg16.add(Dense(512,activation=('relu'))) \n","model_vgg16.add(Dense(256,activation=('relu'))) \n","#model.add(Dropout(.3))\n","model_vgg16.add(Dense(128,activation=('relu')))\n","#model.add(Dropout(.2))\n","model_vgg16.add(Dense(10,activation=('softmax')))\n","\n","#Checking the final VGG16 model summary\n","model_vgg16.summary()"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RaBsjS6123Px","executionInfo":{"status":"ok","timestamp":1622715972598,"user_tz":-330,"elapsed":16,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"52ccb0c1-ce6d-45e3-ba2f-e79a012b5d16"}},{"cell_type":"code","execution_count":null,"source":["#Compiling VGG16\n","model_vgg16.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n","\n","\n","#Training VGG16\n","model_vgg16.fit_generator(train_generator.flow(x_train, y_train, batch_size = batch_size), epochs = epochs, steps_per_epoch = x_train.shape[0]//batch_size, validation_data = val_generator.flow(x_val, y_val, batch_size = batch_size), validation_steps=250, callbacks=[lrr], verbose=1)"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I6HbMlAW3AZb","executionInfo":{"status":"ok","timestamp":1622716975979,"user_tz":-330,"elapsed":1003393,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"ec6cb725-ebcb-4184-a3d1-13c60b3cd255"}},{"cell_type":"code","execution_count":null,"source":["#Plotting the VGG16 training and validation loss\n","f,ax=plt.subplots(2,1) #Creates 2 subplots under 1 column\n","#Training loss and validation loss\n","ax[0].plot(model_vgg16.history.history['loss'],color='b',label='Training Loss')\n","ax[0].plot(model_vgg16.history.history['val_loss'],color='r',label='Validation Loss')\n","#Training accuracy and validation accuracy\n","ax[1].plot(model_vgg16.history.history['accuracy'],color='b',label='Training  Accuracy')\n","ax[1].plot(model_vgg16.history.history['val_accuracy'],color='r',label='Validation Accuracy')"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":283},"id":"IGGcBw1N3Ew5","executionInfo":{"status":"ok","timestamp":1622716975983,"user_tz":-330,"elapsed":29,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"2de40a19-c2a3-4210-bd69-5af79c585935"}},{"cell_type":"code","execution_count":null,"source":["#Making prediction\n","y_pred2=model_vgg16.predict_classes(x_test)\n","y_true=np.argmax(y_test,axis=1)\n","\n","#Plotting the confusion matrix\n","confusion_mtx=confusion_matrix(y_true,y_pred2)\n","\n","#Plotting non-normalized confusion matrix\n","plot_confusion_matrix(y_true, y_pred2, classes = class_names,title = 'Non-Normalized VGG16 Confusion Matrix')"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":580},"id":"7I_Q8l8m3PEz","executionInfo":{"status":"ok","timestamp":1622716979773,"user_tz":-330,"elapsed":3804,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"c29d3e8f-524a-414d-86f1-60ecf4843bc2"}},{"cell_type":"code","execution_count":null,"source":["#Plotting normalized confusion matrix\n","plot_confusion_matrix(y_true, y_pred2, classes = class_names, normalize = True, title= 'Normalized VGG16 Confusion matrix')"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":524},"id":"Kkms3KwF3VBe","executionInfo":{"status":"ok","timestamp":1622716980554,"user_tz":-330,"elapsed":787,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"bad71498-d664-47c1-cd25-e7bce0aace5e"}},{"cell_type":"code","execution_count":null,"source":["#Accuracy of VGG16\n","from sklearn.metrics import accuracy_score\n","accuracy_score(y_true, y_pred2)"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wIsy8qx03XQu","executionInfo":{"status":"ok","timestamp":1622716980555,"user_tz":-330,"elapsed":47,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"3dd31151-0d43-45ab-a39d-98bbb1c4066c"}},{"cell_type":"markdown","source":["## **ResNet50 Transfer Learning Model**"],"metadata":{"id":"ry7cDV4P3Yrn"}},{"cell_type":"markdown","source":["In the next step, we will perform the same steps with the ResNet50 model."],"metadata":{"id":"oPoRsQhE3bSG"}},{"cell_type":"code","execution_count":null,"source":["#Initializing ResNet50\n","model_resnet = resnet50.ResNet50(include_top = False, weights = 'imagenet', input_shape = (32,32,3), classes = y_train.shape[1])"],"outputs":[],"metadata":{"id":"B8_xyPO13df2","executionInfo":{"status":"aborted","timestamp":1622717046393,"user_tz":-330,"elapsed":8,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"code","execution_count":null,"source":["#Adding layers to the ResNet50\n","model_resnet=Sequential()\n","#Add the Dense layers along with activation and batch normalization\n","model_resnet.add(base_model_resnet)\n","model_resnet.add(Flatten())\n","#Add the Dense layers along with activation and batch normalization\n","model_resnet.add(Dense(1024,activation=('relu'),input_dim=512))\n","model_resnet.add(Dense(512,activation=('relu'))) \n","model_resnet.add(Dropout(.4))\n","model_resnet.add(Dense(256,activation=('relu'))) \n","model_resnet.add(Dropout(.3))\n","model_resnet.add(Dense(128,activation=('relu')))\n","model_resnet.add(Dropout(.2))\n","model_resnet.add(Dense(10,activation=('softmax')))\n","\n","#Summary of ResNet50 Model\n","model_resnet.summary()"],"outputs":[],"metadata":{"id":"TBrQ68r_3gJE","executionInfo":{"status":"aborted","timestamp":1622717046396,"user_tz":-330,"elapsed":11,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"code","execution_count":null,"source":["#Compiling ResNet50\n","model_resnet.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n","\n","\n","#Training the ResNet50 model\n","model_resnet.fit_generator(train_generator.flow(x_train, y_train, batch_size=batch_size), epochs=epochs, steps_per_epoch = x_train.shape[0]//batch_size, validation_data = val_generator.flow(x_val, y_val, batch_size = batch_size), validation_steps = 250, callbacks = [lrr], verbose=1)"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N2wau7YM3ldV","executionInfo":{"status":"ok","timestamp":1622718514750,"user_tz":-330,"elapsed":1463289,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"053f4363-2f7a-4520-ddd4-c995c1c087fd"}},{"cell_type":"code","execution_count":null,"source":["#Plotting the training and validation loss\n","f,ax=plt.subplots(2,1) #Creates 2 subplots under 1 column\n","#Training loss and validation loss\n","ax[0].plot(model_resnet.history.history['loss'],color='b',label='Training Loss')\n","ax[0].plot(model_resnet.history.history['val_loss'],color='r',label='Validation Loss')\n","#Training accuracy and validation accuracy\n","ax[1].plot(model_resnet.history.history['accuracy'],color='b',label='Training  Accuracy')\n","ax[1].plot(model_resnet.history.history['val_accuracy'],color='r',label='Validation Accuracy')"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":283},"id":"CZRipX3N3pJN","executionInfo":{"status":"ok","timestamp":1622718515357,"user_tz":-330,"elapsed":623,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"4d785315-1039-499f-eae7-0e0807f64888"}},{"cell_type":"code","execution_count":null,"source":["#Making prediction\n","y_pred3=model_resnet.predict_classes(x_test)\n","y_true=np.argmax(y_test,axis=1)\n","\n","#Plotting the non normalized confusion matrix\n","confusion_mtx=confusion_matrix(y_true,y_pred3)\n","\n","#Plotting non-normalized confusion matrix\n","plot_confusion_matrix(y_true, y_pred3, classes = class_names, title = 'Non-Normalized ResNet50 Confusion Matrix')"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":579},"id":"EQCZmbBO3ucE","executionInfo":{"status":"ok","timestamp":1622718522673,"user_tz":-330,"elapsed":7323,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"40ba9d08-e030-4133-8a2f-65c7fd5cc707"}},{"cell_type":"code","execution_count":null,"source":["#Plotting normalized confusion matrix\n","plot_confusion_matrix(y_true, y_pred3, classes=class_names, normalize = True, title = 'Normalized ResNet50 Confusion Matrix')"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":523},"id":"8asP9ReG3y9B","executionInfo":{"status":"ok","timestamp":1622718523440,"user_tz":-330,"elapsed":779,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"9bf4685b-002d-4feb-a04a-9d865e300db5"}},{"cell_type":"code","execution_count":null,"source":["#ResNet50 Classification accuracy\n","from sklearn.metrics import accuracy_score\n","accuracy_score(y_true, y_pred3)"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tDrnNsBo31W7","executionInfo":{"status":"ok","timestamp":1622718523442,"user_tz":-330,"elapsed":21,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"fa19c9e0-e817-4ab5-a18b-793e97e1c5b8"}},{"cell_type":"markdown","source":["#**Related Articles:**\n","\n","> * [Comparison of Transfer Learning with Multi Class Classification](https://analyticsindiamag.com/practical-comparison-of-transfer-learning-models-in-multi-class-image-classification/)\n","\n","> * [Fruit Recognition with CNN](https://analyticsindiamag.com/fruit-recognition-using-the-convolutional-neural-network/)\n","\n","> * [Semantic Segmentation Using TensorFlow Keras](https://analyticsindiamag.com/semantic-segmentation-using-tensorflow-keras/)\n","\n","> * [Convert Image to Pencil Sketch](https://analyticsindiamag.com/converting-image-into-a-pencil-sketch-in-python/)\n","\n","> * [Image Classification Task with and without Data Augmentation](https://analyticsindiamag.com/image-data-augmentation-impacts-performance-of-image-classification-with-codes/)\n","\n","> * [Image Data Augmentation Work As A Regularizer](https://analyticsindiamag.com/why-does-image-data-augmentation-work-as-a-regularizer-in-deep-learning/)\n","\n","> * [Guide to Pillow](https://analyticsindiamag.com/hands-on-guide-to-pillow-python-library-for-image-processing/)\n"],"metadata":{"id":"1ZtPNx78qe5T"}}]}