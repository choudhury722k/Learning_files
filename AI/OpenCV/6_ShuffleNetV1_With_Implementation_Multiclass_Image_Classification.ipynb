{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"ShuffleNetV1_With_Implementation_Multiclass_Image_Classification.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNQujAtsG12TZwGnGUIEBVX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **ShuffleNet V1 With Implementation In Multiclass Image Classification**"],"metadata":{"id":"T5jgdM0YpFWT"}},{"cell_type":"markdown","source":["With the recent advancement in the field of deep learning building deeper convolutional neural networks has become a trend for solving visualization problems. Though it gives accurate results the CNNs require computation of billions of FLOPS. To overcome this issue we introduce a computation efficient CNN architecture named ShuffleNet which is designed especially for mobile devices, drones and robots. It gives the best accuracy in the very limited computational budget.\n","\n","This practice session demonstrates how we can implement a deep learning model with ShuffleNet architecture to classify images of CIFAR-10 dataset.  Here, we define a Convolutional Neural Network (CNN) model using Torch to train this model. We will test the model to check the reduction in computational cost and obtain accuracy."],"metadata":{"id":"k60jB4xnqBv3"}},{"cell_type":"markdown","source":["To read about the whole architecture of ShuffleNet V1, please refer [this](https://analyticsindiamag.com/complete-guide-to-shufflenet-v1-with-implementation-in-multiclass-image-classification/) artilce."],"metadata":{"id":"EsktaiQkqG52"}},{"cell_type":"markdown","source":["## **About the Dataset**"],"metadata":{"id":"OWi1Tk-mqsbc"}},{"cell_type":"markdown","source":["The CIFAR-10 dataset contains 60,000 224Ã—224 colour images in 10 different classes. There are 6,000 images of each class. The 10 different classes represent aeroplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. There are 6,000 images of each class."],"metadata":{"id":"T1zaaeLDqxSJ"}},{"cell_type":"markdown","source":["## **Implementation**"],"metadata":{"id":"_naG9-gvqzgz"}},{"cell_type":"markdown","source":["First of all, we will import the required libraries."],"metadata":{"id":"qDSHg6gOq3Zk"}},{"cell_type":"code","execution_count":null,"source":["!python -m pip install pip --upgrade --user -q --no-warn-script-location\n","!python -m pip install numpy pandas seaborn matplotlib scipy statsmodels sklearn tensorflow keras opencv-python pillow scikit-image torch torchvision tqdm \\\n","    glob --user -q --no-warn-script-location\n","\n","import IPython\n","IPython.Application.instance().kernel.do_shutdown(True)\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["#Importing Libraries\n","import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import torchvision.datasets as dsets\n","from torchvision import models\n","from torchsummary import summary\n","from torch import nn,optim\n","import torch.nn.functional as F\n","import numpy as np\n","import pandas as pd\n","import torchvision\n","import os\n","import sys\n","import time\n","import math\n","import datetime as dt\n","import tqdm\n","import argparse\n","import glob\n","import matplotlib.pyplot as plt\n","import tarfile\n","import warnings \n","import torch.optim as optim\n","import torch.utils.data\n","warnings.filterwarnings(\"ignore\")"],"outputs":[],"metadata":{"id":"6uQ9crIumA-p"}},{"cell_type":"markdown","source":["After it, we will proceed by displaying the image."],"metadata":{"id":"7mfnZNiTq89N"}},{"cell_type":"markdown","source":["With data augmentation, we can get better accuracy. Normalize the data before training the data. Add padding, RandomHorizontalFlip and RandomCrop to it."],"metadata":{"id":"spw8XVg-rB2m"}},{"cell_type":"code","execution_count":null,"source":["#Initialize values\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","best_acc = 0  # best test accuracy\n","start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n","batch_size = 128"],"outputs":[],"metadata":{"id":"UumfkxwmwV1j"}},{"cell_type":"code","execution_count":null,"source":["print('==> Preparing data..')\n","transform_train = transforms.Compose([\n","   transforms.Pad(4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomCrop(32),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","transform_test = transforms.Compose([\n","   transforms.Pad(4),\n","   transforms.RandomHorizontalFlip(),\n","   transforms.RandomCrop(32),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n","train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n","test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n","classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","# functions to show an image\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from matplotlib.pyplot import figure\n","figure(num=None, figsize=(8, 8), dpi=150, facecolor='w', edgecolor='k')\n","# functions to show an image\n","classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","def imshow(img):\n","    img = img / 2 + 0.5     # unnormalize\n","    npimg = img.numpy()\n","    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","    plt.show()\n","# get some random training images\n","dataiter = iter(train_loader)\n","images, labels = dataiter.next()\n","# show images\n","imshow(torchvision.utils.make_grid(images))\n","# print labels\n","print(' '.join('%5s' % classes[labels[j]] for j in range(5)))"],"outputs":[],"metadata":{"id":"BuamidLZrDzF"}},{"cell_type":"markdown","source":["## **Defining Shufflenet for Our Work**"],"metadata":{"id":"1jfjSTPMwirz"}},{"cell_type":"markdown","source":["The below code snippet will define the ShuffleNet Architecture. The image 224*224 is passed on to the convolution layer with filter size 3*3 and stride 2. ShuffleNet uses pointwise group convolution so the model is passed over two GPUs.We get the image size for the next layer by applying formula (n+2p-f)/s +1 where n input channel,p is padding,f is kernel size and s is stride. The features are passed on to a fully connected layer that classifies the image out of 1000 classes."],"metadata":{"id":"uEel4t2IwlVV"}},{"cell_type":"code","execution_count":null,"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","class ShuffleBlock(nn.Module):\n","    def __init__(self, groups):\n","        super(ShuffleBlock, self).__init__()\n","        self.groups = groups\n","    def forward(self, x):\n","        '''Channel shuffle: [N,C,H,W] -> [N,g,C/g,H,W] -> [N,C/g,g,H,w] -> [N,C,H,W]'''\n","        N,C,H,W = x.size()\n","        g = self.groups\n","        return x.view(N,g,C//g,H,W).permute(0,2,1,3,4).reshape(N,C,H,W)\n","class Bottleneck(nn.Module):\n","    def __init__(self, in_planes, out_planes, stride, groups):\n","        super(Bottleneck, self).__init__()\n","        self.stride = stride\n","        mid_planes =int(out_planes/4)\n","        g = 1 if in_planes==24 else groups\n","        self.conv1 = nn.Conv2d(in_planes, mid_planes, kernel_size=1, groups=g, bias=False)\n","        self.bn1 = nn.BatchNorm2d(mid_planes)\n","        self.shuffle1 = ShuffleBlock(groups=g)\n","        self.conv2 = nn.Conv2d(mid_planes, mid_planes, kernel_size=3, stride=stride, padding=1, groups=mid_planes, bias=False)\n","        self.bn2 = nn.BatchNorm2d(mid_planes)\n","        self.conv3 = nn.Conv2d(mid_planes, out_planes, kernel_size=1, groups=groups, bias=False)\n","        self.bn3 = nn.BatchNorm2d(out_planes)\n","        self.shortcut = nn.Sequential()\n","        if stride == 2:\n","            self.shortcut = nn.Sequential(nn.AvgPool2d(3, stride=2, padding=1))\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.shuffle1(out)\n","        out = F.relu(self.bn2(self.conv2(out)))\n","        out = self.bn3(self.conv3(out))\n","        res = self.shortcut(x)\n","        out = F.relu(torch.cat([out,res], 1)) if self.stride==2 else F.relu(out+res)\n","        return out\n","class ShuffleNet(nn.Module):\n","    def __init__(self, cfg):\n","        super(ShuffleNet, self).__init__()\n","        out_planes = cfg['out_planes']\n","        num_blocks = cfg['num_blocks']\n","        groups = cfg['groups']\n","        self.conv1 = nn.Conv2d(3, 24, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(24)\n","        self.in_planes = 24\n","        self.layer1 = self._make_layer(out_planes[0], num_blocks[0], groups)\n","        self.layer2 = self._make_layer(out_planes[1], num_blocks[1], groups)\n","        self.layer3 = self._make_layer(out_planes[2], num_blocks[2], groups)\n","        self.linear = nn.Linear(out_planes[2], 10)\n","    def _make_layer(self, out_planes, num_blocks, groups):\n","        layers = []\n","        for i in range(num_blocks):\n","            stride = 2 if i == 0 else 1\n","            cat_planes = self.in_planes if i == 0 else 0\n","            layers.append(Bottleneck(self.in_planes, out_planes-cat_planes, stride=stride, groups=groups))\n","            self.in_planes = out_planes\n","        return nn.Sequential(*layers)\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = F.avg_pool2d(out, 4)\n","        out = out.view(out.size(0), -1)\n","        out = self.linear(out)\n","        return out\n","def ShuffleNetG2():\n","    cfg = {\n","        'out_planes': [200,400,800],\n","        'num_blocks': [4,8,4],\n","        'groups': 2\n","    }\n","    return ShuffleNet(cfg)\n","def ShuffleNetG3():\n","    cfg = {\n","        'out_planes': [240,480,960],\n","        'num_blocks': [4,8,4],\n","        'groups': 3\n","    }\n","    return ShuffleNet(cfg)\n","net = ShuffleNetG2()\n","x = torch.randn(1,3,32,32)\n","y = net(x)\n","print(y)\n","net = ShuffleNetG2()\n","print(net)\n","#Setting the model on CUDA\n","if torch.cuda.is_available():\n","    net.cuda()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)"],"outputs":[],"metadata":{"id":"qbk7BwuiwtH-"}},{"cell_type":"markdown","source":["## **Training Testing and Making Predictions**"],"metadata":{"id":"sl2eQthowwbx"}},{"cell_type":"markdown","source":["Now, we are all set to train and test the model on the CIFAR-10 dataset.For better accuracy train and test the model with 60 epochs."],"metadata":{"id":"vZNY892mwzxG"}},{"cell_type":"code","execution_count":null,"source":["# Training the model\n","def train_net():\n","    net.train()\n","    train_loss = 0\n","    n_correct = 0\n","    n_total = 0\n","    for batch_size, (inputs, targets) in enumerate(train_loader):\n","        inputs, targets = inputs.to(device), targets.to(device)\n","        optimizer.zero_grad()\n","        outputs = net(inputs)\n","        loss = criterion(outputs, targets)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item()\n","        _, predicted = outputs.max(1)\n","        n_correct += predicted.eq(targets).sum().item()\n","        n_total += targets.shape[0]\n","    return train_loss/(batch_size+1),n_correct/n_total\n","def get_loss_acc(is_test_dataset = True):\n","    net.eval()\n","    dataloader = test_loader if is_test_dataset else train_loader\n","    n_correct = 0\n","    n_total = 0\n","    test_loss = 0\n","    with torch.no_grad():\n","        for batch_size, (inputs, targets) in enumerate(dataloader):\n","            inputs, targets = inputs.to(device), targets.to(device)\n","            outputs = net(inputs)\n","            test_loss += criterion(outputs, targets).item()\n","            _, predicted = outputs.max(1)\n","            n_correct += predicted.eq(targets).sum().item()\n","            n_total += targets.shape[0]\n","    return test_loss/(batch_size+1),n_correct/n_total\n","#Testing the model\n","def test(epoch):\n","    global best_acc\n","    net.eval()\n","    test_loss = 0\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for batch_idx, (inputs, targets) in enumerate(test_loader):\n","            inputs, targets = inputs.to(device), targets.to(device)\n","            outputs = net(inputs)\n","            loss = criterion(outputs, targets)\n","            test_loss += loss.item()\n","            _, predicted = outputs.max(1)\n","            total += targets.size(0)\n","            correct += predicted.eq(targets).sum().item()\n","            print(batch_idx, len(test_loader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n","                % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n","  # Save checkpoint.\n","    acc = 100.*correct/total\n","    if acc > best_acc:\n","        print('Saving..')\n","        state = {\n","            'net': net.state_dict(),\n","            'acc': acc,\n","            'epoch': epoch,\n","        }\n","        if not os.path.isdir('checkpoint'):\n","            os.mkdir('checkpoint')\n","        torch.save(state, './checkpoint/ckpt.pth')\n","        torch.save(net, './checkpoint/net.pth')\n","        best_acc = acc\n","import glob\n","import torch.optim as optim\n","import datetime as dt\n","EPOCH = 60\n","start = dt.datetime.now()\n","start_epoch=0\n","for epochi in range(start_epoch,start_epoch + EPOCH):\n","    #scheduler.step()\n","    cur_lr = [i['lr'] for i in optimizer.param_groups][0]\n","    print(\"Batch Size\",batch_size,'(%.2fs)\\n\\nEpoch: %d/%d | cur_lr:%.4f ' % (\n","       (dt.datetime.now()-start).seconds, epochi+1,EPOCH+start_epoch,cur_lr))\n","    start = dt.datetime.now()\n","    test_loss , test_acc = get_loss_acc()\n","    train_loss , train_acc = train_net()\n","    #hist.append([train_loss , train_acc,test_loss , test_acc])\n","    print( 'train Loss: %.3f | Acc: %.3f%% \\ntest Loss: %.3f | Acc: %.3f%% ' % (\n","        train_loss, train_acc*100,test_loss, test_acc*100))\n","\n","#Count Parameters\n","def count_parameters(model):\n","    pytorch_total_params = sum(p.numel() for p in model.parameters())\n","    print(\"Total_params\",pytorch_total_params)\n","    pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","    print(\"Trainable_params\",pytorch_total_params)"],"outputs":[],"metadata":{"id":"89JHg0dqw8Ir"}},{"cell_type":"markdown","source":["Compared to other architecture the number of parameters is less."],"metadata":{"id":"rgnyK1odw-rE"}},{"cell_type":"code","execution_count":null,"source":["#Model Accuracy\n","total_correct = 0\n","total_images = 0\n","confusion_matrix = np.zeros([10,10], int)\n","with torch.no_grad():\n","    for data in test_loader:\n","        images, labels = data\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = net(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total_images += labels.size(0)\n","        total_correct += (predicted == labels).sum().item()\n","        for i, l in enumerate(labels):\n","            confusion_matrix[l.item(), predicted[i].item()] += 1 \n","model_accuracy = total_correct / total_images * 100\n","print('Model accuracy on {0} test images: {1:.2f}%'.format(total_images, model_accuracy))"],"outputs":[],"metadata":{"id":"Q_JZBasUxA50"}},{"cell_type":"markdown","source":["## **Results of the Model**"],"metadata":{"id":"IYNQMZEfxC2f"}},{"cell_type":"code","execution_count":null,"source":["#Result\n","print('{0:10s} - {1}'.format('Category','Accuracy'))\n","for i, r in enumerate(confusion_matrix):\n","    print('{0:10s} - {1:.1f}'.format(classes[i], r[i]/np.sum(r)*100))\n","\n","#Plot the confusion Matrix\n","fig, ax = plt.subplots(1,1,figsize=(8,6))\n","ax.matshow(confusion_matrix, aspect='auto', vmin=0, vmax=1000, cmap=plt.get_cmap('Blues'))\n","plt.ylabel('Actual Category')\n","plt.yticks(range(10), classes)\n","plt.xlabel('Predicted Category')\n","plt.xticks(range(10), classes)\n","plt.show()"],"outputs":[],"metadata":{"id":"tq91SkL3xF8N"}},{"cell_type":"markdown","source":["As we can see in the above result the model has very high accuracy on both training and test. The number of parameters is less thereby reducing the computational complexity. So we can conclude that the model has given accurate predictions to classify images on the CIFAR-10 dataset. With an increase in the number of epochs, we can get better accuracy."],"metadata":{"id":"Vch3UznKxI5u"}},{"cell_type":"markdown","source":["#**Related Articles:**\n","\n","> * [SuffleNet V1 for Image Classification](https://analyticsindiamag.com/complete-guide-to-shufflenet-v1-with-implementation-in-multiclass-image-classification/)\n","\n","> * [Image Compression using K-Means Clustering](https://analyticsindiamag.com/beginners-guide-to-image-compression-using-k-means-clustering/)\n","\n","> * [PCA for images](https://analyticsindiamag.com/how-does-pca-dimension-reduction-work-for-images/)\n","\n","> * [Image Generation with Tensorflow Keras](https://analyticsindiamag.com/getting-started-image-generation-tensorflow-keras/)\n","\n","> * [Getting Started with Computer Vision using Tensorflow Keras](https://analyticsindiamag.com/computer-vision-using-tensorflow-keras/)\n","\n","> * [Feature Extraction of Images with Skimage](https://analyticsindiamag.com/image-feature-extraction-using-scikit-image-a-hands-on-guide/)\n","\n"],"metadata":{"id":"1ZtPNx78qe5T"}}]}