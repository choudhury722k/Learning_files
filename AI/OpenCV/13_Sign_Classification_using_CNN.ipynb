{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"1_Sign_Classification_using_CNN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNIfigb/XtcfAe7yg/PVXEj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## **Sign Language Classification Using CNN**"],"metadata":{"id":"HJHt72NlV_8v"}},{"cell_type":"markdown","source":["In this practice session, we will classify the sign language symbols using the Convolutional Neural Network (CNN). After successful training of the CNN model, the corresponding alphabet of a sign language symbol will be predicted. We will evaluate the classification performance of our model using the non-normalized and normalized confusion matrices. Finally, we will obtain the classification accuracy score of the CNN model in this task."],"metadata":{"id":"yNpvy5irWFmg"}},{"cell_type":"markdown","source":["## **The Data Set**\n","\n","We have used the American Sign Language (ASL) data set that is provided by MNIST and it is publicly available at [Kaggle](https://www.kaggle.com/datamunge/sign-language-mnist). This dataset contains 27455 training images and 7172 test images all with a shape of 28 x 28 pixels. These images belong to the 25 classes of English alphabet starting from A to Y (No class labels for Z because of gesture motions). The dataset on Kaggle is available in the CSV format where training data has 27455 rows and 785 columns. The first column of the dataset represents the class label of the image and the remaining 784 columns represent the 28 x 28 pixels. The same paradigm is followed by the test data set."],"metadata":{"id":"BP6s1T9ZWJPm"}},{"cell_type":"markdown","source":["## **Implementation of Sign Language Classification**"],"metadata":{"id":"XHD1t8BYWX3a"}},{"cell_type":"code","execution_count":null,"source":["!python -m pip install pip --upgrade --user -q --no-warn-script-location\n","!python -m pip install numpy pandas seaborn matplotlib scipy statsmodels sklearn nltk gensim tensorflow keras torch torchvision \\\n","    tqdm scikit-image --user -q --no-warn-script-location\n","\n","\n","import IPython\n","IPython.Application.instance().kernel.do_shutdown(True)\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# !git clone https://github.com/gchilingaryan/Sign-Language"],"outputs":[],"metadata":{"id":"DHWXm36lW0U9"}},{"cell_type":"markdown","source":["The directory of the uploaded CSV files is defined using the below line of code."],"metadata":{"id":"yfmF1cEhW6Zo"}},{"cell_type":"code","execution_count":null,"source":["# !mkdir data"],"outputs":[],"metadata":{"id":"lxYJED0kXEJP"}},{"cell_type":"code","execution_count":null,"source":["# !cp Sign-Language/amer_sign2.png data/\n","# !cp Sign-Language/amer_sign3.png data/\n","# !cp Sign-Language/american_sign_language.PNG data/\n","# !cp Sign-Language/sign_mnist_test.csv data/\n","# !cp Sign-Language/sign_mnist_train.csv data/"],"outputs":[],"metadata":{"id":"ZZ7CAKHQXMMY"}},{"cell_type":"code","execution_count":null,"source":["dir_path = \"https://gitlab.com/AnalyticsIndiaMagazine/practicedatasets/-/raw/main/sign_classification/\""],"outputs":[],"metadata":{"id":"_7thiDxMW78D"}},{"cell_type":"markdown","source":["We will verify the contents of the directory using the below lines of codes."],"metadata":{"id":"XqC5Ab0DW_6C"}},{"cell_type":"code","execution_count":null,"source":["# import os\n","# for dirname, _, filenames in os.walk(dir_path):\n","#     for filename in filenames:\n","#         print(os.path.join(dirname, filename))"],"outputs":[],"metadata":{"id":"rShsx00LXwi-"}},{"cell_type":"markdown","source":["We will print the Sign Language image that we can see in the above list of files."],"metadata":{"id":"Pqhqo6f8Xysv"}},{"cell_type":"code","execution_count":null,"source":["from IPython.display import Image\n","Image('https://gitlab.com/AnalyticsIndiaMagazine/practicedatasets/-/raw/main/sign_classification/data/amer_sign2.png')"],"outputs":[],"metadata":{"id":"aEiaon3QX0Zh"}},{"cell_type":"markdown","source":["Some important libraries will be uploaded to read the dataset, preprocessing and visualization."],"metadata":{"id":"JUtMIJjpX3eH"}},{"cell_type":"code","execution_count":null,"source":["import pandas as pd\n","import numpy as np\n","import random\n","import matplotlib.pyplot as plt"],"outputs":[],"metadata":{"id":"C1ignmdaX5VJ"}},{"cell_type":"markdown","source":["We will read the training and test CSV files"],"metadata":{"id":"HLndEqNlX6wm"}},{"cell_type":"code","execution_count":null,"source":["train = pd.read_csv('https://gitlab.com/AnalyticsIndiaMagazine/practicedatasets/-/raw/main/sign_classification/data/sign_mnist_train.csv')\n","test = pd.read_csv('https://gitlab.com/AnalyticsIndiaMagazine/practicedatasets/-/raw/main/sign_classification/data/sign_mnist_test.csv')"],"outputs":[],"metadata":{"id":"AU3T7eJ8X8ep"}},{"cell_type":"markdown","source":["We will check the shape of the training and test data that we have read above."],"metadata":{"id":"qI6guWLzX_7M"}},{"cell_type":"code","execution_count":null,"source":["print(train.shape)\n","print(test.shape)"],"outputs":[],"metadata":{"id":"3KILGGuJYBjv"}},{"cell_type":"markdown","source":["We will check the training data to verify class labels and columns representing pixels. "],"metadata":{"id":"Wd0meT_ZYDGE"}},{"cell_type":"code","execution_count":null,"source":["train.head()"],"outputs":[],"metadata":{"id":"pD2M9O1PYEqM"}},{"cell_type":"markdown","source":["For further preprocessing and visualization, we will convert the data frames into arrays."],"metadata":{"id":"uVHAKLjLYG_a"}},{"cell_type":"code","execution_count":null,"source":["# Create training and testing arrays\n","train_set = np.array(train, dtype = 'float32')\n","test_set = np.array(test, dtype='float32')"],"outputs":[],"metadata":{"id":"FF4bZsOAYG2v"}},{"cell_type":"markdown","source":["We will specify the class labels for the images."],"metadata":{"id":"WKvj5yJZYM44"}},{"cell_type":"code","execution_count":null,"source":["#Specifying class labels\n","class_names = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y' ]"],"outputs":[],"metadata":{"id":"lrwYnsFjYPS4"}},{"cell_type":"markdown","source":["We will check a random image from the training set to verify its class label."],"metadata":{"id":"ktyDgCBlYRNJ"}},{"cell_type":"code","execution_count":null,"source":["#See a random image for class label verification\n","i = random.randint(1,27455)\n","plt.imshow(train_set[i,1:].reshape((28,28))) \n","plt.imshow(train_set[i,1:].reshape((28,28))) \n","label_index = train[\"label\"][i]\n","plt.title(f\"{class_names[label_index]}\")\n","plt.axis('off')"],"outputs":[],"metadata":{"id":"GkAl3G1mYSwz"}},{"cell_type":"markdown","source":["Now, we will plot some random images from the training set with their class labels."],"metadata":{"id":"XmWdWYnbYUZ8"}},{"cell_type":"code","execution_count":null,"source":["# Define the dimensions of the plot grid \n","W_grid = 5\n","L_grid = 5\n","fig, axes = plt.subplots(L_grid, W_grid, figsize = (10,10))\n","axes = axes.ravel() # flaten the 15 x 15 matrix into 225 array\n","n_train = len(train_set) # get the length of the train dataset\n","# Select a random number from 0 to n_train\n","for i in np.arange(0, W_grid * L_grid): # create evenly spaces variables \n","    # Select a random number\n","    index = np.random.randint(0, n_train)\n","    # read and display an image with the selected index    \n","    axes[i].imshow( train_set[index,1:].reshape((28,28)) )\n","    label_index = int(train_set[index,0])\n","    axes[i].set_title(class_names[label_index], fontsize = 8)\n","    axes[i].axis('off')\n","plt.subplots_adjust(hspace=0.4)"],"outputs":[],"metadata":{"id":"ow14ne3WYXBs"}},{"cell_type":"markdown","source":["In the next step, we will preprocess out datasets to make them available for the training."],"metadata":{"id":"0OvAb0W6YY12"}},{"cell_type":"code","execution_count":null,"source":["# Prepare the training and testing dataset \n","X_train = train_set[:, 1:] / 255\n","y_train = train_set[:, 0]\n","\n","X_test = test_set[:, 1:] / 255\n","y_test = test_set[:,0]"],"outputs":[],"metadata":{"id":"bYsBWdd-YbGX"}},{"cell_type":"markdown","source":["From the processed training data, we will plot some random images."],"metadata":{"id":"v2yAU3RZYcvK"}},{"cell_type":"code","execution_count":null,"source":["#Visualize train images\n","plt.figure(figsize=(10, 10))\n","for i in range(25):\n","    plt.subplot(5, 5, i + 1)\n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.grid(False)\n","    plt.imshow(X_train[i].reshape((28,28)), cmap=plt.cm.binary)\n","    label_index = int(y_train[i])\n","    plt.title(class_names[label_index])\n","plt.show()"],"outputs":[],"metadata":{"id":"viK1IgBEYenS"}},{"cell_type":"markdown","source":["Now, to train the model, we will split our data set into training and test sets."],"metadata":{"id":"5G-TBpRsYhdF"}},{"cell_type":"code","execution_count":null,"source":["#Split the training and test sets\n","from sklearn.model_selection import train_test_split\n","X_train, X_validate, y_train, y_validate = train_test_split(X_train, y_train, test_size = 0.2, random_state = 12345)"],"outputs":[],"metadata":{"id":"KFp4-iFMYjSC"}},{"cell_type":"markdown","source":["Now, we will check the shape of the training data set."],"metadata":{"id":"-pjmiYA1Yk1C"}},{"cell_type":"code","execution_count":null,"source":["print(X_train.shape)\n","print(y_train.shape)"],"outputs":[],"metadata":{"id":"AJuUutFlYnCw"}},{"cell_type":"markdown","source":["To train the model, we will unfold the data to make it available for training, testing and validation purposes."],"metadata":{"id":"m2BAuqHmYqnU"}},{"cell_type":"code","execution_count":null,"source":["# Unpack the training and test tuple\n","X_train = X_train.reshape(X_train.shape[0], *(28, 28, 1))\n","X_test = X_test.reshape(X_test.shape[0], *(28, 28, 1))\n","X_validate = X_validate.reshape(X_validate.shape[0], *(28, 28, 1))\n","\n","print(X_train.shape)\n","print(y_train.shape)\n","print(X_validate.shape)"],"outputs":[],"metadata":{"id":"iWnQkw6-Ysqz"}},{"cell_type":"markdown","source":["## **Convolutional Neural Network**"],"metadata":{"id":"_uUyo49TYvPZ"}},{"cell_type":"markdown","source":["In the next step, we will define our Convolutional Neural Network (CNN) Model. For this purpose, first, we will import the required libraries. Make sure that you have installed the TensorFlow if you are working on your local system."],"metadata":{"id":"IJmMAo0dY5ZY"}},{"cell_type":"code","execution_count":null,"source":["#Library for CNN Model\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n","from tensorflow.keras.optimizers import Adam\n","from keras.callbacks import TensorBoard\n","\n","#Defining the Convolutional Neural Network\n","cnn_model = Sequential()\n","\n","cnn_model.add(Conv2D(32, (3, 3), input_shape = (28,28,1), activation='relu'))\n","cnn_model.add(MaxPooling2D(pool_size = (2, 2)))\n","cnn_model.add(Dropout(0.25))\n","\n","cnn_model.add(Conv2D(64, (3, 3), input_shape = (28,28,1), activation='relu'))\n","cnn_model.add(MaxPooling2D(pool_size = (2, 2)))\n","cnn_model.add(Dropout(0.25))\n","\n","cnn_model.add(Conv2D(128, (3, 3), input_shape = (28,28,1), activation='relu'))\n","cnn_model.add(MaxPooling2D(pool_size = (2, 2)))\n","cnn_model.add(Dropout(0.25))\n","\n","cnn_model.add(Flatten())\n","\n","cnn_model.add(Dense(units = 512, activation = 'relu'))\n","cnn_model.add(Dropout(0.25))\n","cnn_model.add(Dense(units = 25, activation = 'softmax'))"],"outputs":[],"metadata":{"id":"hDC1NXtcY7gk"}},{"cell_type":"markdown","source":["After defining our model, we will check the model by its summary."],"metadata":{"id":"hGe0_FVWY9Gc"}},{"cell_type":"code","execution_count":null,"source":["#CNN Model Summary\n","cnn_model.summary()"],"outputs":[],"metadata":{"id":"fPb2i5OBY_ZK"}},{"cell_type":"markdown","source":["In the next step, we will compile and train the CNN model."],"metadata":{"id":"2Nu_6a-xZClm"}},{"cell_type":"code","execution_count":null,"source":["#Compiling\n","cnn_model.compile(loss ='sparse_categorical_crossentropy', optimizer='adam' ,metrics =['accuracy'])\n","\n","#Training the CNN model\n","history = cnn_model.fit(X_train, y_train, batch_size = 512, epochs = 50, verbose = 1, validation_data = (X_validate, y_validate))"],"outputs":[],"metadata":{"id":"7biNV7WvZEnp"}},{"cell_type":"markdown","source":["After successful training, we will visualize the training performance of the CNN model."],"metadata":{"id":"MIcm87cwZGor"}},{"cell_type":"code","execution_count":null,"source":["#Visualizing the training performance\n","plt.figure(figsize=(12, 8))\n","\n","plt.subplot(2, 2, 1)\n","plt.plot(history.history['loss'], label='Loss')\n","plt.plot(history.history['val_loss'], label='val_Loss')\n","plt.legend()\n","plt.grid()\n","plt.title('Loss evolution')\n","\n","plt.subplot(2, 2, 2)\n","plt.plot(history.history['accuracy'], label='accuracy')\n","plt.plot(history.history['val_accuracy'], label='val_accuracy')\n","plt.legend()\n","plt.grid()\n","plt.title('Accuracy evolution')"],"outputs":[],"metadata":{"id":"4PncihSeZIbt"}},{"cell_type":"markdown","source":["Once we find the training satisfactory, we will use our trained CNN model to make predictions on the unseen test data."],"metadata":{"id":"MpGjbovNZKaV"}},{"cell_type":"markdown","source":["##**Predictions for the test data**"],"metadata":{"id":"zjmZNPHbZMWN"}},{"cell_type":"code","execution_count":null,"source":["predict_x=cnn_model.predict(X_test) \n","predicted_classes=np.argmax(predict_x,axis=1)"],"outputs":[],"metadata":{"id":"cx-RkD6HZPWW"}},{"cell_type":"code","execution_count":null,"source":["#Visualize predictions\n","L = 5\n","W = 5\n","\n","fig, axes = plt.subplots(L, W, figsize = (12,12))\n","axes = axes.ravel()\n","\n","for i in np.arange(0, L * W):  \n","    axes[i].imshow(X_test[i].reshape(28,28))\n","    axes[i].set_title(f\"Prediction Class = {predicted_classes[i]:0.1f}\\n True Class = {y_test[i]:0.1f}\")\n","    axes[i].axis('off')\n","plt.subplots_adjust(wspace=0.5)"],"outputs":[],"metadata":{"id":"eKNbPUDuZQ7e"}},{"cell_type":"markdown","source":["As we can see in the above visualization, the CNN model has predicted the correct class labels for almost all the images. Now we will see the full classification report using a normalized and non-normalized confusion matrices. "],"metadata":{"id":"dQZ8rA0lZTL0"}},{"cell_type":"code","execution_count":null,"source":["from sklearn.metrics import confusion_matrix\n","from sklearn import metrics\n","cm = metrics.confusion_matrix(y_test, predicted_classes)"],"outputs":[],"metadata":{"id":"bymv_p9XZU2S"}},{"cell_type":"markdown","source":["We will define a function to plot the confusion matrix"],"metadata":{"id":"PKcOaMf7ZWpM"}},{"cell_type":"code","execution_count":null,"source":["#Defining function for confusion matrix plot\n","def plot_confusion_matrix(y_true, y_pred, classes,\n","                          normalize=False,\n","                          title=None,\n","                          cmap=plt.cm.Blues):\n","    if not title:\n","        if normalize:\n","            title = 'Normalized confusion matrix'\n","        else:\n","            title = 'Confusion matrix, without normalization'\n","\n","    # Computing confusion matrix\n","    cm = confusion_matrix(y_true, y_pred)\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        print(\"Normalized confusion matrix\")\n","    else:\n","        print('Confusion matrix, without normalization')\n","\n","# Visualizing\n","    fig, ax = plt.subplots(figsize=(10, 10))\n","    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n","    ax.figure.colorbar(im, ax=ax)\n","    # We want to show all ticks...\n","    ax.set(xticks=np.arange(cm.shape[1]),\n","           yticks=np.arange(cm.shape[0]),\n","           xticklabels=classes, yticklabels=classes,\n","           title=title,\n","           ylabel='True label',\n","           xlabel='Predicted label')\n","\n","   # Rotating the tick labels and setting their alignment.\n","    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n","             rotation_mode=\"anchor\")\n","    # Looping over data dimensions and create text annotations.\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","    for i in range(cm.shape[0]):\n","        for j in range(cm.shape[1]):\n","            ax.text(j, i, format(cm[i, j], fmt),\n","                    ha=\"center\", va=\"center\",\n","                    color=\"white\" if cm[i, j] > thresh else \"black\")\n","    fig.tight_layout()\n","    return ax\n","np.set_printoptions(precision=2)"],"outputs":[],"metadata":{"id":"x70NCI_WZYsW"}},{"cell_type":"markdown","source":["Before plotting the confusion matrix, we will specify the class labels."],"metadata":{"id":"DNdhkEuzZaPw"}},{"cell_type":"code","execution_count":null,"source":["#Specifying class labels\n","class_names = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y' ]"],"outputs":[],"metadata":{"id":"WoSCwPq2ZdIa"}},{"cell_type":"code","execution_count":null,"source":["#Non-Normalized Confusion Matrix\n","plt.figure(figsize=(20,20))\n","plot_confusion_matrix(y_test, predicted_classes, classes = class_names, title='Non-Normalized Confusion matrix')\n","plt.show()"],"outputs":[],"metadata":{"id":"0FFjxkizZe-b"}},{"cell_type":"code","execution_count":null,"source":["#Normalized Confusion Matrix\n","plt.figure(figsize=(35,35))\n","plot_confusion_matrix(y_test, predicted_classes, classes = class_names, normalize=True, title='Non-Normalized Confusion matrix')\n","plt.show()"],"outputs":[],"metadata":{"id":"qrdHd0CzZhZE"}},{"cell_type":"code","execution_count":null,"source":["#Classification accuracy\n","from sklearn.metrics import accuracy_score\n","acc_score = accuracy_score(y_test, predicted_classes)\n","print('Accuracy Score = ',acc_score)"],"outputs":[],"metadata":{"id":"TPNp6pp5ZlOq"}},{"cell_type":"markdown","source":["#**Related Articles:**\n","\n","> * [Sign Language Classification using CNN](https://analyticsindiamag.com/hands-on-guide-to-sign-language-classification-using-cnn/)\n","\n","> * [Transfer Learning for multi class classification](https://analyticsindiamag.com/transfer-learning-for-multi-class-image-classification-using-deep-convolutional-neural-network/)\n","\n","> * [FastAI with PyTorch for multiclass Image Classification](https://analyticsindiamag.com/fastai-with-tpu-in-pytorch-for-multiclass-image-classification/)\n","\n","> * [SuffleNet V1 for Multiclass Image Classification](https://analyticsindiamag.com/complete-guide-to-shufflenet-v1-with-implementation-in-multiclass-image-classification/)\n","\n","> * [Image Compression using K-Means Clustering](https://analyticsindiamag.com/beginners-guide-to-image-compression-using-k-means-clustering/)\n","\n","> * [PCA for images](https://analyticsindiamag.com/how-does-pca-dimension-reduction-work-for-images/)\n","\n","> * [Image Generation with Tensorflow Keras](https://analyticsindiamag.com/getting-started-image-generation-tensorflow-keras/)\n","\n"],"metadata":{"id":"1ZtPNx78qe5T"}}]}