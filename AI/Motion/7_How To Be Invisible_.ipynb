{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"How To Be Invisible?.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNhUcU1dlxsgc9wSkKZT6hT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **How To Be Invisible?**"],"metadata":{"id":"9I6Akz7ZA6Rl"}},{"cell_type":"markdown","source":["Most of you must have heard about the Harry Potter series. In that series, Harry potter used an invisibility cloak, that makes him invisible…! Are you wondering how they made invisible cloaks…..? That’s not as tough as rocket science to build this invisibility cloak. By using simple techniques in the OpenCV we can implement this invisible cloak. This concept is similar to the green mat used in movie shootings. After shooting, they add graphics in the place of a green mat to give the output."],"metadata":{"id":"ubflzoz3A9QP"}},{"cell_type":"markdown","source":["In this implementation, we will learn how to create our own ‘Invisibility Cloak’ using simple computer vision techniques in OpenCV. Here we are using OpenCV because it provides the best-inbuilt libraries to implement this in a few steps."],"metadata":{"id":"KGhVX_SiA_4U"}},{"cell_type":"markdown","source":["## Steps used for this implementation on Being invisible using OpenCV:-\n","\n","> * Defining the function \n","> * Capturing and storing the background\n","> * Capturing the live video using a webcam\n","> * Displaying the output\n","\n","So, now let’s begin with this interesting implementation."],"metadata":{"id":"0kcBPEnjBBrT"}},{"cell_type":"markdown","source":["Importing libraries "],"metadata":{"id":"oPn83--wBHEv"}},{"cell_type":"code","execution_count":null,"source":["\n","!python -m pip install pip --upgrade --user -q --no-warn-script-location\n","!python -m pip install numpy pandas seaborn matplotlib scipy statsmodels sklearn nltk opencv-python tensorflow keras torch torchvision \\\n","    tqdm scikit-image pixellib pytube dlib --user -q --no-warn-script-location\n","\n","import IPython\n","IPython.Application.instance().kernel.do_shutdown(True)\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":1,"source":["import numpy as np\n","import cv2"],"outputs":[],"metadata":{"id":"YnfQBWYiA5Tk","executionInfo":{"status":"ok","timestamp":1623749615150,"user_tz":-330,"elapsed":423,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"markdown","source":["Step – 1 – Defining the function "],"metadata":{"id":"saNn6-aEBLWS"}},{"cell_type":"code","execution_count":3,"source":["def detect_func(frame, background):\n","\n","    hsv_image = cv2.cvtColor(frame, cv2.COLOR_RGB2HSV)  \n","    #Using the below code snippet, we will assign the values of sensitivity, Hue, and range for blue color.\n","    sensitivity = 20\n","    H_Value = 20   \n","    light_blue = np.array([H_Value - sensitivity, 60, 60])\n","    dark_blue = np.array([H_Value + sensitivity, 255, 255])\n","\n","    #In the above implementation, we have used blue color values you can replace with another color just by changing those values\n","\n","    #Using the below code snippet, we will use morphing techniques to create the mask for the blue-colored region.\n","    create_mask = cv2.inRange(hsv_image, light_blue, dark_blue)  \n","    kernel_size = 15\n","    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n","    closing = cv2.morphologyEx(create_mask, cv2.MORPH_CLOSE, kernel)\n","    contours, _ = cv2.findContours(closing, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","    sorted = sorted(contours, key=cv2.contourArea, reverse=True)[:5]\n","    mask = cv2.fillPoly(np.zeros((500, 500, 3), dtype=np.uint8), pts =[cont_sorted[0]], color=(255,255,255))\n","\n","    #In the above implementation, the bigger sized kernel gives fewer gaps on the image\n","\n","    #In the below code snippet, we will use the cv2.fillPoly function to merge the mask and background frames which displays the final output.\n","    object_mask = cv2.fillPoly(frame, pts =[cont_sorted[0]], color=(0,0,0))\n","    background = np.bitwise_and(contour_mask, background)\n","    final_img = cv2.bitwise_or(object_mask, background)\n","    return final_img"],"outputs":[],"metadata":{"id":"MpWcWljJBKDC","executionInfo":{"status":"ok","timestamp":1623749696000,"user_tz":-330,"elapsed":357,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}}}},{"cell_type":"markdown","source":["To manipulate the video by using a mask, we have used bitwise_and and bitwise_or operations."],"metadata":{"id":"cxIozLxCBiQ4"}},{"cell_type":"markdown","source":["Step – 2 – Capturing and storing the background"],"metadata":{"id":"1O7_1vw9BkZw"}},{"cell_type":"code","execution_count":4,"source":["cap = cv2.VideoCapture(0)\n","ret, background = cap.read()\n","background = cv2.resize(background, (500, 500))\n","cv2.imshow('back_img', background)\n","cv2.waitKey(0)\n","cv2.destroyAllWindows()"],"outputs":[{"output_type":"error","ename":"error","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-2ff56339f401>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackground\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbackground\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackground\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'back_img'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackground\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/imgproc/src/resize.cpp:3720: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":243},"id":"lNf4-i_SBeCP","executionInfo":{"status":"error","timestamp":1623749729888,"user_tz":-330,"elapsed":372,"user":{"displayName":"Aishwarya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64","userId":"06108390091304498033"}},"outputId":"647805d8-297f-41eb-964e-dcb20284c581"}},{"cell_type":"markdown","source":["Step – 3 – Capturing the live video and applying an invisible function to it."],"metadata":{"id":"NSLvqjmXBsnd"}},{"cell_type":"code","execution_count":null,"source":["fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n","output = cv2.VideoWriter('output.mp4', fourcc, 30.0, (500,500))\n","while(True):\n","    ret, frame = cap.read()\n","    frame = cv2.resize(frame, (500, 500))\n","    image = detect_blue(frame, background)\n","    output.write(image)"],"outputs":[],"metadata":{"id":"_Jf6aoIcBpqQ"}},{"cell_type":"markdown","source":["Step – 4 – Displaying the results "],"metadata":{"id":"_4xOGgJGBy48"}},{"cell_type":"code","execution_count":null,"source":["import matplotlib.pyplot as plt\n","plt.imshow(image)\n","plt.show()"],"outputs":[],"metadata":{"id":"8abVuBgLBzEW"}}]}